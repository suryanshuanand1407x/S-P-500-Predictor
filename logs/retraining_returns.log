[2025-10-25 10:48:06,954] INFO: Sensex & Gold LSTM Price Predictor starting...
[2025-10-25 10:48:06,954] INFO: ðŸ“‹ Loading configuration from: configs/tuned.yaml
[2025-10-25 10:48:06,956] INFO: âœ… Configuration validated successfully
[2025-10-25 10:48:06,956] INFO: ðŸ” Checking system requirements...
[2025-10-25 10:48:08,862] INFO: âœ… MPS (Apple Silicon) acceleration available
[2025-10-25 10:48:08,862] INFO: âœ… System requirements check passed
[2025-10-25 10:48:08,862] INFO: ðŸ“ Directory structure verified
[2025-10-25 10:48:08,862] INFO: ðŸš€ Starting LSTM training pipeline...
[2025-10-25 10:48:08,862] INFO: ðŸ“‹ Configuration: configs/tuned.yaml
[2025-10-25 10:48:08,950] INFO: === SENSEX-GOLD LSTM PREDICTOR TRAINING ===
[2025-10-25 10:48:08,950] INFO: Configuration: configs/tuned.yaml
[2025-10-25 10:48:08,951] INFO: Random seed set to 42
[2025-10-25 10:48:08,951] INFO: Using device: mps
[2025-10-25 10:48:08,951] INFO: Step 1: Verifying real data integrity...
[2025-10-25 10:48:09,027] INFO: Step 2: Ingesting and cleaning data...
[2025-10-25 10:48:09,027] INFO: Starting data ingestion pipeline
[2025-10-25 10:48:09,027] INFO: Processing SENSEX data from data/sensex/*.csv
[2025-10-25 10:48:09,027] INFO: Found 1 CSV files for SENSEX
[2025-10-25 10:48:09,027] INFO: Loading data/sensex/SENSEX_01102003_23102025.csv
[2025-10-25 10:48:09,035] INFO: Combined data: 5478 rows
[2025-10-25 10:48:09,037] INFO: After cleaning: 5478 rows
[2025-10-25 10:48:09,038] WARNING: Found 2 extreme price moves for SENSEX
[2025-10-25 10:48:09,038] WARNING: Extreme moves detected (review required):
[2025-10-25 10:48:09,040] WARNING: 
           Date     Close  daily_return
2480 2013-09-06  72643.43      2.827416
2481 2013-09-10  19997.09     -0.724723
[2025-10-25 10:48:09,040] CRITICAL: âš ï¸  CRITICAL DATA QUALITY ALERT âš ï¸
[2025-10-25 10:48:09,040] CRITICAL: 2 data points with >50% daily moves detected in SENSEX!
[2025-10-25 10:48:09,040] CRITICAL: These extreme values will be INTERPOLATED - manual verification recommended:
[2025-10-25 10:48:09,040] CRITICAL:   Date: 2013-09-06 00:00:00, Close: 72643.43, Return: 282.7%
[2025-10-25 10:48:09,040] CRITICAL:   Date: 2013-09-10 00:00:00, Close: 19997.09, Return: -72.5%
[2025-10-25 10:48:09,041] CRITICAL: ðŸ“Š Extreme moves report saved to: logs/SENSEX_extreme_moves_interpolated.csv
[2025-10-25 10:48:09,041] WARNING: Interpolating 2 extreme data points...
[2025-10-25 10:48:09,043] WARNING: âœ“ Interpolation complete. Original extreme values preserved in report.
[2025-10-25 10:48:09,043] INFO: Processed SENSEX to 5478 days (keeping original trading calendar)
[2025-10-25 10:48:09,043] INFO: After resampling: 5478 rows
[2025-10-25 10:48:09,086] INFO: Saved processed SENSEX data to data/processed/sensex_clean.csv
[2025-10-25 10:48:09,086] INFO: âœ… Sensex processing completed
[2025-10-25 10:48:09,086] INFO: Processing GOLD data from data/gold/XAU_1d_data.csv
[2025-10-25 10:48:09,086] INFO: Found 1 CSV files for GOLD
[2025-10-25 10:48:09,086] INFO: Loading data/gold/XAU_1d_data.csv
[2025-10-25 10:48:09,090] INFO: Combined data: 5383 rows
[2025-10-25 10:48:09,092] INFO: After cleaning: 5383 rows
[2025-10-25 10:48:09,094] INFO: Processed GOLD to 5383 days (keeping original trading calendar)
[2025-10-25 10:48:09,094] INFO: After resampling: 5383 rows
[2025-10-25 10:48:09,118] INFO: Saved processed GOLD data to data/processed/gold_clean.csv
[2025-10-25 10:48:09,118] INFO: âœ… Gold processing completed
[2025-10-25 10:48:09,118] INFO: Data ingestion pipeline completed successfully
[2025-10-25 10:48:09,118] INFO: Step 3: Creating temporal cross-validation folds...
[2025-10-25 10:48:09,133] INFO: Data range: 2003-10-01 to 2025-10-21
[2025-10-25 10:48:09,133] INFO: Test holdout: 2024-04-21 to 2025-10-21
[2025-10-25 10:48:09,133] INFO: Available for train/val: 2003-10-01 to 2024-04-21
[2025-10-25 10:48:09,133] INFO: Total available months: 246
[2025-10-25 10:48:09,133] INFO: Training range: 120 to 245 months
[2025-10-25 10:48:09,134] INFO: Fold 0: Train 2003-10-01 to 2013-10-01 (2497 samples), Val 2013-10-01 to 2013-11-01 (21 samples), Test 2024-04-21 to 2025-10-21 (375 samples)
[2025-10-25 10:48:09,134] INFO: Fold 1: Train 2003-10-01 to 2015-03-01 (2843 samples), Val 2015-03-01 to 2015-04-01 (22 samples), Test 2024-04-21 to 2025-10-21 (375 samples)
[2025-10-25 10:48:09,135] INFO: Fold 2: Train 2003-10-01 to 2016-08-01 (3194 samples), Val 2016-08-01 to 2016-09-01 (22 samples), Test 2024-04-21 to 2025-10-21 (375 samples)
[2025-10-25 10:48:09,136] INFO: Fold 3: Train 2003-10-01 to 2018-01-01 (3546 samples), Val 2018-01-01 to 2018-02-01 (22 samples), Test 2024-04-21 to 2025-10-21 (375 samples)
[2025-10-25 10:48:09,136] INFO: Fold 4: Train 2003-10-01 to 2019-06-01 (3894 samples), Val 2019-06-01 to 2019-07-01 (20 samples), Test 2024-04-21 to 2025-10-21 (375 samples)
[2025-10-25 10:48:09,137] INFO: Fold 5: Train 2003-10-01 to 2020-11-01 (4246 samples), Val 2020-11-01 to 2020-12-01 (21 samples), Test 2024-04-21 to 2025-10-21 (375 samples)
[2025-10-25 10:48:09,138] INFO: Fold 6: Train 2003-10-01 to 2022-04-01 (4598 samples), Val 2022-04-01 to 2022-05-01 (18 samples), Test 2024-04-21 to 2025-10-21 (375 samples)
[2025-10-25 10:48:09,138] INFO: Fold 7: Train 2003-10-01 to 2023-09-01 (4950 samples), Val 2023-09-01 to 2023-10-01 (19 samples), Test 2024-04-21 to 2025-10-21 (375 samples)
[2025-10-25 10:48:09,138] INFO: Step 4: Training LSTM models...
[2025-10-25 10:48:09,138] INFO: 
=== Training SENSEX models ===
[2025-10-25 10:48:09,139] INFO: Training SENSEX fold 0
[2025-10-25 10:48:09,139] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 10:48:09,152] INFO: Calculating technical indicators...
[2025-10-25 10:48:09,152] INFO: Calculating technical indicators...
[2025-10-25 10:48:09,155] INFO: Technical indicators calculated successfully
[2025-10-25 10:48:09,155] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 10:48:09,158] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 10:48:09,162] INFO: Return statistics: mean=0.0006, std=0.0164
[2025-10-25 10:48:09,162] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 10:48:09,162] INFO: Created 2437 sequences of length 60
[2025-10-25 10:48:09,162] INFO: Feature shape: (2437, 60, 13), Target shape: (2437,)
[2025-10-25 10:48:09,172] INFO: Scalers fitted on training data
[2025-10-25 10:48:09,172] INFO: Feature scaler mean: [13782.36470963 13891.84621099 13650.9500746 ]...
[2025-10-25 10:48:09,172] INFO: Target scaler mean: 0.00, std: 0.02
[2025-10-25 10:48:09,178] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 10:48:09,182] INFO: Return statistics: mean=0.0005, std=0.0102
[2025-10-25 10:48:09,182] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 10:48:09,182] INFO: Created 2900 sequences of length 60
[2025-10-25 10:48:09,182] INFO: Feature shape: (2900, 60, 13), Target shape: (2900,)
[2025-10-25 10:48:09,190] INFO: Sequence building completed for SENSEX
[2025-10-25 10:48:09,190] INFO: Training samples: 2437
[2025-10-25 10:48:09,195] INFO: Dataset initialized: 2437 samples, seq_len=60, features=13, device=mps
[2025-10-25 10:48:09,195] INFO: Training DataLoader: 2437 samples, 19 batches of size 128
[2025-10-25 10:48:09,211] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 10:48:09,211] INFO: Created basic model with 804097 parameters
[2025-10-25 10:48:09,776] INFO: Starting training for 400 epochs
[2025-10-25 10:48:14,389] INFO: Epoch 10: Train Loss 0.9857
[2025-10-25 10:48:18,844] INFO: Epoch 20: Train Loss 0.9650
[2025-10-25 10:48:23,272] INFO: Epoch 30: Train Loss 0.8329
[2025-10-25 10:48:27,723] INFO: Epoch 40: Train Loss 0.7342
[2025-10-25 10:48:32,194] INFO: Epoch 50: Train Loss 0.5738
[2025-10-25 10:48:36,651] INFO: Epoch 60: Train Loss 0.4247
[2025-10-25 10:48:41,112] INFO: Epoch 70: Train Loss 0.3213
[2025-10-25 10:48:45,572] INFO: Epoch 80: Train Loss 0.2372
[2025-10-25 10:48:50,054] INFO: Epoch 90: Train Loss 0.1908
[2025-10-25 10:48:54,515] INFO: Epoch 100: Train Loss 0.1483
[2025-10-25 10:48:58,989] INFO: Epoch 110: Train Loss 0.1257
[2025-10-25 10:49:03,447] INFO: Epoch 120: Train Loss 0.1155
[2025-10-25 10:49:07,904] INFO: Epoch 130: Train Loss 0.0870
[2025-10-25 10:49:12,404] INFO: Epoch 140: Train Loss 0.0860
[2025-10-25 10:49:16,923] INFO: Epoch 150: Train Loss 0.0733
[2025-10-25 10:49:21,461] INFO: Epoch 160: Train Loss 0.0695
[2025-10-25 10:49:26,000] INFO: Epoch 170: Train Loss 0.0606
[2025-10-25 10:49:30,690] INFO: Epoch 180: Train Loss 0.0608
[2025-10-25 10:49:35,364] INFO: Epoch 190: Train Loss 0.0506
[2025-10-25 10:49:40,062] INFO: Epoch 200: Train Loss 0.0518
[2025-10-25 10:49:44,679] INFO: Epoch 210: Train Loss 0.0488
[2025-10-25 10:49:49,240] INFO: Epoch 220: Train Loss 0.0481
[2025-10-25 10:49:53,792] INFO: Epoch 230: Train Loss 0.0427
[2025-10-25 10:49:58,306] INFO: Epoch 240: Train Loss 0.0428
[2025-10-25 10:50:02,915] INFO: Epoch 250: Train Loss 0.0404
[2025-10-25 10:50:07,382] INFO: Epoch 260: Train Loss 0.0399
[2025-10-25 10:50:12,117] INFO: Epoch 270: Train Loss 0.0392
[2025-10-25 10:50:16,625] INFO: Epoch 280: Train Loss 0.0377
[2025-10-25 10:50:21,265] INFO: Epoch 290: Train Loss 0.0346
[2025-10-25 10:50:25,850] INFO: Epoch 300: Train Loss 0.0349
[2025-10-25 10:50:30,429] INFO: Epoch 310: Train Loss 0.0327
[2025-10-25 10:50:35,004] INFO: Epoch 320: Train Loss 0.0345
[2025-10-25 10:50:39,630] INFO: Epoch 330: Train Loss 0.0324
[2025-10-25 10:50:44,197] INFO: Epoch 340: Train Loss 0.0301
[2025-10-25 10:50:48,790] INFO: Epoch 350: Train Loss 0.0313
[2025-10-25 10:50:53,363] INFO: Epoch 360: Train Loss 0.0295
[2025-10-25 10:50:57,933] INFO: Epoch 370: Train Loss 0.0297
[2025-10-25 10:51:02,495] INFO: Epoch 380: Train Loss 0.0294
[2025-10-25 10:51:07,062] INFO: Epoch 390: Train Loss 0.0301
[2025-10-25 10:51:11,624] INFO: Epoch 400: Train Loss 0.0304
[2025-10-25 10:51:11,660] INFO: âœ… Saved artifacts for SENSEX fold 0 to models/SENSEX/fold_0
[2025-10-25 10:51:11,660] INFO:    - Features: 13
[2025-10-25 10:51:11,660] INFO:    - Sequence length: 60
[2025-10-25 10:51:11,660] INFO:    - Model parameters: 804,097
[2025-10-25 10:51:11,660] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_0
[2025-10-25 10:51:11,660] INFO: Completed SENSEX fold 0: Train samples 2437, Final train loss 0.0304
[2025-10-25 10:51:11,660] INFO: Training SENSEX fold 1
[2025-10-25 10:51:11,660] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 10:51:11,689] INFO: Calculating technical indicators...
[2025-10-25 10:51:11,690] INFO: Calculating technical indicators...
[2025-10-25 10:51:11,694] INFO: Technical indicators calculated successfully
[2025-10-25 10:51:11,694] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 10:51:11,698] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 10:51:11,708] INFO: Return statistics: mean=0.0007, std=0.0156
[2025-10-25 10:51:11,708] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 10:51:11,708] INFO: Created 2783 sequences of length 60
[2025-10-25 10:51:11,708] INFO: Feature shape: (2783, 60, 13), Target shape: (2783,)
[2025-10-25 10:51:11,724] INFO: Scalers fitted on training data
[2025-10-25 10:51:11,724] INFO: Feature scaler mean: [15004.279702   15115.13406908 14871.37997041]...
[2025-10-25 10:51:11,724] INFO: Target scaler mean: 0.00, std: 0.02
[2025-10-25 10:51:11,739] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 10:51:11,743] INFO: Return statistics: mean=0.0005, std=0.0103
[2025-10-25 10:51:11,743] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 10:51:11,743] INFO: Created 2553 sequences of length 60
[2025-10-25 10:51:11,743] INFO: Feature shape: (2553, 60, 13), Target shape: (2553,)
[2025-10-25 10:51:11,750] INFO: Sequence building completed for SENSEX
[2025-10-25 10:51:11,750] INFO: Training samples: 2783
[2025-10-25 10:51:11,752] INFO: Dataset initialized: 2783 samples, seq_len=60, features=13, device=mps
[2025-10-25 10:51:11,752] INFO: Training DataLoader: 2783 samples, 21 batches of size 128
[2025-10-25 10:51:11,770] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 10:51:11,770] INFO: Created basic model with 804097 parameters
[2025-10-25 10:51:11,772] INFO: Starting training for 400 epochs
[2025-10-25 10:51:16,814] INFO: Epoch 10: Train Loss 0.9831
[2025-10-25 10:51:21,852] INFO: Epoch 20: Train Loss 0.9342
[2025-10-25 10:51:26,890] INFO: Epoch 30: Train Loss 0.8154
[2025-10-25 10:51:31,931] INFO: Epoch 40: Train Loss 0.6658
[2025-10-25 10:51:36,976] INFO: Epoch 50: Train Loss 0.5266
[2025-10-25 10:51:42,029] INFO: Epoch 60: Train Loss 0.3902
[2025-10-25 10:51:47,085] INFO: Epoch 70: Train Loss 0.3029
[2025-10-25 10:51:52,133] INFO: Epoch 80: Train Loss 0.2132
[2025-10-25 10:51:57,179] INFO: Epoch 90: Train Loss 0.1727
[2025-10-25 10:52:02,221] INFO: Epoch 100: Train Loss 0.1408
[2025-10-25 10:52:07,265] INFO: Epoch 110: Train Loss 0.1107
[2025-10-25 10:52:12,304] INFO: Epoch 120: Train Loss 0.0967
[2025-10-25 10:52:17,360] INFO: Epoch 130: Train Loss 0.0795
[2025-10-25 10:52:22,428] INFO: Epoch 140: Train Loss 0.0747
[2025-10-25 10:52:27,541] INFO: Epoch 150: Train Loss 0.0668
[2025-10-25 10:52:32,667] INFO: Epoch 160: Train Loss 0.0581
[2025-10-25 10:52:37,784] INFO: Epoch 170: Train Loss 0.0560
[2025-10-25 10:52:42,905] INFO: Epoch 180: Train Loss 0.0488
[2025-10-25 10:52:48,047] INFO: Epoch 190: Train Loss 0.0519
[2025-10-25 10:52:53,133] INFO: Epoch 200: Train Loss 0.0469
[2025-10-25 10:52:58,240] INFO: Epoch 210: Train Loss 0.0442
[2025-10-25 10:53:03,290] INFO: Epoch 220: Train Loss 0.0442
[2025-10-25 10:53:08,330] INFO: Epoch 230: Train Loss 0.0456
[2025-10-25 10:53:13,363] INFO: Epoch 240: Train Loss 0.0401
[2025-10-25 10:53:18,410] INFO: Epoch 250: Train Loss 0.0370
[2025-10-25 10:53:23,431] INFO: Epoch 260: Train Loss 0.0366
[2025-10-25 10:53:28,481] INFO: Epoch 270: Train Loss 0.0342
[2025-10-25 10:53:33,496] INFO: Epoch 280: Train Loss 0.0353
[2025-10-25 10:53:38,535] INFO: Epoch 290: Train Loss 0.0348
[2025-10-25 10:53:43,583] INFO: Epoch 300: Train Loss 0.0320
[2025-10-25 10:53:48,603] INFO: Epoch 310: Train Loss 0.0341
[2025-10-25 10:53:53,623] INFO: Epoch 320: Train Loss 0.0310
[2025-10-25 10:53:58,684] INFO: Epoch 330: Train Loss 0.0300
[2025-10-25 10:54:03,804] INFO: Epoch 340: Train Loss 0.0314
[2025-10-25 10:54:08,935] INFO: Epoch 350: Train Loss 0.0280
[2025-10-25 10:54:14,033] INFO: Epoch 360: Train Loss 0.0294
[2025-10-25 10:54:19,093] INFO: Epoch 370: Train Loss 0.0288
[2025-10-25 10:54:24,122] INFO: Epoch 380: Train Loss 0.0289
[2025-10-25 10:54:29,175] INFO: Epoch 390: Train Loss 0.0290
[2025-10-25 10:54:34,248] INFO: Epoch 400: Train Loss 0.0284
[2025-10-25 10:54:34,272] INFO: âœ… Saved artifacts for SENSEX fold 1 to models/SENSEX/fold_1
[2025-10-25 10:54:34,272] INFO:    - Features: 13
[2025-10-25 10:54:34,272] INFO:    - Sequence length: 60
[2025-10-25 10:54:34,272] INFO:    - Model parameters: 804,097
[2025-10-25 10:54:34,272] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_1
[2025-10-25 10:54:34,272] INFO: Completed SENSEX fold 1: Train samples 2783, Final train loss 0.0284
[2025-10-25 10:54:34,272] INFO: Training SENSEX fold 2
[2025-10-25 10:54:34,272] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 10:54:34,289] INFO: Calculating technical indicators...
[2025-10-25 10:54:34,289] INFO: Calculating technical indicators...
[2025-10-25 10:54:34,292] INFO: Technical indicators calculated successfully
[2025-10-25 10:54:34,292] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 10:54:34,296] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 10:54:34,301] INFO: Return statistics: mean=0.0006, std=0.0151
[2025-10-25 10:54:34,301] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 10:54:34,301] INFO: Created 3134 sequences of length 60
[2025-10-25 10:54:34,301] INFO: Feature shape: (3134, 60, 13), Target shape: (3134,)
[2025-10-25 10:54:34,315] INFO: Scalers fitted on training data
[2025-10-25 10:54:34,315] INFO: Feature scaler mean: [16307.76355164 16420.60323951 16166.86579862]...
[2025-10-25 10:54:34,315] INFO: Target scaler mean: 0.00, std: 0.02
[2025-10-25 10:54:34,324] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 10:54:34,328] INFO: Return statistics: mean=0.0006, std=0.0104
[2025-10-25 10:54:34,328] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 10:54:34,328] INFO: Created 2202 sequences of length 60
[2025-10-25 10:54:34,328] INFO: Feature shape: (2202, 60, 13), Target shape: (2202,)
[2025-10-25 10:54:34,334] INFO: Sequence building completed for SENSEX
[2025-10-25 10:54:34,334] INFO: Training samples: 3134
[2025-10-25 10:54:34,335] INFO: Dataset initialized: 3134 samples, seq_len=60, features=13, device=mps
[2025-10-25 10:54:34,335] INFO: Training DataLoader: 3134 samples, 24 batches of size 128
[2025-10-25 10:54:34,351] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 10:54:34,351] INFO: Created basic model with 804097 parameters
[2025-10-25 10:54:34,358] INFO: Starting training for 400 epochs
[2025-10-25 10:54:40,061] INFO: Epoch 10: Train Loss 0.9812
[2025-10-25 10:54:45,780] INFO: Epoch 20: Train Loss 0.9309
[2025-10-25 10:54:51,595] INFO: Epoch 30: Train Loss 0.8471
[2025-10-25 10:54:57,412] INFO: Epoch 40: Train Loss 0.6722
[2025-10-25 10:55:03,245] INFO: Epoch 50: Train Loss 0.5255
[2025-10-25 10:55:09,031] INFO: Epoch 60: Train Loss 0.3646
[2025-10-25 10:55:14,783] INFO: Epoch 70: Train Loss 0.2748
[2025-10-25 10:55:20,545] INFO: Epoch 80: Train Loss 0.2090
[2025-10-25 10:55:26,343] INFO: Epoch 90: Train Loss 0.1578
[2025-10-25 10:55:32,119] INFO: Epoch 100: Train Loss 0.1224
[2025-10-25 10:55:37,869] INFO: Epoch 110: Train Loss 0.1064
[2025-10-25 10:55:43,636] INFO: Epoch 120: Train Loss 0.0930
[2025-10-25 10:55:49,393] INFO: Epoch 130: Train Loss 0.0808
[2025-10-25 10:55:55,151] INFO: Epoch 140: Train Loss 0.0774
[2025-10-25 10:56:00,901] INFO: Epoch 150: Train Loss 0.0655
[2025-10-25 10:56:06,656] INFO: Epoch 160: Train Loss 0.0618
[2025-10-25 10:56:12,401] INFO: Epoch 170: Train Loss 0.0599
[2025-10-25 10:56:18,164] INFO: Epoch 180: Train Loss 0.0483
[2025-10-25 10:56:23,924] INFO: Epoch 190: Train Loss 0.0498
[2025-10-25 10:56:29,689] INFO: Epoch 200: Train Loss 0.0461
[2025-10-25 10:56:35,452] INFO: Epoch 210: Train Loss 0.0437
[2025-10-25 10:56:41,214] INFO: Epoch 220: Train Loss 0.0407
[2025-10-25 10:56:47,003] INFO: Epoch 230: Train Loss 0.0423
[2025-10-25 10:56:52,742] INFO: Epoch 240: Train Loss 0.0370
[2025-10-25 10:56:58,460] INFO: Epoch 250: Train Loss 0.0354
[2025-10-25 10:57:04,180] INFO: Epoch 260: Train Loss 0.0363
[2025-10-25 10:57:09,932] INFO: Epoch 270: Train Loss 0.0330
[2025-10-25 10:57:15,758] INFO: Epoch 280: Train Loss 0.0327
[2025-10-25 10:57:21,447] INFO: Epoch 290: Train Loss 0.0325
[2025-10-25 10:57:27,122] INFO: Epoch 300: Train Loss 0.0309
[2025-10-25 10:57:32,792] INFO: Epoch 310: Train Loss 0.0303
[2025-10-25 10:57:38,479] INFO: Epoch 320: Train Loss 0.0284
[2025-10-25 10:57:44,259] INFO: Epoch 330: Train Loss 0.0295
[2025-10-25 10:57:49,903] INFO: Epoch 340: Train Loss 0.0296
[2025-10-25 10:57:55,572] INFO: Epoch 350: Train Loss 0.0280
[2025-10-25 10:58:01,259] INFO: Epoch 360: Train Loss 0.0273
[2025-10-25 10:58:06,942] INFO: Epoch 370: Train Loss 0.0272
[2025-10-25 10:58:12,594] INFO: Epoch 380: Train Loss 0.0273
[2025-10-25 10:58:18,299] INFO: Epoch 390: Train Loss 0.0250
[2025-10-25 10:58:23,943] INFO: Epoch 400: Train Loss 0.0281
[2025-10-25 10:58:23,968] INFO: âœ… Saved artifacts for SENSEX fold 2 to models/SENSEX/fold_2
[2025-10-25 10:58:23,968] INFO:    - Features: 13
[2025-10-25 10:58:23,968] INFO:    - Sequence length: 60
[2025-10-25 10:58:23,968] INFO:    - Model parameters: 804,097
[2025-10-25 10:58:23,968] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_2
[2025-10-25 10:58:23,968] INFO: Completed SENSEX fold 2: Train samples 3134, Final train loss 0.0281
[2025-10-25 10:58:23,968] INFO: Training SENSEX fold 3
[2025-10-25 10:58:23,968] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 10:58:23,991] INFO: Calculating technical indicators...
[2025-10-25 10:58:23,991] INFO: Calculating technical indicators...
[2025-10-25 10:58:23,995] INFO: Technical indicators calculated successfully
[2025-10-25 10:58:23,996] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 10:58:24,000] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 10:58:24,007] INFO: Return statistics: mean=0.0006, std=0.0145
[2025-10-25 10:58:24,007] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 10:58:24,007] INFO: Created 3486 sequences of length 60
[2025-10-25 10:58:24,007] INFO: Feature shape: (3486, 60, 13), Target shape: (3486,)
[2025-10-25 10:58:24,025] INFO: Scalers fitted on training data
[2025-10-25 10:58:24,025] INFO: Feature scaler mean: [17632.32093987 17744.06913205 17491.28671907]...
[2025-10-25 10:58:24,025] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 10:58:24,038] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 10:58:24,042] INFO: Return statistics: mean=0.0005, std=0.0111
[2025-10-25 10:58:24,042] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 10:58:24,042] INFO: Created 1850 sequences of length 60
[2025-10-25 10:58:24,042] INFO: Feature shape: (1850, 60, 13), Target shape: (1850,)
[2025-10-25 10:58:24,048] INFO: Sequence building completed for SENSEX
[2025-10-25 10:58:24,049] INFO: Training samples: 3486
[2025-10-25 10:58:24,050] INFO: Dataset initialized: 3486 samples, seq_len=60, features=13, device=mps
[2025-10-25 10:58:24,050] INFO: Training DataLoader: 3486 samples, 27 batches of size 128
[2025-10-25 10:58:24,068] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 10:58:24,068] INFO: Created basic model with 804097 parameters
[2025-10-25 10:58:24,071] INFO: Starting training for 400 epochs
[2025-10-25 10:58:30,415] INFO: Epoch 10: Train Loss 0.9879
[2025-10-25 10:58:36,861] INFO: Epoch 20: Train Loss 0.9351
[2025-10-25 10:58:43,522] INFO: Epoch 30: Train Loss 0.8028
[2025-10-25 10:58:50,537] INFO: Epoch 40: Train Loss 0.6047
[2025-10-25 10:58:57,087] INFO: Epoch 50: Train Loss 0.4207
[2025-10-25 10:59:03,552] INFO: Epoch 60: Train Loss 0.3009
[2025-10-25 10:59:10,038] INFO: Epoch 70: Train Loss 0.2057
[2025-10-25 10:59:16,513] INFO: Epoch 80: Train Loss 0.1562
[2025-10-25 10:59:22,979] INFO: Epoch 90: Train Loss 0.1238
[2025-10-25 10:59:29,464] INFO: Epoch 100: Train Loss 0.1075
[2025-10-25 10:59:35,941] INFO: Epoch 110: Train Loss 0.0948
[2025-10-25 10:59:42,413] INFO: Epoch 120: Train Loss 0.0832
[2025-10-25 10:59:48,909] INFO: Epoch 130: Train Loss 0.0692
[2025-10-25 10:59:55,670] INFO: Epoch 140: Train Loss 0.0651
[2025-10-25 11:00:02,476] INFO: Epoch 150: Train Loss 0.0571
[2025-10-25 11:00:09,005] INFO: Epoch 160: Train Loss 0.0541
[2025-10-25 11:00:15,491] INFO: Epoch 170: Train Loss 0.0489
[2025-10-25 11:00:21,942] INFO: Epoch 180: Train Loss 0.0493
[2025-10-25 11:00:28,431] INFO: Epoch 190: Train Loss 0.0447
[2025-10-25 11:00:34,900] INFO: Epoch 200: Train Loss 0.0422
[2025-10-25 11:00:41,393] INFO: Epoch 210: Train Loss 0.0383
[2025-10-25 11:00:47,865] INFO: Epoch 220: Train Loss 0.0377
[2025-10-25 11:00:54,329] INFO: Epoch 230: Train Loss 0.0356
[2025-10-25 11:01:00,787] INFO: Epoch 240: Train Loss 0.0349
[2025-10-25 11:01:07,253] INFO: Epoch 250: Train Loss 0.0326
[2025-10-25 11:01:13,716] INFO: Epoch 260: Train Loss 0.0305
[2025-10-25 11:01:20,200] INFO: Epoch 270: Train Loss 0.0316
[2025-10-25 11:01:26,668] INFO: Epoch 280: Train Loss 0.0289
[2025-10-25 11:01:33,127] INFO: Epoch 290: Train Loss 0.0290
[2025-10-25 11:01:39,619] INFO: Epoch 300: Train Loss 0.0281
[2025-10-25 11:01:46,074] INFO: Epoch 310: Train Loss 0.0270
[2025-10-25 11:01:52,542] INFO: Epoch 320: Train Loss 0.0257
[2025-10-25 11:01:59,039] INFO: Epoch 330: Train Loss 0.0263
[2025-10-25 11:02:05,491] INFO: Epoch 340: Train Loss 0.0254
[2025-10-25 11:02:11,964] INFO: Epoch 350: Train Loss 0.0253
[2025-10-25 11:02:18,442] INFO: Epoch 360: Train Loss 0.0245
[2025-10-25 11:02:24,918] INFO: Epoch 370: Train Loss 0.0233
[2025-10-25 11:02:31,411] INFO: Epoch 380: Train Loss 0.0241
[2025-10-25 11:02:37,878] INFO: Epoch 390: Train Loss 0.0247
[2025-10-25 11:02:44,345] INFO: Epoch 400: Train Loss 0.0245
[2025-10-25 11:02:44,368] INFO: âœ… Saved artifacts for SENSEX fold 3 to models/SENSEX/fold_3
[2025-10-25 11:02:44,368] INFO:    - Features: 13
[2025-10-25 11:02:44,368] INFO:    - Sequence length: 60
[2025-10-25 11:02:44,368] INFO:    - Model parameters: 804,097
[2025-10-25 11:02:44,368] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_3
[2025-10-25 11:02:44,368] INFO: Completed SENSEX fold 3: Train samples 3486, Final train loss 0.0245
[2025-10-25 11:02:44,368] INFO: Training SENSEX fold 4
[2025-10-25 11:02:44,369] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 11:02:44,396] INFO: Calculating technical indicators...
[2025-10-25 11:02:44,396] INFO: Calculating technical indicators...
[2025-10-25 11:02:44,402] INFO: Technical indicators calculated successfully
[2025-10-25 11:02:44,403] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 11:02:44,409] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:02:44,415] INFO: Return statistics: mean=0.0006, std=0.0140
[2025-10-25 11:02:44,415] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 11:02:44,416] INFO: Created 3834 sequences of length 60
[2025-10-25 11:02:44,416] INFO: Feature shape: (3834, 60, 13), Target shape: (3834,)
[2025-10-25 11:02:44,433] INFO: Scalers fitted on training data
[2025-10-25 11:02:44,434] INFO: Feature scaler mean: [19262.07031725 19376.36006885 19114.2307869 ]...
[2025-10-25 11:02:44,434] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:02:44,444] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:02:44,447] INFO: Return statistics: mean=0.0006, std=0.0115
[2025-10-25 11:02:44,447] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 11:02:44,447] INFO: Created 1504 sequences of length 60
[2025-10-25 11:02:44,447] INFO: Feature shape: (1504, 60, 13), Target shape: (1504,)
[2025-10-25 11:02:44,451] INFO: Sequence building completed for SENSEX
[2025-10-25 11:02:44,451] INFO: Training samples: 3834
[2025-10-25 11:02:44,455] INFO: Dataset initialized: 3834 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:02:44,456] INFO: Training DataLoader: 3834 samples, 29 batches of size 128
[2025-10-25 11:02:44,481] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:02:44,482] INFO: Created basic model with 804097 parameters
[2025-10-25 11:02:44,488] INFO: Starting training for 400 epochs
[2025-10-25 11:02:51,503] INFO: Epoch 10: Train Loss 0.9777
[2025-10-25 11:02:58,500] INFO: Epoch 20: Train Loss 0.9465
[2025-10-25 11:03:05,495] INFO: Epoch 30: Train Loss 0.8222
[2025-10-25 11:03:12,508] INFO: Epoch 40: Train Loss 0.6921
[2025-10-25 11:03:19,519] INFO: Epoch 50: Train Loss 0.4958
[2025-10-25 11:03:26,504] INFO: Epoch 60: Train Loss 0.3536
[2025-10-25 11:03:33,516] INFO: Epoch 70: Train Loss 0.2439
[2025-10-25 11:03:40,532] INFO: Epoch 80: Train Loss 0.1739
[2025-10-25 11:03:47,512] INFO: Epoch 90: Train Loss 0.1468
[2025-10-25 11:03:54,519] INFO: Epoch 100: Train Loss 0.1186
[2025-10-25 11:04:01,535] INFO: Epoch 110: Train Loss 0.0954
[2025-10-25 11:04:08,520] INFO: Epoch 120: Train Loss 0.0854
[2025-10-25 11:04:15,523] INFO: Epoch 130: Train Loss 0.0804
[2025-10-25 11:04:22,544] INFO: Epoch 140: Train Loss 0.0695
[2025-10-25 11:04:29,539] INFO: Epoch 150: Train Loss 0.0617
[2025-10-25 11:04:36,529] INFO: Epoch 160: Train Loss 0.0546
[2025-10-25 11:04:43,543] INFO: Epoch 170: Train Loss 0.0553
[2025-10-25 11:04:50,547] INFO: Epoch 180: Train Loss 0.0535
[2025-10-25 11:04:57,531] INFO: Epoch 190: Train Loss 0.0495
[2025-10-25 11:05:04,710] INFO: Epoch 200: Train Loss 0.0433
[2025-10-25 11:05:11,726] INFO: Epoch 210: Train Loss 0.0433
[2025-10-25 11:05:18,712] INFO: Epoch 220: Train Loss 0.0405
[2025-10-25 11:05:25,710] INFO: Epoch 230: Train Loss 0.0389
[2025-10-25 11:05:32,721] INFO: Epoch 240: Train Loss 0.0377
[2025-10-25 11:05:39,712] INFO: Epoch 250: Train Loss 0.0349
[2025-10-25 11:05:46,717] INFO: Epoch 260: Train Loss 0.0356
[2025-10-25 11:05:53,722] INFO: Epoch 270: Train Loss 0.0325
[2025-10-25 11:06:00,735] INFO: Epoch 280: Train Loss 0.0315
[2025-10-25 11:06:07,717] INFO: Epoch 290: Train Loss 0.0299
[2025-10-25 11:06:14,731] INFO: Epoch 300: Train Loss 0.0309
[2025-10-25 11:06:21,743] INFO: Epoch 310: Train Loss 0.0289
[2025-10-25 11:06:28,737] INFO: Epoch 320: Train Loss 0.0283
[2025-10-25 11:06:35,738] INFO: Epoch 330: Train Loss 0.0279
[2025-10-25 11:06:42,755] INFO: Epoch 340: Train Loss 0.0277
[2025-10-25 11:06:49,760] INFO: Epoch 350: Train Loss 0.0260
[2025-10-25 11:06:56,768] INFO: Epoch 360: Train Loss 0.0254
[2025-10-25 11:07:03,783] INFO: Epoch 370: Train Loss 0.0256
[2025-10-25 11:07:10,772] INFO: Epoch 380: Train Loss 0.0261
[2025-10-25 11:07:17,765] INFO: Epoch 390: Train Loss 0.0263
[2025-10-25 11:07:24,778] INFO: Epoch 400: Train Loss 0.0247
[2025-10-25 11:07:24,799] INFO: âœ… Saved artifacts for SENSEX fold 4 to models/SENSEX/fold_4
[2025-10-25 11:07:24,799] INFO:    - Features: 13
[2025-10-25 11:07:24,799] INFO:    - Sequence length: 60
[2025-10-25 11:07:24,799] INFO:    - Model parameters: 804,097
[2025-10-25 11:07:24,799] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_4
[2025-10-25 11:07:24,799] INFO: Completed SENSEX fold 4: Train samples 3834, Final train loss 0.0247
[2025-10-25 11:07:24,799] INFO: Training SENSEX fold 5
[2025-10-25 11:07:24,799] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 11:07:24,818] INFO: Calculating technical indicators...
[2025-10-25 11:07:24,819] INFO: Calculating technical indicators...
[2025-10-25 11:07:24,822] INFO: Technical indicators calculated successfully
[2025-10-25 11:07:24,823] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 11:07:24,827] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:07:24,834] INFO: Return statistics: mean=0.0006, std=0.0144
[2025-10-25 11:07:24,834] INFO: Return range: [-0.1315, 0.1734]
[2025-10-25 11:07:24,834] INFO: Created 4186 sequences of length 60
[2025-10-25 11:07:24,834] INFO: Feature shape: (4186, 60, 13), Target shape: (4186,)
[2025-10-25 11:07:24,857] INFO: Scalers fitted on training data
[2025-10-25 11:07:24,857] INFO: Feature scaler mean: [20805.21256398 20929.1907754  20640.28153673]...
[2025-10-25 11:07:24,857] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:07:24,869] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:07:24,870] INFO: Return statistics: mean=0.0005, std=0.0088
[2025-10-25 11:07:24,870] INFO: Return range: [-0.0574, 0.0374]
[2025-10-25 11:07:24,870] INFO: Created 1151 sequences of length 60
[2025-10-25 11:07:24,870] INFO: Feature shape: (1151, 60, 13), Target shape: (1151,)
[2025-10-25 11:07:24,874] INFO: Sequence building completed for SENSEX
[2025-10-25 11:07:24,874] INFO: Training samples: 4186
[2025-10-25 11:07:24,876] INFO: Dataset initialized: 4186 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:07:24,876] INFO: Training DataLoader: 4186 samples, 32 batches of size 128
[2025-10-25 11:07:24,894] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:07:24,894] INFO: Created basic model with 804097 parameters
[2025-10-25 11:07:24,900] INFO: Starting training for 400 epochs
[2025-10-25 11:07:32,596] INFO: Epoch 10: Train Loss 0.9963
[2025-10-25 11:07:40,252] INFO: Epoch 20: Train Loss 0.9673
[2025-10-25 11:07:47,912] INFO: Epoch 30: Train Loss 0.8419
[2025-10-25 11:07:55,602] INFO: Epoch 40: Train Loss 0.6949
[2025-10-25 11:08:03,308] INFO: Epoch 50: Train Loss 0.4689
[2025-10-25 11:08:10,974] INFO: Epoch 60: Train Loss 0.3071
[2025-10-25 11:08:18,659] INFO: Epoch 70: Train Loss 0.2051
[2025-10-25 11:08:26,358] INFO: Epoch 80: Train Loss 0.1559
[2025-10-25 11:08:34,039] INFO: Epoch 90: Train Loss 0.1197
[2025-10-25 11:08:41,731] INFO: Epoch 100: Train Loss 0.0961
[2025-10-25 11:08:49,413] INFO: Epoch 110: Train Loss 0.0835
[2025-10-25 11:08:57,116] INFO: Epoch 120: Train Loss 0.0755
[2025-10-25 11:09:04,882] INFO: Epoch 130: Train Loss 0.0679
[2025-10-25 11:09:12,584] INFO: Epoch 140: Train Loss 0.0631
[2025-10-25 11:09:20,264] INFO: Epoch 150: Train Loss 0.0572
[2025-10-25 11:09:27,963] INFO: Epoch 160: Train Loss 0.0565
[2025-10-25 11:09:35,676] INFO: Epoch 170: Train Loss 0.0461
[2025-10-25 11:09:43,362] INFO: Epoch 180: Train Loss 0.0457
[2025-10-25 11:09:51,087] INFO: Epoch 190: Train Loss 0.0451
[2025-10-25 11:09:58,770] INFO: Epoch 200: Train Loss 0.0402
[2025-10-25 11:10:06,481] INFO: Epoch 210: Train Loss 0.0373
[2025-10-25 11:10:14,204] INFO: Epoch 220: Train Loss 0.0388
[2025-10-25 11:10:21,895] INFO: Epoch 230: Train Loss 0.0363
[2025-10-25 11:10:29,590] INFO: Epoch 240: Train Loss 0.0347
[2025-10-25 11:10:37,315] INFO: Epoch 250: Train Loss 0.0328
[2025-10-25 11:10:45,028] INFO: Epoch 260: Train Loss 0.0325
[2025-10-25 11:10:52,722] INFO: Epoch 270: Train Loss 0.0306
[2025-10-25 11:11:00,397] INFO: Epoch 280: Train Loss 0.0282
[2025-10-25 11:11:08,085] INFO: Epoch 290: Train Loss 0.0282
[2025-10-25 11:11:15,790] INFO: Epoch 300: Train Loss 0.0281
[2025-10-25 11:11:23,505] INFO: Epoch 310: Train Loss 0.0271
[2025-10-25 11:11:31,202] INFO: Epoch 320: Train Loss 0.0255
[2025-10-25 11:11:38,901] INFO: Epoch 330: Train Loss 0.0253
[2025-10-25 11:11:46,626] INFO: Epoch 340: Train Loss 0.0243
[2025-10-25 11:11:54,326] INFO: Epoch 350: Train Loss 0.0249
[2025-10-25 11:12:02,025] INFO: Epoch 360: Train Loss 0.0244
[2025-10-25 11:12:09,748] INFO: Epoch 370: Train Loss 0.0236
[2025-10-25 11:12:17,467] INFO: Epoch 380: Train Loss 0.0240
[2025-10-25 11:12:25,166] INFO: Epoch 390: Train Loss 0.0235
[2025-10-25 11:12:32,882] INFO: Epoch 400: Train Loss 0.0235
[2025-10-25 11:12:32,908] INFO: âœ… Saved artifacts for SENSEX fold 5 to models/SENSEX/fold_5
[2025-10-25 11:12:32,908] INFO:    - Features: 13
[2025-10-25 11:12:32,908] INFO:    - Sequence length: 60
[2025-10-25 11:12:32,908] INFO:    - Model parameters: 804,097
[2025-10-25 11:12:32,909] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_5
[2025-10-25 11:12:32,909] INFO: Completed SENSEX fold 5: Train samples 4186, Final train loss 0.0235
[2025-10-25 11:12:32,909] INFO: Training SENSEX fold 6
[2025-10-25 11:12:32,909] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 11:12:32,931] INFO: Calculating technical indicators...
[2025-10-25 11:12:32,931] INFO: Calculating technical indicators...
[2025-10-25 11:12:32,935] INFO: Technical indicators calculated successfully
[2025-10-25 11:12:32,935] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 11:12:32,939] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:12:32,947] INFO: Return statistics: mean=0.0006, std=0.0141
[2025-10-25 11:12:32,947] INFO: Return range: [-0.1315, 0.1734]
[2025-10-25 11:12:32,947] INFO: Created 4538 sequences of length 60
[2025-10-25 11:12:32,947] INFO: Feature shape: (4538, 60, 13), Target shape: (4538,)
[2025-10-25 11:12:32,975] INFO: Scalers fitted on training data
[2025-10-25 11:12:32,975] INFO: Feature scaler mean: [23220.00832518 23353.86013924 23037.84009682]...
[2025-10-25 11:12:32,975] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:12:32,987] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:12:32,989] INFO: Return statistics: mean=0.0005, std=0.0078
[2025-10-25 11:12:32,989] INFO: Return range: [-0.0574, 0.0374]
[2025-10-25 11:12:32,989] INFO: Created 802 sequences of length 60
[2025-10-25 11:12:32,989] INFO: Feature shape: (802, 60, 13), Target shape: (802,)
[2025-10-25 11:12:32,991] INFO: Sequence building completed for SENSEX
[2025-10-25 11:12:32,991] INFO: Training samples: 4538
[2025-10-25 11:12:32,993] INFO: Dataset initialized: 4538 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:12:32,994] INFO: Training DataLoader: 4538 samples, 35 batches of size 128
[2025-10-25 11:12:33,012] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:12:33,012] INFO: Created basic model with 804097 parameters
[2025-10-25 11:12:33,017] INFO: Starting training for 400 epochs
[2025-10-25 11:12:41,488] INFO: Epoch 10: Train Loss 0.9933
[2025-10-25 11:12:49,977] INFO: Epoch 20: Train Loss 0.9474
[2025-10-25 11:12:58,500] INFO: Epoch 30: Train Loss 0.8345
[2025-10-25 11:13:06,999] INFO: Epoch 40: Train Loss 0.6352
[2025-10-25 11:13:15,507] INFO: Epoch 50: Train Loss 0.4369
[2025-10-25 11:13:23,987] INFO: Epoch 60: Train Loss 0.2927
[2025-10-25 11:13:32,448] INFO: Epoch 70: Train Loss 0.2028
[2025-10-25 11:13:40,955] INFO: Epoch 80: Train Loss 0.1481
[2025-10-25 11:13:49,439] INFO: Epoch 90: Train Loss 0.1222
[2025-10-25 11:13:57,954] INFO: Epoch 100: Train Loss 0.0990
[2025-10-25 11:14:06,462] INFO: Epoch 110: Train Loss 0.0787
[2025-10-25 11:14:14,945] INFO: Epoch 120: Train Loss 0.0775
[2025-10-25 11:14:23,449] INFO: Epoch 130: Train Loss 0.0667
[2025-10-25 11:14:31,921] INFO: Epoch 140: Train Loss 0.0606
[2025-10-25 11:14:40,418] INFO: Epoch 150: Train Loss 0.0536
[2025-10-25 11:14:48,927] INFO: Epoch 160: Train Loss 0.0521
[2025-10-25 11:14:57,415] INFO: Epoch 170: Train Loss 0.0483
[2025-10-25 11:15:05,912] INFO: Epoch 180: Train Loss 0.0462
[2025-10-25 11:15:14,417] INFO: Epoch 190: Train Loss 0.0452
[2025-10-25 11:15:22,920] INFO: Epoch 200: Train Loss 0.0423
[2025-10-25 11:15:31,425] INFO: Epoch 210: Train Loss 0.0395
[2025-10-25 11:15:39,934] INFO: Epoch 220: Train Loss 0.0370
[2025-10-25 11:15:48,437] INFO: Epoch 230: Train Loss 0.0359
[2025-10-25 11:15:57,036] INFO: Epoch 240: Train Loss 0.0349
[2025-10-25 11:16:05,751] INFO: Epoch 250: Train Loss 0.0334
[2025-10-25 11:16:14,244] INFO: Epoch 260: Train Loss 0.0328
[2025-10-25 11:16:22,748] INFO: Epoch 270: Train Loss 0.0307
[2025-10-25 11:16:31,248] INFO: Epoch 280: Train Loss 0.0292
[2025-10-25 11:16:39,725] INFO: Epoch 290: Train Loss 0.0288
[2025-10-25 11:16:48,201] INFO: Epoch 300: Train Loss 0.0267
[2025-10-25 11:16:56,678] INFO: Epoch 310: Train Loss 0.0271
[2025-10-25 11:17:05,171] INFO: Epoch 320: Train Loss 0.0258
[2025-10-25 11:17:13,658] INFO: Epoch 330: Train Loss 0.0268
[2025-10-25 11:17:22,155] INFO: Epoch 340: Train Loss 0.0268
[2025-10-25 11:17:30,639] INFO: Epoch 350: Train Loss 0.0250
[2025-10-25 11:17:39,099] INFO: Epoch 360: Train Loss 0.0257
[2025-10-25 11:17:47,629] INFO: Epoch 370: Train Loss 0.0246
[2025-10-25 11:17:56,036] INFO: Epoch 380: Train Loss 0.0240
[2025-10-25 11:18:04,446] INFO: Epoch 390: Train Loss 0.0245
[2025-10-25 11:18:12,858] INFO: Epoch 400: Train Loss 0.0243
[2025-10-25 11:18:12,885] INFO: âœ… Saved artifacts for SENSEX fold 6 to models/SENSEX/fold_6
[2025-10-25 11:18:12,885] INFO:    - Features: 13
[2025-10-25 11:18:12,885] INFO:    - Sequence length: 60
[2025-10-25 11:18:12,885] INFO:    - Model parameters: 804,097
[2025-10-25 11:18:12,885] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_6
[2025-10-25 11:18:12,885] INFO: Completed SENSEX fold 6: Train samples 4538, Final train loss 0.0243
[2025-10-25 11:18:12,886] INFO: Training SENSEX fold 7
[2025-10-25 11:18:12,886] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 11:18:12,908] INFO: Calculating technical indicators...
[2025-10-25 11:18:12,908] INFO: Calculating technical indicators...
[2025-10-25 11:18:12,912] INFO: Technical indicators calculated successfully
[2025-10-25 11:18:12,913] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 11:18:12,917] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:18:12,927] INFO: Return statistics: mean=0.0006, std=0.0138
[2025-10-25 11:18:12,927] INFO: Return range: [-0.1315, 0.1734]
[2025-10-25 11:18:12,927] INFO: Created 4890 sequences of length 60
[2025-10-25 11:18:12,927] INFO: Feature shape: (4890, 60, 13), Target shape: (4890,)
[2025-10-25 11:18:12,950] INFO: Scalers fitted on training data
[2025-10-25 11:18:12,950] INFO: Feature scaler mean: [25803.67137741 25949.52477043 25611.12103095]...
[2025-10-25 11:18:12,950] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:18:12,963] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:18:12,963] INFO: Return statistics: mean=0.0004, std=0.0084
[2025-10-25 11:18:12,963] INFO: Return range: [-0.0574, 0.0374]
[2025-10-25 11:18:12,963] INFO: Created 449 sequences of length 60
[2025-10-25 11:18:12,963] INFO: Feature shape: (449, 60, 13), Target shape: (449,)
[2025-10-25 11:18:12,964] INFO: Sequence building completed for SENSEX
[2025-10-25 11:18:12,964] INFO: Training samples: 4890
[2025-10-25 11:18:12,966] INFO: Dataset initialized: 4890 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:18:12,966] INFO: Training DataLoader: 4890 samples, 38 batches of size 128
[2025-10-25 11:18:12,982] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:18:12,982] INFO: Created basic model with 804097 parameters
[2025-10-25 11:18:12,985] INFO: Starting training for 400 epochs
[2025-10-25 11:18:22,004] INFO: Epoch 10: Train Loss 0.9926
[2025-10-25 11:18:31,042] INFO: Epoch 20: Train Loss 0.9423
[2025-10-25 11:18:40,094] INFO: Epoch 30: Train Loss 0.8061
[2025-10-25 11:18:49,142] INFO: Epoch 40: Train Loss 0.6106
[2025-10-25 11:18:58,174] INFO: Epoch 50: Train Loss 0.4161
[2025-10-25 11:19:07,204] INFO: Epoch 60: Train Loss 0.2727
[2025-10-25 11:19:16,239] INFO: Epoch 70: Train Loss 0.1880
[2025-10-25 11:19:25,293] INFO: Epoch 80: Train Loss 0.1466
[2025-10-25 11:19:34,340] INFO: Epoch 90: Train Loss 0.1137
[2025-10-25 11:19:43,394] INFO: Epoch 100: Train Loss 0.0924
[2025-10-25 11:19:52,318] INFO: Epoch 110: Train Loss 0.0803
[2025-10-25 11:20:01,324] INFO: Epoch 120: Train Loss 0.0743
[2025-10-25 11:20:10,383] INFO: Epoch 130: Train Loss 0.0728
[2025-10-25 11:20:19,436] INFO: Epoch 140: Train Loss 0.0589
[2025-10-25 11:20:28,475] INFO: Epoch 150: Train Loss 0.0536
[2025-10-25 11:20:37,530] INFO: Epoch 160: Train Loss 0.0493
[2025-10-25 11:20:46,576] INFO: Epoch 170: Train Loss 0.0476
[2025-10-25 11:20:55,625] INFO: Epoch 180: Train Loss 0.0436
[2025-10-25 11:21:04,644] INFO: Epoch 190: Train Loss 0.0442
[2025-10-25 11:21:13,693] INFO: Epoch 200: Train Loss 0.0404
[2025-10-25 11:21:22,739] INFO: Epoch 210: Train Loss 0.0397
[2025-10-25 11:21:31,793] INFO: Epoch 220: Train Loss 0.0369
[2025-10-25 11:21:40,859] INFO: Epoch 230: Train Loss 0.0364
[2025-10-25 11:21:49,915] INFO: Epoch 240: Train Loss 0.0313
[2025-10-25 11:21:58,970] INFO: Epoch 250: Train Loss 0.0323
[2025-10-25 11:22:08,008] INFO: Epoch 260: Train Loss 0.0329
[2025-10-25 11:22:17,068] INFO: Epoch 270: Train Loss 0.0302
[2025-10-25 11:22:26,119] INFO: Epoch 280: Train Loss 0.0293
[2025-10-25 11:22:35,172] INFO: Epoch 290: Train Loss 0.0273
[2025-10-25 11:22:44,223] INFO: Epoch 300: Train Loss 0.0277
[2025-10-25 11:22:53,277] INFO: Epoch 310: Train Loss 0.0271
[2025-10-25 11:23:02,331] INFO: Epoch 320: Train Loss 0.0264
[2025-10-25 11:23:11,387] INFO: Epoch 330: Train Loss 0.0262
[2025-10-25 11:23:20,437] INFO: Epoch 340: Train Loss 0.0255
[2025-10-25 11:23:29,474] INFO: Epoch 350: Train Loss 0.0259
[2025-10-25 11:23:38,512] INFO: Epoch 360: Train Loss 0.0247
[2025-10-25 11:23:47,572] INFO: Epoch 370: Train Loss 0.0254
[2025-10-25 11:23:56,627] INFO: Epoch 380: Train Loss 0.0241
[2025-10-25 11:24:05,685] INFO: Epoch 390: Train Loss 0.0239
[2025-10-25 11:24:14,747] INFO: Epoch 400: Train Loss 0.0246
[2025-10-25 11:24:14,776] INFO: âœ… Saved artifacts for SENSEX fold 7 to models/SENSEX/fold_7
[2025-10-25 11:24:14,776] INFO:    - Features: 13
[2025-10-25 11:24:14,776] INFO:    - Sequence length: 60
[2025-10-25 11:24:14,776] INFO:    - Model parameters: 804,097
[2025-10-25 11:24:14,776] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_7
[2025-10-25 11:24:14,776] INFO: Completed SENSEX fold 7: Train samples 4890, Final train loss 0.0246
[2025-10-25 11:24:14,777] INFO: SENSEX summary: Avg train loss 0.0261, Avg val loss nan
[2025-10-25 11:24:14,777] INFO: 
=== Training GOLD models ===
[2025-10-25 11:24:14,777] INFO: Training GOLD fold 0
[2025-10-25 11:24:14,778] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 11:24:14,796] INFO: Calculating technical indicators...
[2025-10-25 11:24:14,796] INFO: Calculating technical indicators...
[2025-10-25 11:24:14,799] INFO: Technical indicators calculated successfully
[2025-10-25 11:24:14,800] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 11:24:14,805] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:24:14,809] INFO: Return statistics: mean=0.0006, std=0.0128
[2025-10-25 11:24:14,809] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 11:24:14,809] INFO: Created 2318 sequences of length 60
[2025-10-25 11:24:14,809] INFO: Feature shape: (2318, 60, 13), Target shape: (2318,)
[2025-10-25 11:24:14,823] INFO: Scalers fitted on training data
[2025-10-25 11:24:14,823] INFO: Feature scaler mean: [1013.89488335 1022.45891816 1004.58627231]...
[2025-10-25 11:24:14,823] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:24:14,832] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:24:14,835] INFO: Return statistics: mean=0.0004, std=0.0093
[2025-10-25 11:24:14,835] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 11:24:14,835] INFO: Created 2922 sequences of length 60
[2025-10-25 11:24:14,835] INFO: Feature shape: (2922, 60, 13), Target shape: (2922,)
[2025-10-25 11:24:14,844] INFO: Sequence building completed for GOLD
[2025-10-25 11:24:14,844] INFO: Training samples: 2318
[2025-10-25 11:24:14,846] INFO: Dataset initialized: 2318 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:24:14,846] INFO: Training DataLoader: 2318 samples, 18 batches of size 128
[2025-10-25 11:24:14,862] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:24:14,862] INFO: Created basic model with 804097 parameters
[2025-10-25 11:24:14,869] INFO: Starting training for 400 epochs
[2025-10-25 11:24:19,139] INFO: Epoch 10: Train Loss 0.9898
[2025-10-25 11:24:23,459] INFO: Epoch 20: Train Loss 0.9354
[2025-10-25 11:24:27,782] INFO: Epoch 30: Train Loss 0.8178
[2025-10-25 11:24:32,102] INFO: Epoch 40: Train Loss 0.6537
[2025-10-25 11:24:36,423] INFO: Epoch 50: Train Loss 0.5004
[2025-10-25 11:24:40,741] INFO: Epoch 60: Train Loss 0.3919
[2025-10-25 11:24:45,059] INFO: Epoch 70: Train Loss 0.3182
[2025-10-25 11:24:49,380] INFO: Epoch 80: Train Loss 0.2390
[2025-10-25 11:24:53,699] INFO: Epoch 90: Train Loss 0.1877
[2025-10-25 11:24:58,012] INFO: Epoch 100: Train Loss 0.1482
[2025-10-25 11:25:02,329] INFO: Epoch 110: Train Loss 0.1280
[2025-10-25 11:25:06,649] INFO: Epoch 120: Train Loss 0.1170
[2025-10-25 11:25:10,971] INFO: Epoch 130: Train Loss 0.1010
[2025-10-25 11:25:15,288] INFO: Epoch 140: Train Loss 0.0831
[2025-10-25 11:25:19,609] INFO: Epoch 150: Train Loss 0.0764
[2025-10-25 11:25:23,927] INFO: Epoch 160: Train Loss 0.0703
[2025-10-25 11:25:28,247] INFO: Epoch 170: Train Loss 0.0659
[2025-10-25 11:25:32,565] INFO: Epoch 180: Train Loss 0.0611
[2025-10-25 11:25:36,884] INFO: Epoch 190: Train Loss 0.0550
[2025-10-25 11:25:41,206] INFO: Epoch 200: Train Loss 0.0569
[2025-10-25 11:25:45,525] INFO: Epoch 210: Train Loss 0.0489
[2025-10-25 11:25:49,843] INFO: Epoch 220: Train Loss 0.0494
[2025-10-25 11:25:54,163] INFO: Epoch 230: Train Loss 0.0474
[2025-10-25 11:25:58,484] INFO: Epoch 240: Train Loss 0.0449
[2025-10-25 11:26:02,801] INFO: Epoch 250: Train Loss 0.0423
[2025-10-25 11:26:07,122] INFO: Epoch 260: Train Loss 0.0413
[2025-10-25 11:26:11,439] INFO: Epoch 270: Train Loss 0.0404
[2025-10-25 11:26:15,757] INFO: Epoch 280: Train Loss 0.0364
[2025-10-25 11:26:20,077] INFO: Epoch 290: Train Loss 0.0369
[2025-10-25 11:26:24,395] INFO: Epoch 300: Train Loss 0.0341
[2025-10-25 11:26:28,715] INFO: Epoch 310: Train Loss 0.0339
[2025-10-25 11:26:33,033] INFO: Epoch 320: Train Loss 0.0321
[2025-10-25 11:26:37,354] INFO: Epoch 330: Train Loss 0.0335
[2025-10-25 11:26:41,674] INFO: Epoch 340: Train Loss 0.0319
[2025-10-25 11:26:45,993] INFO: Epoch 350: Train Loss 0.0304
[2025-10-25 11:26:50,312] INFO: Epoch 360: Train Loss 0.0325
[2025-10-25 11:26:54,628] INFO: Epoch 370: Train Loss 0.0327
[2025-10-25 11:26:58,945] INFO: Epoch 380: Train Loss 0.0318
[2025-10-25 11:27:03,263] INFO: Epoch 390: Train Loss 0.0312
[2025-10-25 11:27:07,582] INFO: Epoch 400: Train Loss 0.0313
[2025-10-25 11:27:07,606] INFO: âœ… Saved artifacts for GOLD fold 0 to models/GOLD/fold_0
[2025-10-25 11:27:07,606] INFO:    - Features: 13
[2025-10-25 11:27:07,606] INFO:    - Sequence length: 60
[2025-10-25 11:27:07,606] INFO:    - Model parameters: 804,097
[2025-10-25 11:27:07,606] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_0
[2025-10-25 11:27:07,606] INFO: Completed GOLD fold 0: Train samples 2318, Final train loss 0.0313
[2025-10-25 11:27:07,606] INFO: Training GOLD fold 1
[2025-10-25 11:27:07,606] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 11:27:07,626] INFO: Calculating technical indicators...
[2025-10-25 11:27:07,626] INFO: Calculating technical indicators...
[2025-10-25 11:27:07,630] INFO: Technical indicators calculated successfully
[2025-10-25 11:27:07,630] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 11:27:07,634] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:27:07,638] INFO: Return statistics: mean=0.0005, std=0.0124
[2025-10-25 11:27:07,638] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 11:27:07,638] INFO: Created 2680 sequences of length 60
[2025-10-25 11:27:07,639] INFO: Feature shape: (2680, 60, 13), Target shape: (2680,)
[2025-10-25 11:27:07,652] INFO: Scalers fitted on training data
[2025-10-25 11:27:07,652] INFO: Feature scaler mean: [1049.09304943 1057.68794549 1039.7314813 ]...
[2025-10-25 11:27:07,652] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:27:07,659] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:27:07,663] INFO: Return statistics: mean=0.0005, std=0.0094
[2025-10-25 11:27:07,663] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 11:27:07,663] INFO: Created 2560 sequences of length 60
[2025-10-25 11:27:07,663] INFO: Feature shape: (2560, 60, 13), Target shape: (2560,)
[2025-10-25 11:27:07,671] INFO: Sequence building completed for GOLD
[2025-10-25 11:27:07,671] INFO: Training samples: 2680
[2025-10-25 11:27:07,673] INFO: Dataset initialized: 2680 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:27:07,673] INFO: Training DataLoader: 2680 samples, 20 batches of size 128
[2025-10-25 11:27:07,689] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:27:07,689] INFO: Created basic model with 804097 parameters
[2025-10-25 11:27:07,692] INFO: Starting training for 400 epochs
[2025-10-25 11:27:12,358] INFO: Epoch 10: Train Loss 0.9988
[2025-10-25 11:27:17,081] INFO: Epoch 20: Train Loss 0.9295
[2025-10-25 11:27:21,847] INFO: Epoch 30: Train Loss 0.8074
[2025-10-25 11:27:26,629] INFO: Epoch 40: Train Loss 0.6653
[2025-10-25 11:27:31,417] INFO: Epoch 50: Train Loss 0.5402
[2025-10-25 11:27:36,197] INFO: Epoch 60: Train Loss 0.4122
[2025-10-25 11:27:40,968] INFO: Epoch 70: Train Loss 0.3198
[2025-10-25 11:27:45,730] INFO: Epoch 80: Train Loss 0.2549
[2025-10-25 11:27:50,494] INFO: Epoch 90: Train Loss 0.2038
[2025-10-25 11:27:55,260] INFO: Epoch 100: Train Loss 0.1653
[2025-10-25 11:28:00,026] INFO: Epoch 110: Train Loss 0.1368
[2025-10-25 11:28:04,792] INFO: Epoch 120: Train Loss 0.1176
[2025-10-25 11:28:09,556] INFO: Epoch 130: Train Loss 0.1085
[2025-10-25 11:28:14,331] INFO: Epoch 140: Train Loss 0.0902
[2025-10-25 11:28:19,098] INFO: Epoch 150: Train Loss 0.0810
[2025-10-25 11:28:23,866] INFO: Epoch 160: Train Loss 0.0754
[2025-10-25 11:28:28,635] INFO: Epoch 170: Train Loss 0.0712
[2025-10-25 11:28:33,393] INFO: Epoch 180: Train Loss 0.0647
[2025-10-25 11:28:38,160] INFO: Epoch 190: Train Loss 0.0602
[2025-10-25 11:28:42,928] INFO: Epoch 200: Train Loss 0.0561
[2025-10-25 11:28:47,680] INFO: Epoch 210: Train Loss 0.0554
[2025-10-25 11:28:52,446] INFO: Epoch 220: Train Loss 0.0492
[2025-10-25 11:28:57,222] INFO: Epoch 230: Train Loss 0.0504
[2025-10-25 11:29:02,007] INFO: Epoch 240: Train Loss 0.0474
[2025-10-25 11:29:06,774] INFO: Epoch 250: Train Loss 0.0454
[2025-10-25 11:29:11,542] INFO: Epoch 260: Train Loss 0.0417
[2025-10-25 11:29:16,310] INFO: Epoch 270: Train Loss 0.0424
[2025-10-25 11:29:21,081] INFO: Epoch 280: Train Loss 0.0383
[2025-10-25 11:29:25,843] INFO: Epoch 290: Train Loss 0.0376
[2025-10-25 11:29:30,610] INFO: Epoch 300: Train Loss 0.0363
[2025-10-25 11:29:35,373] INFO: Epoch 310: Train Loss 0.0341
[2025-10-25 11:29:40,138] INFO: Epoch 320: Train Loss 0.0371
[2025-10-25 11:29:44,900] INFO: Epoch 330: Train Loss 0.0355
[2025-10-25 11:29:49,652] INFO: Epoch 340: Train Loss 0.0356
[2025-10-25 11:29:54,421] INFO: Epoch 350: Train Loss 0.0340
[2025-10-25 11:29:59,182] INFO: Epoch 360: Train Loss 0.0349
[2025-10-25 11:30:03,948] INFO: Epoch 370: Train Loss 0.0335
[2025-10-25 11:30:08,717] INFO: Epoch 380: Train Loss 0.0312
[2025-10-25 11:30:13,459] INFO: Epoch 390: Train Loss 0.0330
[2025-10-25 11:30:18,237] INFO: Epoch 400: Train Loss 0.0315
[2025-10-25 11:30:18,265] INFO: âœ… Saved artifacts for GOLD fold 1 to models/GOLD/fold_1
[2025-10-25 11:30:18,265] INFO:    - Features: 13
[2025-10-25 11:30:18,265] INFO:    - Sequence length: 60
[2025-10-25 11:30:18,265] INFO:    - Model parameters: 804,097
[2025-10-25 11:30:18,265] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_1
[2025-10-25 11:30:18,265] INFO: Completed GOLD fold 1: Train samples 2680, Final train loss 0.0315
[2025-10-25 11:30:18,265] INFO: Training GOLD fold 2
[2025-10-25 11:30:18,265] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 11:30:18,284] INFO: Calculating technical indicators...
[2025-10-25 11:30:18,284] INFO: Calculating technical indicators...
[2025-10-25 11:30:18,288] INFO: Technical indicators calculated successfully
[2025-10-25 11:30:18,288] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 11:30:18,293] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:30:18,298] INFO: Return statistics: mean=0.0005, std=0.0121
[2025-10-25 11:30:18,298] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 11:30:18,298] INFO: Created 3048 sequences of length 60
[2025-10-25 11:30:18,298] INFO: Feature shape: (3048, 60, 13), Target shape: (3048,)
[2025-10-25 11:30:18,314] INFO: Scalers fitted on training data
[2025-10-25 11:30:18,315] INFO: Feature scaler mean: [1064.46290727 1073.06113639 1055.21875171]...
[2025-10-25 11:30:18,315] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:30:18,323] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:30:18,327] INFO: Return statistics: mean=0.0006, std=0.0093
[2025-10-25 11:30:18,327] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 11:30:18,327] INFO: Created 2192 sequences of length 60
[2025-10-25 11:30:18,328] INFO: Feature shape: (2192, 60, 13), Target shape: (2192,)
[2025-10-25 11:30:18,335] INFO: Sequence building completed for GOLD
[2025-10-25 11:30:18,335] INFO: Training samples: 3048
[2025-10-25 11:30:18,336] INFO: Dataset initialized: 3048 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:30:18,336] INFO: Training DataLoader: 3048 samples, 23 batches of size 128
[2025-10-25 11:30:18,352] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:30:18,352] INFO: Created basic model with 804097 parameters
[2025-10-25 11:30:18,355] INFO: Starting training for 400 epochs
[2025-10-25 11:30:23,835] INFO: Epoch 10: Train Loss 0.9892
[2025-10-25 11:30:29,360] INFO: Epoch 20: Train Loss 0.9160
[2025-10-25 11:30:34,883] INFO: Epoch 30: Train Loss 0.8246
[2025-10-25 11:30:40,410] INFO: Epoch 40: Train Loss 0.6875
[2025-10-25 11:30:45,936] INFO: Epoch 50: Train Loss 0.5299
[2025-10-25 11:30:51,465] INFO: Epoch 60: Train Loss 0.3801
[2025-10-25 11:30:56,989] INFO: Epoch 70: Train Loss 0.2995
[2025-10-25 11:31:02,484] INFO: Epoch 80: Train Loss 0.2186
[2025-10-25 11:31:08,009] INFO: Epoch 90: Train Loss 0.1731
[2025-10-25 11:31:13,542] INFO: Epoch 100: Train Loss 0.1452
[2025-10-25 11:31:19,067] INFO: Epoch 110: Train Loss 0.1192
[2025-10-25 11:31:24,593] INFO: Epoch 120: Train Loss 0.1124
[2025-10-25 11:31:30,119] INFO: Epoch 130: Train Loss 0.0901
[2025-10-25 11:31:35,643] INFO: Epoch 140: Train Loss 0.0796
[2025-10-25 11:31:41,171] INFO: Epoch 150: Train Loss 0.0733
[2025-10-25 11:31:46,696] INFO: Epoch 160: Train Loss 0.0675
[2025-10-25 11:31:52,222] INFO: Epoch 170: Train Loss 0.0618
[2025-10-25 11:31:57,746] INFO: Epoch 180: Train Loss 0.0528
[2025-10-25 11:32:03,268] INFO: Epoch 190: Train Loss 0.0546
[2025-10-25 11:32:08,793] INFO: Epoch 200: Train Loss 0.0486
[2025-10-25 11:32:14,311] INFO: Epoch 210: Train Loss 0.0467
[2025-10-25 11:32:19,835] INFO: Epoch 220: Train Loss 0.0454
[2025-10-25 11:32:25,365] INFO: Epoch 230: Train Loss 0.0439
[2025-10-25 11:32:30,905] INFO: Epoch 240: Train Loss 0.0421
[2025-10-25 11:32:36,426] INFO: Epoch 250: Train Loss 0.0389
[2025-10-25 11:32:41,953] INFO: Epoch 260: Train Loss 0.0408
[2025-10-25 11:32:47,478] INFO: Epoch 270: Train Loss 0.0365
[2025-10-25 11:32:53,003] INFO: Epoch 280: Train Loss 0.0352
[2025-10-25 11:32:58,528] INFO: Epoch 290: Train Loss 0.0323
[2025-10-25 11:33:04,174] INFO: Epoch 300: Train Loss 0.0338
[2025-10-25 11:33:09,875] INFO: Epoch 310: Train Loss 0.0317
[2025-10-25 11:33:15,428] INFO: Epoch 320: Train Loss 0.0337
[2025-10-25 11:33:21,071] INFO: Epoch 330: Train Loss 0.0306
[2025-10-25 11:33:26,833] INFO: Epoch 340: Train Loss 0.0299
[2025-10-25 11:33:32,604] INFO: Epoch 350: Train Loss 0.0302
[2025-10-25 11:33:38,434] INFO: Epoch 360: Train Loss 0.0301
[2025-10-25 11:33:44,116] INFO: Epoch 370: Train Loss 0.0278
[2025-10-25 11:33:49,809] INFO: Epoch 380: Train Loss 0.0295
[2025-10-25 11:33:55,532] INFO: Epoch 390: Train Loss 0.0298
[2025-10-25 11:34:01,220] INFO: Epoch 400: Train Loss 0.0287
[2025-10-25 11:34:01,248] INFO: âœ… Saved artifacts for GOLD fold 2 to models/GOLD/fold_2
[2025-10-25 11:34:01,248] INFO:    - Features: 13
[2025-10-25 11:34:01,248] INFO:    - Sequence length: 60
[2025-10-25 11:34:01,248] INFO:    - Model parameters: 804,097
[2025-10-25 11:34:01,248] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_2
[2025-10-25 11:34:01,248] INFO: Completed GOLD fold 2: Train samples 3048, Final train loss 0.0287
[2025-10-25 11:34:01,248] INFO: Training GOLD fold 3
[2025-10-25 11:34:01,248] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 11:34:01,270] INFO: Calculating technical indicators...
[2025-10-25 11:34:01,271] INFO: Calculating technical indicators...
[2025-10-25 11:34:01,275] INFO: Technical indicators calculated successfully
[2025-10-25 11:34:01,276] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 11:34:01,280] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:34:01,286] INFO: Return statistics: mean=0.0004, std=0.0116
[2025-10-25 11:34:01,286] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 11:34:01,286] INFO: Created 3413 sequences of length 60
[2025-10-25 11:34:01,286] INFO: Feature shape: (3413, 60, 13), Target shape: (3413,)
[2025-10-25 11:34:01,304] INFO: Scalers fitted on training data
[2025-10-25 11:34:01,304] INFO: Feature scaler mean: [1085.73597003 1094.17146332 1076.71918165]...
[2025-10-25 11:34:01,304] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:34:01,316] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:34:01,320] INFO: Return statistics: mean=0.0006, std=0.0098
[2025-10-25 11:34:01,320] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 11:34:01,320] INFO: Created 1827 sequences of length 60
[2025-10-25 11:34:01,320] INFO: Feature shape: (1827, 60, 13), Target shape: (1827,)
[2025-10-25 11:34:01,326] INFO: Sequence building completed for GOLD
[2025-10-25 11:34:01,326] INFO: Training samples: 3413
[2025-10-25 11:34:01,328] INFO: Dataset initialized: 3413 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:34:01,328] INFO: Training DataLoader: 3413 samples, 26 batches of size 128
[2025-10-25 11:34:01,346] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:34:01,346] INFO: Created basic model with 804097 parameters
[2025-10-25 11:34:01,351] INFO: Starting training for 400 epochs
[2025-10-25 11:34:07,723] INFO: Epoch 10: Train Loss 0.9908
[2025-10-25 11:34:14,087] INFO: Epoch 20: Train Loss 0.9431
[2025-10-25 11:34:20,499] INFO: Epoch 30: Train Loss 0.8496
[2025-10-25 11:34:26,946] INFO: Epoch 40: Train Loss 0.6575
[2025-10-25 11:34:33,260] INFO: Epoch 50: Train Loss 0.4878
[2025-10-25 11:34:39,583] INFO: Epoch 60: Train Loss 0.3739
[2025-10-25 11:34:45,889] INFO: Epoch 70: Train Loss 0.2796
[2025-10-25 11:34:52,210] INFO: Epoch 80: Train Loss 0.2200
[2025-10-25 11:34:58,524] INFO: Epoch 90: Train Loss 0.1807
[2025-10-25 11:35:04,842] INFO: Epoch 100: Train Loss 0.1344
[2025-10-25 11:35:11,144] INFO: Epoch 110: Train Loss 0.1163
[2025-10-25 11:35:17,446] INFO: Epoch 120: Train Loss 0.0970
[2025-10-25 11:35:23,756] INFO: Epoch 130: Train Loss 0.0915
[2025-10-25 11:35:30,065] INFO: Epoch 140: Train Loss 0.0814
[2025-10-25 11:35:36,380] INFO: Epoch 150: Train Loss 0.0727
[2025-10-25 11:35:42,905] INFO: Epoch 160: Train Loss 0.0636
[2025-10-25 11:35:49,287] INFO: Epoch 170: Train Loss 0.0605
[2025-10-25 11:35:55,766] INFO: Epoch 180: Train Loss 0.0559
[2025-10-25 11:36:02,205] INFO: Epoch 190: Train Loss 0.0557
[2025-10-25 11:36:08,566] INFO: Epoch 200: Train Loss 0.0503
[2025-10-25 11:36:14,895] INFO: Epoch 210: Train Loss 0.0481
[2025-10-25 11:36:21,227] INFO: Epoch 220: Train Loss 0.0455
[2025-10-25 11:36:27,559] INFO: Epoch 230: Train Loss 0.0441
[2025-10-25 11:36:33,888] INFO: Epoch 240: Train Loss 0.0413
[2025-10-25 11:36:40,217] INFO: Epoch 250: Train Loss 0.0406
[2025-10-25 11:36:46,532] INFO: Epoch 260: Train Loss 0.0378
[2025-10-25 11:36:52,840] INFO: Epoch 270: Train Loss 0.0368
[2025-10-25 11:36:59,151] INFO: Epoch 280: Train Loss 0.0340
[2025-10-25 11:37:05,466] INFO: Epoch 290: Train Loss 0.0355
[2025-10-25 11:37:11,789] INFO: Epoch 300: Train Loss 0.0329
[2025-10-25 11:37:18,229] INFO: Epoch 310: Train Loss 0.0332
[2025-10-25 11:37:24,571] INFO: Epoch 320: Train Loss 0.0320
[2025-10-25 11:37:30,906] INFO: Epoch 330: Train Loss 0.0323
[2025-10-25 11:37:37,229] INFO: Epoch 340: Train Loss 0.0309
[2025-10-25 11:37:43,550] INFO: Epoch 350: Train Loss 0.0309
[2025-10-25 11:37:49,887] INFO: Epoch 360: Train Loss 0.0294
[2025-10-25 11:37:56,199] INFO: Epoch 370: Train Loss 0.0295
[2025-10-25 11:38:02,517] INFO: Epoch 380: Train Loss 0.0298
[2025-10-25 11:38:08,829] INFO: Epoch 390: Train Loss 0.0281
[2025-10-25 11:38:15,208] INFO: Epoch 400: Train Loss 0.0287
[2025-10-25 11:38:15,235] INFO: âœ… Saved artifacts for GOLD fold 3 to models/GOLD/fold_3
[2025-10-25 11:38:15,236] INFO:    - Features: 13
[2025-10-25 11:38:15,236] INFO:    - Sequence length: 60
[2025-10-25 11:38:15,236] INFO:    - Model parameters: 804,097
[2025-10-25 11:38:15,236] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_3
[2025-10-25 11:38:15,236] INFO: Completed GOLD fold 3: Train samples 3413, Final train loss 0.0287
[2025-10-25 11:38:15,236] INFO: Training GOLD fold 4
[2025-10-25 11:38:15,236] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 11:38:15,258] INFO: Calculating technical indicators...
[2025-10-25 11:38:15,258] INFO: Calculating technical indicators...
[2025-10-25 11:38:15,263] INFO: Technical indicators calculated successfully
[2025-10-25 11:38:15,264] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 11:38:15,269] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:38:15,277] INFO: Return statistics: mean=0.0004, std=0.0112
[2025-10-25 11:38:15,277] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 11:38:15,277] INFO: Created 3778 sequences of length 60
[2025-10-25 11:38:15,277] INFO: Feature shape: (3778, 60, 13), Target shape: (3778,)
[2025-10-25 11:38:15,298] INFO: Scalers fitted on training data
[2025-10-25 11:38:15,299] INFO: Feature scaler mean: [1104.09583046 1112.29042479 1095.37146477]...
[2025-10-25 11:38:15,299] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:38:15,309] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:38:15,312] INFO: Return statistics: mean=0.0007, std=0.0104
[2025-10-25 11:38:15,312] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 11:38:15,312] INFO: Created 1464 sequences of length 60
[2025-10-25 11:38:15,312] INFO: Feature shape: (1464, 60, 13), Target shape: (1464,)
[2025-10-25 11:38:15,317] INFO: Sequence building completed for GOLD
[2025-10-25 11:38:15,317] INFO: Training samples: 3778
[2025-10-25 11:38:15,319] INFO: Dataset initialized: 3778 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:38:15,319] INFO: Training DataLoader: 3778 samples, 29 batches of size 128
[2025-10-25 11:38:15,338] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:38:15,338] INFO: Created basic model with 804097 parameters
[2025-10-25 11:38:15,343] INFO: Starting training for 400 epochs
[2025-10-25 11:38:22,447] INFO: Epoch 10: Train Loss 0.9868
[2025-10-25 11:38:29,573] INFO: Epoch 20: Train Loss 0.9293
[2025-10-25 11:38:36,676] INFO: Epoch 30: Train Loss 0.7968
[2025-10-25 11:38:43,785] INFO: Epoch 40: Train Loss 0.6388
[2025-10-25 11:38:50,868] INFO: Epoch 50: Train Loss 0.4752
[2025-10-25 11:38:57,960] INFO: Epoch 60: Train Loss 0.3353
[2025-10-25 11:39:05,233] INFO: Epoch 70: Train Loss 0.2442
[2025-10-25 11:39:12,400] INFO: Epoch 80: Train Loss 0.1919
[2025-10-25 11:39:19,566] INFO: Epoch 90: Train Loss 0.1456
[2025-10-25 11:39:26,727] INFO: Epoch 100: Train Loss 0.1036
[2025-10-25 11:39:33,966] INFO: Epoch 110: Train Loss 0.0941
[2025-10-25 11:39:41,138] INFO: Epoch 120: Train Loss 0.0886
[2025-10-25 11:39:48,397] INFO: Epoch 130: Train Loss 0.0734
[2025-10-25 11:39:55,672] INFO: Epoch 140: Train Loss 0.0655
[2025-10-25 11:40:02,888] INFO: Epoch 150: Train Loss 0.0611
[2025-10-25 11:40:10,077] INFO: Epoch 160: Train Loss 0.0565
[2025-10-25 11:40:17,314] INFO: Epoch 170: Train Loss 0.0526
[2025-10-25 11:40:24,508] INFO: Epoch 180: Train Loss 0.0508
[2025-10-25 11:40:31,605] INFO: Epoch 190: Train Loss 0.0477
[2025-10-25 11:40:38,687] INFO: Epoch 200: Train Loss 0.0474
[2025-10-25 11:40:45,922] INFO: Epoch 210: Train Loss 0.0448
[2025-10-25 11:40:53,078] INFO: Epoch 220: Train Loss 0.0384
[2025-10-25 11:41:00,230] INFO: Epoch 230: Train Loss 0.0373
[2025-10-25 11:41:07,372] INFO: Epoch 240: Train Loss 0.0365
[2025-10-25 11:41:14,498] INFO: Epoch 250: Train Loss 0.0349
[2025-10-25 11:41:21,646] INFO: Epoch 260: Train Loss 0.0339
[2025-10-25 11:41:28,782] INFO: Epoch 270: Train Loss 0.0330
[2025-10-25 11:41:35,883] INFO: Epoch 280: Train Loss 0.0327
[2025-10-25 11:41:42,843] INFO: Epoch 290: Train Loss 0.0308
[2025-10-25 11:41:49,770] INFO: Epoch 300: Train Loss 0.0305
[2025-10-25 11:41:56,696] INFO: Epoch 310: Train Loss 0.0292
[2025-10-25 11:42:03,629] INFO: Epoch 320: Train Loss 0.0294
[2025-10-25 11:42:10,565] INFO: Epoch 330: Train Loss 0.0280
[2025-10-25 11:42:17,502] INFO: Epoch 340: Train Loss 0.0274
[2025-10-25 11:42:24,434] INFO: Epoch 350: Train Loss 0.0273
[2025-10-25 11:42:31,372] INFO: Epoch 360: Train Loss 0.0256
[2025-10-25 11:42:38,304] INFO: Epoch 370: Train Loss 0.0262
[2025-10-25 11:42:45,237] INFO: Epoch 380: Train Loss 0.0264
[2025-10-25 11:42:52,172] INFO: Epoch 390: Train Loss 0.0263
[2025-10-25 11:42:59,101] INFO: Epoch 400: Train Loss 0.0265
[2025-10-25 11:42:59,126] INFO: âœ… Saved artifacts for GOLD fold 4 to models/GOLD/fold_4
[2025-10-25 11:42:59,126] INFO:    - Features: 13
[2025-10-25 11:42:59,126] INFO:    - Sequence length: 60
[2025-10-25 11:42:59,126] INFO:    - Model parameters: 804,097
[2025-10-25 11:42:59,127] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_4
[2025-10-25 11:42:59,127] INFO: Completed GOLD fold 4: Train samples 3778, Final train loss 0.0265
[2025-10-25 11:42:59,127] INFO: Training GOLD fold 5
[2025-10-25 11:42:59,127] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 11:42:59,149] INFO: Calculating technical indicators...
[2025-10-25 11:42:59,149] INFO: Calculating technical indicators...
[2025-10-25 11:42:59,153] INFO: Technical indicators calculated successfully
[2025-10-25 11:42:59,153] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 11:42:59,159] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:42:59,166] INFO: Return statistics: mean=0.0004, std=0.0112
[2025-10-25 11:42:59,166] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 11:42:59,166] INFO: Created 4145 sequences of length 60
[2025-10-25 11:42:59,166] INFO: Feature shape: (4145, 60, 13), Target shape: (4145,)
[2025-10-25 11:42:59,189] INFO: Scalers fitted on training data
[2025-10-25 11:42:59,190] INFO: Feature scaler mean: [1146.32797728 1154.91191508 1137.34505659]...
[2025-10-25 11:42:59,190] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:42:59,201] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:42:59,203] INFO: Return statistics: mean=0.0008, std=0.0102
[2025-10-25 11:42:59,203] INFO: Return range: [-0.0346, 0.1448]
[2025-10-25 11:42:59,203] INFO: Created 1096 sequences of length 60
[2025-10-25 11:42:59,203] INFO: Feature shape: (1096, 60, 13), Target shape: (1096,)
[2025-10-25 11:42:59,206] INFO: Sequence building completed for GOLD
[2025-10-25 11:42:59,206] INFO: Training samples: 4145
[2025-10-25 11:42:59,208] INFO: Dataset initialized: 4145 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:42:59,208] INFO: Training DataLoader: 4145 samples, 32 batches of size 128
[2025-10-25 11:42:59,228] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:42:59,228] INFO: Created basic model with 804097 parameters
[2025-10-25 11:42:59,235] INFO: Starting training for 400 epochs
[2025-10-25 11:43:06,814] INFO: Epoch 10: Train Loss 0.9934
[2025-10-25 11:43:14,405] INFO: Epoch 20: Train Loss 0.9587
[2025-10-25 11:43:21,963] INFO: Epoch 30: Train Loss 0.8332
[2025-10-25 11:43:29,523] INFO: Epoch 40: Train Loss 0.6431
[2025-10-25 11:43:37,086] INFO: Epoch 50: Train Loss 0.4814
[2025-10-25 11:43:44,675] INFO: Epoch 60: Train Loss 0.3476
[2025-10-25 11:43:52,271] INFO: Epoch 70: Train Loss 0.2523
[2025-10-25 11:43:59,890] INFO: Epoch 80: Train Loss 0.1840
[2025-10-25 11:44:07,507] INFO: Epoch 90: Train Loss 0.1450
[2025-10-25 11:44:15,123] INFO: Epoch 100: Train Loss 0.1139
[2025-10-25 11:44:22,739] INFO: Epoch 110: Train Loss 0.0988
[2025-10-25 11:44:30,356] INFO: Epoch 120: Train Loss 0.0849
[2025-10-25 11:44:37,973] INFO: Epoch 130: Train Loss 0.0738
[2025-10-25 11:44:45,588] INFO: Epoch 140: Train Loss 0.0658
[2025-10-25 11:44:53,204] INFO: Epoch 150: Train Loss 0.0621
[2025-10-25 11:45:00,821] INFO: Epoch 160: Train Loss 0.0567
[2025-10-25 11:45:08,438] INFO: Epoch 170: Train Loss 0.0529
[2025-10-25 11:45:16,053] INFO: Epoch 180: Train Loss 0.0499
[2025-10-25 11:45:23,668] INFO: Epoch 190: Train Loss 0.0471
[2025-10-25 11:45:31,355] INFO: Epoch 200: Train Loss 0.0464
[2025-10-25 11:45:39,209] INFO: Epoch 210: Train Loss 0.0419
[2025-10-25 11:45:46,981] INFO: Epoch 220: Train Loss 0.0398
[2025-10-25 11:45:54,422] INFO: Epoch 230: Train Loss 0.0383
[2025-10-25 11:46:02,190] INFO: Epoch 240: Train Loss 0.0369
[2025-10-25 11:46:09,772] INFO: Epoch 250: Train Loss 0.0331
[2025-10-25 11:46:17,275] INFO: Epoch 260: Train Loss 0.0328
[2025-10-25 11:46:24,773] INFO: Epoch 270: Train Loss 0.0316
[2025-10-25 11:46:32,363] INFO: Epoch 280: Train Loss 0.0327
[2025-10-25 11:46:39,942] INFO: Epoch 290: Train Loss 0.0315
[2025-10-25 11:46:47,387] INFO: Epoch 300: Train Loss 0.0306
[2025-10-25 11:46:55,011] INFO: Epoch 310: Train Loss 0.0296
[2025-10-25 11:47:02,755] INFO: Epoch 320: Train Loss 0.0308
[2025-10-25 11:47:10,199] INFO: Epoch 330: Train Loss 0.0282
[2025-10-25 11:47:17,833] INFO: Epoch 340: Train Loss 0.0276
[2025-10-25 11:47:25,446] INFO: Epoch 350: Train Loss 0.0263
[2025-10-25 11:47:32,890] INFO: Epoch 360: Train Loss 0.0269
[2025-10-25 11:47:40,443] INFO: Epoch 370: Train Loss 0.0275
[2025-10-25 11:47:48,048] INFO: Epoch 380: Train Loss 0.0263
[2025-10-25 11:47:55,499] INFO: Epoch 390: Train Loss 0.0264
[2025-10-25 11:48:03,080] INFO: Epoch 400: Train Loss 0.0254
[2025-10-25 11:48:03,098] INFO: âœ… Saved artifacts for GOLD fold 5 to models/GOLD/fold_5
[2025-10-25 11:48:03,098] INFO:    - Features: 13
[2025-10-25 11:48:03,098] INFO:    - Sequence length: 60
[2025-10-25 11:48:03,098] INFO:    - Model parameters: 804,097
[2025-10-25 11:48:03,098] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_5
[2025-10-25 11:48:03,098] INFO: Completed GOLD fold 5: Train samples 4145, Final train loss 0.0254
[2025-10-25 11:48:03,098] INFO: Training GOLD fold 6
[2025-10-25 11:48:03,098] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 11:48:03,114] INFO: Calculating technical indicators...
[2025-10-25 11:48:03,114] INFO: Calculating technical indicators...
[2025-10-25 11:48:03,117] INFO: Technical indicators calculated successfully
[2025-10-25 11:48:03,118] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 11:48:03,121] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:48:03,127] INFO: Return statistics: mean=0.0004, std=0.0110
[2025-10-25 11:48:03,127] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 11:48:03,127] INFO: Created 4511 sequences of length 60
[2025-10-25 11:48:03,127] INFO: Feature shape: (4511, 60, 13), Target shape: (4511,)
[2025-10-25 11:48:03,146] INFO: Scalers fitted on training data
[2025-10-25 11:48:03,146] INFO: Feature scaler mean: [1201.04241062 1209.86975132 1191.72162507]...
[2025-10-25 11:48:03,146] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:48:03,158] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:48:03,160] INFO: Return statistics: mean=0.0012, std=0.0110
[2025-10-25 11:48:03,160] INFO: Return range: [-0.0346, 0.1448]
[2025-10-25 11:48:03,160] INFO: Created 733 sequences of length 60
[2025-10-25 11:48:03,160] INFO: Feature shape: (733, 60, 13), Target shape: (733,)
[2025-10-25 11:48:03,162] INFO: Sequence building completed for GOLD
[2025-10-25 11:48:03,163] INFO: Training samples: 4511
[2025-10-25 11:48:03,164] INFO: Dataset initialized: 4511 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:48:03,164] INFO: Training DataLoader: 4511 samples, 35 batches of size 128
[2025-10-25 11:48:03,179] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:48:03,180] INFO: Created basic model with 804097 parameters
[2025-10-25 11:48:03,182] INFO: Starting training for 400 epochs
[2025-10-25 11:48:11,784] INFO: Epoch 10: Train Loss 0.9965
[2025-10-25 11:48:20,166] INFO: Epoch 20: Train Loss 0.9571
[2025-10-25 11:48:28,380] INFO: Epoch 30: Train Loss 0.8670
[2025-10-25 11:48:36,768] INFO: Epoch 40: Train Loss 0.6708
[2025-10-25 11:48:45,117] INFO: Epoch 50: Train Loss 0.4671
[2025-10-25 11:48:53,433] INFO: Epoch 60: Train Loss 0.3375
[2025-10-25 11:49:01,641] INFO: Epoch 70: Train Loss 0.2245
[2025-10-25 11:49:10,171] INFO: Epoch 80: Train Loss 0.1737
[2025-10-25 11:49:18,518] INFO: Epoch 90: Train Loss 0.1344
[2025-10-25 11:49:26,884] INFO: Epoch 100: Train Loss 0.1138
[2025-10-25 11:49:35,091] INFO: Epoch 110: Train Loss 0.0899
[2025-10-25 11:49:43,483] INFO: Epoch 120: Train Loss 0.0857
[2025-10-25 11:49:51,833] INFO: Epoch 130: Train Loss 0.0698
[2025-10-25 11:50:00,168] INFO: Epoch 140: Train Loss 0.0681
[2025-10-25 11:50:08,634] INFO: Epoch 150: Train Loss 0.0588
[2025-10-25 11:50:16,837] INFO: Epoch 160: Train Loss 0.0535
[2025-10-25 11:50:25,204] INFO: Epoch 170: Train Loss 0.0539
[2025-10-25 11:50:33,595] INFO: Epoch 180: Train Loss 0.0529
[2025-10-25 11:50:41,927] INFO: Epoch 190: Train Loss 0.0470
[2025-10-25 11:50:50,157] INFO: Epoch 200: Train Loss 0.0441
[2025-10-25 11:50:58,555] INFO: Epoch 210: Train Loss 0.0426
[2025-10-25 11:51:07,459] INFO: Epoch 220: Train Loss 0.0384
[2025-10-25 11:51:15,809] INFO: Epoch 230: Train Loss 0.0374
[2025-10-25 11:51:24,023] INFO: Epoch 240: Train Loss 0.0367
[2025-10-25 11:51:32,376] INFO: Epoch 250: Train Loss 0.0363
[2025-10-25 11:51:40,755] INFO: Epoch 260: Train Loss 0.0325
[2025-10-25 11:51:49,080] INFO: Epoch 270: Train Loss 0.0313
[2025-10-25 11:51:57,458] INFO: Epoch 280: Train Loss 0.0317
[2025-10-25 11:52:05,879] INFO: Epoch 290: Train Loss 0.0298
[2025-10-25 11:52:14,247] INFO: Epoch 300: Train Loss 0.0314
[2025-10-25 11:52:22,580] INFO: Epoch 310: Train Loss 0.0295
[2025-10-25 11:52:30,800] INFO: Epoch 320: Train Loss 0.0281
[2025-10-25 11:52:39,156] INFO: Epoch 330: Train Loss 0.0275
[2025-10-25 11:52:47,505] INFO: Epoch 340: Train Loss 0.0278
[2025-10-25 11:52:56,054] INFO: Epoch 350: Train Loss 0.0266
[2025-10-25 11:53:04,388] INFO: Epoch 360: Train Loss 0.0263
[2025-10-25 11:53:12,645] INFO: Epoch 370: Train Loss 0.0263
[2025-10-25 11:53:21,276] INFO: Epoch 380: Train Loss 0.0253
[2025-10-25 11:53:29,785] INFO: Epoch 390: Train Loss 0.0256
[2025-10-25 11:53:38,191] INFO: Epoch 400: Train Loss 0.0263
[2025-10-25 11:53:38,211] INFO: âœ… Saved artifacts for GOLD fold 6 to models/GOLD/fold_6
[2025-10-25 11:53:38,211] INFO:    - Features: 13
[2025-10-25 11:53:38,211] INFO:    - Sequence length: 60
[2025-10-25 11:53:38,211] INFO:    - Model parameters: 804,097
[2025-10-25 11:53:38,211] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_6
[2025-10-25 11:53:38,211] INFO: Completed GOLD fold 6: Train samples 4511, Final train loss 0.0263
[2025-10-25 11:53:38,211] INFO: Training GOLD fold 7
[2025-10-25 11:53:38,211] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 11:53:38,228] INFO: Calculating technical indicators...
[2025-10-25 11:53:38,228] INFO: Calculating technical indicators...
[2025-10-25 11:53:38,232] INFO: Technical indicators calculated successfully
[2025-10-25 11:53:38,232] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 11:53:38,236] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:53:38,243] INFO: Return statistics: mean=0.0004, std=0.0108
[2025-10-25 11:53:38,243] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 11:53:38,243] INFO: Created 4877 sequences of length 60
[2025-10-25 11:53:38,243] INFO: Feature shape: (4877, 60, 13), Target shape: (4877,)
[2025-10-25 11:53:38,268] INFO: Scalers fitted on training data
[2025-10-25 11:53:38,268] INFO: Feature scaler mean: [1249.68169891 1258.81769386 1240.10214747]...
[2025-10-25 11:53:38,268] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 11:53:38,284] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 11:53:38,286] INFO: Return statistics: mean=0.0018, std=0.0129
[2025-10-25 11:53:38,286] INFO: Return range: [-0.0346, 0.1448]
[2025-10-25 11:53:38,286] INFO: Created 366 sequences of length 60
[2025-10-25 11:53:38,286] INFO: Feature shape: (366, 60, 13), Target shape: (366,)
[2025-10-25 11:53:38,287] INFO: Sequence building completed for GOLD
[2025-10-25 11:53:38,287] INFO: Training samples: 4877
[2025-10-25 11:53:38,289] INFO: Dataset initialized: 4877 samples, seq_len=60, features=13, device=mps
[2025-10-25 11:53:38,289] INFO: Training DataLoader: 4877 samples, 38 batches of size 128
[2025-10-25 11:53:38,305] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 11:53:38,305] INFO: Created basic model with 804097 parameters
[2025-10-25 11:53:38,310] INFO: Starting training for 400 epochs
[2025-10-25 11:53:47,509] INFO: Epoch 10: Train Loss 0.9881
[2025-10-25 11:53:56,528] INFO: Epoch 20: Train Loss 0.9466
[2025-10-25 11:54:05,524] INFO: Epoch 30: Train Loss 0.8112
[2025-10-25 11:54:14,524] INFO: Epoch 40: Train Loss 0.5918
[2025-10-25 11:54:23,487] INFO: Epoch 50: Train Loss 0.4192
[2025-10-25 11:54:32,475] INFO: Epoch 60: Train Loss 0.3043
[2025-10-25 11:54:41,364] INFO: Epoch 70: Train Loss 0.2157
[2025-10-25 11:54:50,317] INFO: Epoch 80: Train Loss 0.1591
[2025-10-25 11:54:59,282] INFO: Epoch 90: Train Loss 0.1318
[2025-10-25 11:55:08,275] INFO: Epoch 100: Train Loss 0.1106
[2025-10-25 11:55:17,256] INFO: Epoch 110: Train Loss 0.0851
[2025-10-25 11:55:26,094] INFO: Epoch 120: Train Loss 0.0820
[2025-10-25 11:55:35,101] INFO: Epoch 130: Train Loss 0.0685
[2025-10-25 11:55:44,065] INFO: Epoch 140: Train Loss 0.0632
[2025-10-25 11:55:53,052] INFO: Epoch 150: Train Loss 0.0611
[2025-10-25 11:56:02,236] INFO: Epoch 160: Train Loss 0.0581
[2025-10-25 11:56:11,079] INFO: Epoch 170: Train Loss 0.0509
[2025-10-25 11:56:20,124] INFO: Epoch 180: Train Loss 0.0477
[2025-10-25 11:56:29,092] INFO: Epoch 190: Train Loss 0.0465
[2025-10-25 11:56:38,112] INFO: Epoch 200: Train Loss 0.0460
[2025-10-25 11:56:47,102] INFO: Epoch 210: Train Loss 0.0448
[2025-10-25 11:56:56,142] INFO: Epoch 220: Train Loss 0.0417
[2025-10-25 11:57:04,985] INFO: Epoch 230: Train Loss 0.0387
[2025-10-25 11:57:14,010] INFO: Epoch 240: Train Loss 0.0357
[2025-10-25 11:57:23,037] INFO: Epoch 250: Train Loss 0.0349
[2025-10-25 11:57:51,147] INFO: Epoch 260: Train Loss 0.0341
[2025-10-25 11:58:27,430] INFO: Epoch 270: Train Loss 0.0337
[2025-10-25 11:58:40,983] INFO: Epoch 280: Train Loss 0.0304
[2025-10-25 11:58:50,026] INFO: Epoch 290: Train Loss 0.0311
[2025-10-25 11:58:59,077] INFO: Epoch 300: Train Loss 0.0313
[2025-10-25 11:59:08,124] INFO: Epoch 310: Train Loss 0.0305
[2025-10-25 11:59:17,174] INFO: Epoch 320: Train Loss 0.0280
[2025-10-25 11:59:26,251] INFO: Epoch 330: Train Loss 0.0273
[2025-10-25 12:00:01,362] INFO: Epoch 340: Train Loss 0.0258
[2025-10-25 12:00:34,945] INFO: Epoch 350: Train Loss 0.0272
[2025-10-25 12:01:11,038] INFO: Epoch 360: Train Loss 0.0271
[2025-10-25 12:01:46,661] INFO: Epoch 370: Train Loss 0.0263
[2025-10-25 12:02:22,073] INFO: Epoch 380: Train Loss 0.0255
[2025-10-25 12:02:57,422] INFO: Epoch 390: Train Loss 0.0265
[2025-10-25 12:03:34,216] INFO: Epoch 400: Train Loss 0.0266
[2025-10-25 12:03:34,247] INFO: âœ… Saved artifacts for GOLD fold 7 to models/GOLD/fold_7
[2025-10-25 12:03:34,247] INFO:    - Features: 13
[2025-10-25 12:03:34,247] INFO:    - Sequence length: 60
[2025-10-25 12:03:34,247] INFO:    - Model parameters: 804,097
[2025-10-25 12:03:34,247] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_7
[2025-10-25 12:03:34,247] INFO: Completed GOLD fold 7: Train samples 4877, Final train loss 0.0266
[2025-10-25 12:03:34,247] INFO: GOLD summary: Avg train loss 0.0281, Avg val loss nan
[2025-10-25 12:03:34,250] INFO: Training completed successfully. Summary saved to reports/training_summary.json
[2025-10-25 12:03:34,250] INFO: âœ… Training pipeline completed successfully

    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘               SENSEX & GOLD LSTM PRICE PREDICTOR                 â•‘
    â•‘                                                                  â•‘
    â•‘  ðŸ“ˆ Advanced LSTM models for financial time series prediction   â•‘
    â•‘  ðŸ”® Next-day price forecasting with temporal cross-validation   â•‘
    â•‘  ðŸŽ Optimized for Apple Silicon (MPS) and CUDA acceleration     â•‘
    â•‘  ðŸ“Š Real data verification and comprehensive evaluation          â•‘
    â•‘                                                                  â•‘
    â•‘  Assets: BSE SENSEX, Gold (INR)                                 â•‘
    â•‘  Horizon: T+1 (next business day)                               â•‘
    â•‘  Features: Technical indicators + price history                  â•‘
    â•‘                                                                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    

=== REAL DATA VERIFICATION STARTING ===

Verifying SENSEX data...
Found 1 file(s) for SENSEX
âœ… VERIFIED: SENSEX rows=5,478 span=2003-10-01â†’2025-10-21 gaps<=2 max_flat=1.0

Verifying GOLD data...
Found 1 file(s) for GOLD
âœ… VERIFIED: GOLD rows=5,383 span=2004-06-11â†’2025-09-30 gaps<=5 max_flat=3.0
ðŸ“ Hashes saved to logs/data_hashes.json

REAL DATA VERIFIED âœ…
