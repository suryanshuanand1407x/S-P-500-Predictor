[2025-10-25 12:35:20,797] INFO: Sensex & Gold LSTM Price Predictor starting...
[2025-10-25 12:35:20,797] INFO: ðŸ“‹ Loading configuration from: configs/tuned.yaml
[2025-10-25 12:35:20,799] INFO: âœ… Configuration validated successfully
[2025-10-25 12:35:20,799] INFO: ðŸ” Checking system requirements...
[2025-10-25 12:35:22,837] INFO: âœ… MPS (Apple Silicon) acceleration available
[2025-10-25 12:35:22,837] INFO: âœ… System requirements check passed
[2025-10-25 12:35:22,837] INFO: ðŸ“ Directory structure verified
[2025-10-25 12:35:22,837] INFO: ðŸš€ Starting LSTM training pipeline...
[2025-10-25 12:35:22,837] INFO: ðŸ“‹ Configuration: configs/tuned.yaml
[2025-10-25 12:35:22,927] INFO: === SENSEX-GOLD LSTM PREDICTOR TRAINING ===
[2025-10-25 12:35:22,927] INFO: Configuration: configs/tuned.yaml
[2025-10-25 12:35:22,929] INFO: Random seed set to 42
[2025-10-25 12:35:22,929] INFO: Using device: mps
[2025-10-25 12:35:22,929] INFO: Step 1: Verifying real data integrity...
[2025-10-25 12:35:23,013] INFO: Step 2: Ingesting and cleaning data...
[2025-10-25 12:35:23,013] INFO: Starting data ingestion pipeline
[2025-10-25 12:35:23,013] INFO: Processing SENSEX data from data/sensex/*.csv
[2025-10-25 12:35:23,013] INFO: Found 1 CSV files for SENSEX
[2025-10-25 12:35:23,013] INFO: Loading data/sensex/SENSEX_01102003_23102025.csv
[2025-10-25 12:35:23,022] INFO: Combined data: 5478 rows
[2025-10-25 12:35:23,025] INFO: After cleaning: 5478 rows
[2025-10-25 12:35:23,026] WARNING: Found 2 extreme price moves for SENSEX
[2025-10-25 12:35:23,026] WARNING: Extreme moves detected (review required):
[2025-10-25 12:35:23,028] WARNING: 
           Date     Close  daily_return
2480 2013-09-06  72643.43      2.827416
2481 2013-09-10  19997.09     -0.724723
[2025-10-25 12:35:23,028] CRITICAL: âš ï¸  CRITICAL DATA QUALITY ALERT âš ï¸
[2025-10-25 12:35:23,028] CRITICAL: 2 data points with >50% daily moves detected in SENSEX!
[2025-10-25 12:35:23,028] CRITICAL: These extreme values will be INTERPOLATED - manual verification recommended:
[2025-10-25 12:35:23,029] CRITICAL:   Date: 2013-09-06 00:00:00, Close: 72643.43, Return: 282.7%
[2025-10-25 12:35:23,029] CRITICAL:   Date: 2013-09-10 00:00:00, Close: 19997.09, Return: -72.5%
[2025-10-25 12:35:23,030] CRITICAL: ðŸ“Š Extreme moves report saved to: logs/SENSEX_extreme_moves_interpolated.csv
[2025-10-25 12:35:23,030] WARNING: Interpolating 2 extreme data points...
[2025-10-25 12:35:23,032] WARNING: âœ“ Interpolation complete. Original extreme values preserved in report.
[2025-10-25 12:35:23,033] INFO: Processed SENSEX to 5478 days (keeping original trading calendar)
[2025-10-25 12:35:23,033] INFO: After resampling: 5478 rows
[2025-10-25 12:35:23,076] INFO: Saved processed SENSEX data to data/processed/sensex_clean.csv
[2025-10-25 12:35:23,076] INFO: âœ… Sensex processing completed
[2025-10-25 12:35:23,076] INFO: Processing GOLD data from data/gold/XAU_1d_data.csv
[2025-10-25 12:35:23,076] INFO: Found 1 CSV files for GOLD
[2025-10-25 12:35:23,076] INFO: Loading data/gold/XAU_1d_data.csv
[2025-10-25 12:35:23,079] INFO: Combined data: 5383 rows
[2025-10-25 12:35:23,081] INFO: After cleaning: 5383 rows
[2025-10-25 12:35:23,083] INFO: Processed GOLD to 5383 days (keeping original trading calendar)
[2025-10-25 12:35:23,083] INFO: After resampling: 5383 rows
[2025-10-25 12:35:23,107] INFO: Saved processed GOLD data to data/processed/gold_clean.csv
[2025-10-25 12:35:23,108] INFO: âœ… Gold processing completed
[2025-10-25 12:35:23,108] INFO: Data ingestion pipeline completed successfully
[2025-10-25 12:35:23,108] INFO: Step 3: Creating temporal cross-validation folds...
[2025-10-25 12:35:23,122] INFO: Data range: 2003-10-01 to 2025-10-21
[2025-10-25 12:35:23,122] INFO: Test holdout: 2025-04-21 to 2025-10-21
[2025-10-25 12:35:23,122] INFO: Available for train/val: 2003-10-01 to 2025-04-21
[2025-10-25 12:35:23,122] INFO: Total available months: 258
[2025-10-25 12:35:23,122] INFO: Training range: 120 to 257 months
[2025-10-25 12:35:23,123] INFO: Fold 0: Train 2003-10-01 to 2013-10-01 (2497 samples), Val 2013-10-01 to 2013-11-01 (21 samples), Test 2025-04-21 to 2025-10-21 (127 samples)
[2025-10-25 12:35:23,124] INFO: Fold 1: Train 2003-10-01 to 2015-05-01 (2883 samples), Val 2015-05-01 to 2015-06-01 (21 samples), Test 2025-04-21 to 2025-10-21 (127 samples)
[2025-10-25 12:35:23,124] INFO: Fold 2: Train 2003-10-01 to 2016-12-01 (3276 samples), Val 2016-12-01 to 2017-01-01 (21 samples), Test 2025-04-21 to 2025-10-21 (127 samples)
[2025-10-25 12:35:23,125] INFO: Fold 3: Train 2003-10-01 to 2018-07-01 (3669 samples), Val 2018-07-01 to 2018-08-01 (23 samples), Test 2025-04-21 to 2025-10-21 (127 samples)
[2025-10-25 12:35:23,126] INFO: Fold 4: Train 2003-10-01 to 2020-02-01 (4060 samples), Val 2020-02-01 to 2020-03-01 (19 samples), Test 2025-04-21 to 2025-10-21 (127 samples)
[2025-10-25 12:35:23,127] INFO: Fold 5: Train 2003-10-01 to 2021-09-01 (4453 samples), Val 2021-09-01 to 2021-10-01 (21 samples), Test 2025-04-21 to 2025-10-21 (127 samples)
[2025-10-25 12:35:23,127] INFO: Fold 6: Train 2003-10-01 to 2023-04-01 (4846 samples), Val 2023-04-01 to 2023-05-01 (17 samples), Test 2025-04-21 to 2025-10-21 (127 samples)
[2025-10-25 12:35:23,128] INFO: Fold 7: Train 2003-10-01 to 2024-11-01 (5238 samples), Val 2024-11-01 to 2024-12-01 (18 samples), Test 2025-04-21 to 2025-10-21 (127 samples)
[2025-10-25 12:35:23,128] INFO: Step 4: Training LSTM models...
[2025-10-25 12:35:23,128] INFO: 
=== Training SENSEX models ===
[2025-10-25 12:35:23,128] INFO: Training SENSEX fold 0
[2025-10-25 12:35:23,128] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 12:35:23,142] INFO: Calculating technical indicators...
[2025-10-25 12:35:23,142] INFO: Calculating technical indicators...
[2025-10-25 12:35:23,145] INFO: Technical indicators calculated successfully
[2025-10-25 12:35:23,146] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 12:35:23,149] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:35:23,153] INFO: Return statistics: mean=0.0006, std=0.0164
[2025-10-25 12:35:23,153] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 12:35:23,153] INFO: Created 2437 sequences of length 60
[2025-10-25 12:35:23,153] INFO: Feature shape: (2437, 60, 13), Target shape: (2437,)
[2025-10-25 12:35:23,164] INFO: Scalers fitted on training data
[2025-10-25 12:35:23,164] INFO: Feature scaler mean: [13782.36470963 13891.84621099 13650.9500746 ]...
[2025-10-25 12:35:23,164] INFO: Target scaler mean: 0.00, std: 0.02
[2025-10-25 12:35:23,170] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:35:23,174] INFO: Return statistics: mean=0.0005, std=0.0102
[2025-10-25 12:35:23,174] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 12:35:23,174] INFO: Created 2900 sequences of length 60
[2025-10-25 12:35:23,174] INFO: Feature shape: (2900, 60, 13), Target shape: (2900,)
[2025-10-25 12:35:23,183] INFO: Sequence building completed for SENSEX
[2025-10-25 12:35:23,183] INFO: Training samples: 2437
[2025-10-25 12:35:23,197] INFO: Dataset initialized: 2437 samples, seq_len=60, features=13, device=mps
[2025-10-25 12:35:23,197] INFO: Training DataLoader: 2437 samples, 19 batches of size 128
[2025-10-25 12:35:23,226] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 12:35:23,226] INFO: Created basic model with 804097 parameters
[2025-10-25 12:35:23,861] INFO: Starting training for 400 epochs
[2025-10-25 12:35:28,821] INFO: Epoch 10: Train Loss 0.9857
[2025-10-25 12:35:33,495] INFO: Epoch 20: Train Loss 0.9650
[2025-10-25 12:35:38,022] INFO: Epoch 30: Train Loss 0.8329
[2025-10-25 12:35:42,507] INFO: Epoch 40: Train Loss 0.7342
[2025-10-25 12:35:46,957] INFO: Epoch 50: Train Loss 0.5738
[2025-10-25 12:35:51,393] INFO: Epoch 60: Train Loss 0.4247
[2025-10-25 12:35:56,036] INFO: Epoch 70: Train Loss 0.3213
[2025-10-25 12:36:00,556] INFO: Epoch 80: Train Loss 0.2372
[2025-10-25 12:36:05,040] INFO: Epoch 90: Train Loss 0.1908
[2025-10-25 12:36:09,553] INFO: Epoch 100: Train Loss 0.1483
[2025-10-25 12:36:14,009] INFO: Epoch 110: Train Loss 0.1257
[2025-10-25 12:36:18,540] INFO: Epoch 120: Train Loss 0.1155
[2025-10-25 12:36:23,015] INFO: Epoch 130: Train Loss 0.0870
[2025-10-25 12:36:27,527] INFO: Epoch 140: Train Loss 0.0860
[2025-10-25 12:36:32,037] INFO: Epoch 150: Train Loss 0.0733
[2025-10-25 12:36:36,611] INFO: Epoch 160: Train Loss 0.0695
[2025-10-25 12:36:41,039] INFO: Epoch 170: Train Loss 0.0606
[2025-10-25 12:36:45,543] INFO: Epoch 180: Train Loss 0.0608
[2025-10-25 12:36:50,043] INFO: Epoch 190: Train Loss 0.0506
[2025-10-25 12:36:54,499] INFO: Epoch 200: Train Loss 0.0518
[2025-10-25 12:36:59,102] INFO: Epoch 210: Train Loss 0.0488
[2025-10-25 12:37:03,576] INFO: Epoch 220: Train Loss 0.0481
[2025-10-25 12:37:08,025] INFO: Epoch 230: Train Loss 0.0427
[2025-10-25 12:37:12,475] INFO: Epoch 240: Train Loss 0.0428
[2025-10-25 12:37:16,935] INFO: Epoch 250: Train Loss 0.0404
[2025-10-25 12:37:21,417] INFO: Epoch 260: Train Loss 0.0399
[2025-10-25 12:37:25,875] INFO: Epoch 270: Train Loss 0.0392
[2025-10-25 12:37:30,331] INFO: Epoch 280: Train Loss 0.0377
[2025-10-25 12:37:34,817] INFO: Epoch 290: Train Loss 0.0346
[2025-10-25 12:37:39,355] INFO: Epoch 300: Train Loss 0.0349
[2025-10-25 12:37:43,966] INFO: Epoch 310: Train Loss 0.0327
[2025-10-25 12:37:48,665] INFO: Epoch 320: Train Loss 0.0345
[2025-10-25 12:37:53,252] INFO: Epoch 330: Train Loss 0.0324
[2025-10-25 12:37:57,769] INFO: Epoch 340: Train Loss 0.0301
[2025-10-25 12:38:02,260] INFO: Epoch 350: Train Loss 0.0313
[2025-10-25 12:38:06,723] INFO: Epoch 360: Train Loss 0.0295
[2025-10-25 12:38:11,353] INFO: Epoch 370: Train Loss 0.0297
[2025-10-25 12:38:15,848] INFO: Epoch 380: Train Loss 0.0294
[2025-10-25 12:38:20,331] INFO: Epoch 390: Train Loss 0.0301
[2025-10-25 12:38:24,993] INFO: Epoch 400: Train Loss 0.0304
[2025-10-25 12:38:25,022] INFO: âœ… Saved artifacts for SENSEX fold 0 to models/SENSEX/fold_0
[2025-10-25 12:38:25,022] INFO:    - Features: 13
[2025-10-25 12:38:25,022] INFO:    - Sequence length: 60
[2025-10-25 12:38:25,022] INFO:    - Model parameters: 804,097
[2025-10-25 12:38:25,022] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_0
[2025-10-25 12:38:25,022] INFO: Completed SENSEX fold 0: Train samples 2437, Final train loss 0.0304
[2025-10-25 12:38:25,022] INFO: Training SENSEX fold 1
[2025-10-25 12:38:25,022] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 12:38:25,044] INFO: Calculating technical indicators...
[2025-10-25 12:38:25,045] INFO: Calculating technical indicators...
[2025-10-25 12:38:25,049] INFO: Technical indicators calculated successfully
[2025-10-25 12:38:25,050] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 12:38:25,054] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:38:25,060] INFO: Return statistics: mean=0.0007, std=0.0156
[2025-10-25 12:38:25,060] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 12:38:25,060] INFO: Created 2823 sequences of length 60
[2025-10-25 12:38:25,060] INFO: Feature shape: (2823, 60, 13), Target shape: (2823,)
[2025-10-25 12:38:25,073] INFO: Scalers fitted on training data
[2025-10-25 12:38:25,073] INFO: Feature scaler mean: [15197.27508916 15308.48174641 15063.10144546]...
[2025-10-25 12:38:25,073] INFO: Target scaler mean: 0.00, std: 0.02
[2025-10-25 12:38:25,084] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:38:25,088] INFO: Return statistics: mean=0.0005, std=0.0103
[2025-10-25 12:38:25,088] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 12:38:25,088] INFO: Created 2514 sequences of length 60
[2025-10-25 12:38:25,088] INFO: Feature shape: (2514, 60, 13), Target shape: (2514,)
[2025-10-25 12:38:25,096] INFO: Sequence building completed for SENSEX
[2025-10-25 12:38:25,096] INFO: Training samples: 2823
[2025-10-25 12:38:25,097] INFO: Dataset initialized: 2823 samples, seq_len=60, features=13, device=mps
[2025-10-25 12:38:25,097] INFO: Training DataLoader: 2823 samples, 22 batches of size 128
[2025-10-25 12:38:25,116] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 12:38:25,116] INFO: Created basic model with 804097 parameters
[2025-10-25 12:38:25,119] INFO: Starting training for 400 epochs
[2025-10-25 12:38:30,339] INFO: Epoch 10: Train Loss 0.9866
[2025-10-25 12:38:35,538] INFO: Epoch 20: Train Loss 0.9118
[2025-10-25 12:38:40,725] INFO: Epoch 30: Train Loss 0.7953
[2025-10-25 12:38:46,144] INFO: Epoch 40: Train Loss 0.6610
[2025-10-25 12:38:51,623] INFO: Epoch 50: Train Loss 0.5138
[2025-10-25 12:38:57,031] INFO: Epoch 60: Train Loss 0.3967
[2025-10-25 12:39:02,409] INFO: Epoch 70: Train Loss 0.2828
[2025-10-25 12:39:07,830] INFO: Epoch 80: Train Loss 0.2190
[2025-10-25 12:39:13,222] INFO: Epoch 90: Train Loss 0.1645
[2025-10-25 12:39:18,631] INFO: Epoch 100: Train Loss 0.1397
[2025-10-25 12:39:24,014] INFO: Epoch 110: Train Loss 0.1272
[2025-10-25 12:39:29,547] INFO: Epoch 120: Train Loss 0.1013
[2025-10-25 12:39:35,012] INFO: Epoch 130: Train Loss 0.0801
[2025-10-25 12:39:40,319] INFO: Epoch 140: Train Loss 0.0781
[2025-10-25 12:39:45,851] INFO: Epoch 150: Train Loss 0.0679
[2025-10-25 12:39:51,195] INFO: Epoch 160: Train Loss 0.0601
[2025-10-25 12:39:56,508] INFO: Epoch 170: Train Loss 0.0612
[2025-10-25 12:40:01,850] INFO: Epoch 180: Train Loss 0.0527
[2025-10-25 12:40:07,171] INFO: Epoch 190: Train Loss 0.0524
[2025-10-25 12:40:12,495] INFO: Epoch 200: Train Loss 0.0461
[2025-10-25 12:40:17,824] INFO: Epoch 210: Train Loss 0.0459
[2025-10-25 12:40:23,398] INFO: Epoch 220: Train Loss 0.0432
[2025-10-25 12:40:28,777] INFO: Epoch 230: Train Loss 0.0399
[2025-10-25 12:40:34,371] INFO: Epoch 240: Train Loss 0.0397
[2025-10-25 12:40:39,801] INFO: Epoch 250: Train Loss 0.0359
[2025-10-25 12:40:45,216] INFO: Epoch 260: Train Loss 0.0359
[2025-10-25 12:40:50,613] INFO: Epoch 270: Train Loss 0.0335
[2025-10-25 12:40:56,027] INFO: Epoch 280: Train Loss 0.0332
[2025-10-25 12:41:01,445] INFO: Epoch 290: Train Loss 0.0337
[2025-10-25 12:41:06,847] INFO: Epoch 300: Train Loss 0.0334
[2025-10-25 12:41:12,247] INFO: Epoch 310: Train Loss 0.0317
[2025-10-25 12:41:17,660] INFO: Epoch 320: Train Loss 0.0315
[2025-10-25 12:41:23,110] INFO: Epoch 330: Train Loss 0.0313
[2025-10-25 12:41:28,580] INFO: Epoch 340: Train Loss 0.0301
[2025-10-25 12:41:34,045] INFO: Epoch 350: Train Loss 0.0280
[2025-10-25 12:41:39,426] INFO: Epoch 360: Train Loss 0.0298
[2025-10-25 12:41:44,973] INFO: Epoch 370: Train Loss 0.0275
[2025-10-25 12:41:50,350] INFO: Epoch 380: Train Loss 0.0283
[2025-10-25 12:41:55,694] INFO: Epoch 390: Train Loss 0.0289
[2025-10-25 12:42:01,022] INFO: Epoch 400: Train Loss 0.0279
[2025-10-25 12:42:01,040] INFO: âœ… Saved artifacts for SENSEX fold 1 to models/SENSEX/fold_1
[2025-10-25 12:42:01,040] INFO:    - Features: 13
[2025-10-25 12:42:01,040] INFO:    - Sequence length: 60
[2025-10-25 12:42:01,040] INFO:    - Model parameters: 804,097
[2025-10-25 12:42:01,040] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_1
[2025-10-25 12:42:01,040] INFO: Completed SENSEX fold 1: Train samples 2823, Final train loss 0.0279
[2025-10-25 12:42:01,041] INFO: Training SENSEX fold 2
[2025-10-25 12:42:01,041] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 12:42:01,057] INFO: Calculating technical indicators...
[2025-10-25 12:42:01,057] INFO: Calculating technical indicators...
[2025-10-25 12:42:01,060] INFO: Technical indicators calculated successfully
[2025-10-25 12:42:01,061] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 12:42:01,065] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:42:01,071] INFO: Return statistics: mean=0.0006, std=0.0150
[2025-10-25 12:42:01,071] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 12:42:01,071] INFO: Created 3216 sequences of length 60
[2025-10-25 12:42:01,071] INFO: Feature shape: (3216, 60, 13), Target shape: (3216,)
[2025-10-25 12:42:01,085] INFO: Scalers fitted on training data
[2025-10-25 12:42:01,085] INFO: Feature scaler mean: [16601.12909688 16713.8520173  16460.02189007]...
[2025-10-25 12:42:01,085] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 12:42:01,095] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:42:01,099] INFO: Return statistics: mean=0.0006, std=0.0106
[2025-10-25 12:42:01,099] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 12:42:01,099] INFO: Created 2121 sequences of length 60
[2025-10-25 12:42:01,099] INFO: Feature shape: (2121, 60, 13), Target shape: (2121,)
[2025-10-25 12:42:01,107] INFO: Sequence building completed for SENSEX
[2025-10-25 12:42:01,107] INFO: Training samples: 3216
[2025-10-25 12:42:01,109] INFO: Dataset initialized: 3216 samples, seq_len=60, features=13, device=mps
[2025-10-25 12:42:01,109] INFO: Training DataLoader: 3216 samples, 25 batches of size 128
[2025-10-25 12:42:01,126] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 12:42:01,127] INFO: Created basic model with 804097 parameters
[2025-10-25 12:42:01,130] INFO: Starting training for 400 epochs
[2025-10-25 12:42:07,183] INFO: Epoch 10: Train Loss 0.9914
[2025-10-25 12:42:13,219] INFO: Epoch 20: Train Loss 0.9378
[2025-10-25 12:42:19,379] INFO: Epoch 30: Train Loss 0.8106
[2025-10-25 12:42:25,624] INFO: Epoch 40: Train Loss 0.6534
[2025-10-25 12:42:31,892] INFO: Epoch 50: Train Loss 0.4768
[2025-10-25 12:42:37,954] INFO: Epoch 60: Train Loss 0.3410
[2025-10-25 12:42:44,008] INFO: Epoch 70: Train Loss 0.2436
[2025-10-25 12:42:50,042] INFO: Epoch 80: Train Loss 0.1774
[2025-10-25 12:42:56,085] INFO: Epoch 90: Train Loss 0.1349
[2025-10-25 12:43:02,154] INFO: Epoch 100: Train Loss 0.1179
[2025-10-25 12:43:08,493] INFO: Epoch 110: Train Loss 0.0949
[2025-10-25 12:43:14,558] INFO: Epoch 120: Train Loss 0.0794
[2025-10-25 12:43:20,611] INFO: Epoch 130: Train Loss 0.0740
[2025-10-25 12:43:26,673] INFO: Epoch 140: Train Loss 0.0624
[2025-10-25 12:43:32,716] INFO: Epoch 150: Train Loss 0.0616
[2025-10-25 12:43:38,776] INFO: Epoch 160: Train Loss 0.0529
[2025-10-25 12:43:44,838] INFO: Epoch 170: Train Loss 0.0523
[2025-10-25 12:43:50,919] INFO: Epoch 180: Train Loss 0.0485
[2025-10-25 12:43:56,949] INFO: Epoch 190: Train Loss 0.0458
[2025-10-25 12:44:03,082] INFO: Epoch 200: Train Loss 0.0415
[2025-10-25 12:44:09,093] INFO: Epoch 210: Train Loss 0.0399
[2025-10-25 12:44:15,289] INFO: Epoch 220: Train Loss 0.0370
[2025-10-25 12:44:21,403] INFO: Epoch 230: Train Loss 0.0363
[2025-10-25 12:44:27,432] INFO: Epoch 240: Train Loss 0.0373
[2025-10-25 12:44:33,624] INFO: Epoch 250: Train Loss 0.0340
[2025-10-25 12:44:39,822] INFO: Epoch 260: Train Loss 0.0325
[2025-10-25 12:44:45,864] INFO: Epoch 270: Train Loss 0.0323
[2025-10-25 12:44:51,969] INFO: Epoch 280: Train Loss 0.0313
[2025-10-25 12:44:58,010] INFO: Epoch 290: Train Loss 0.0289
[2025-10-25 12:45:04,043] INFO: Epoch 300: Train Loss 0.0284
[2025-10-25 12:45:10,090] INFO: Epoch 310: Train Loss 0.0276
[2025-10-25 12:45:16,207] INFO: Epoch 320: Train Loss 0.0268
[2025-10-25 12:45:22,259] INFO: Epoch 330: Train Loss 0.0262
[2025-10-25 12:45:28,315] INFO: Epoch 340: Train Loss 0.0251
[2025-10-25 12:45:34,354] INFO: Epoch 350: Train Loss 0.0262
[2025-10-25 12:45:40,389] INFO: Epoch 360: Train Loss 0.0252
[2025-10-25 12:45:46,470] INFO: Epoch 370: Train Loss 0.0249
[2025-10-25 12:45:52,489] INFO: Epoch 380: Train Loss 0.0255
[2025-10-25 12:45:58,535] INFO: Epoch 390: Train Loss 0.0264
[2025-10-25 12:46:04,591] INFO: Epoch 400: Train Loss 0.0245
[2025-10-25 12:46:04,615] INFO: âœ… Saved artifacts for SENSEX fold 2 to models/SENSEX/fold_2
[2025-10-25 12:46:04,615] INFO:    - Features: 13
[2025-10-25 12:46:04,615] INFO:    - Sequence length: 60
[2025-10-25 12:46:04,615] INFO:    - Model parameters: 804,097
[2025-10-25 12:46:04,615] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_2
[2025-10-25 12:46:04,615] INFO: Completed SENSEX fold 2: Train samples 3216, Final train loss 0.0245
[2025-10-25 12:46:04,616] INFO: Training SENSEX fold 3
[2025-10-25 12:46:04,616] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 12:46:04,635] INFO: Calculating technical indicators...
[2025-10-25 12:46:04,635] INFO: Calculating technical indicators...
[2025-10-25 12:46:04,639] INFO: Technical indicators calculated successfully
[2025-10-25 12:46:04,640] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 12:46:04,645] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:46:04,650] INFO: Return statistics: mean=0.0006, std=0.0143
[2025-10-25 12:46:04,650] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 12:46:04,650] INFO: Created 3609 sequences of length 60
[2025-10-25 12:46:04,650] INFO: Feature shape: (3609, 60, 13), Target shape: (3609,)
[2025-10-25 12:46:04,667] INFO: Scalers fitted on training data
[2025-10-25 12:46:04,667] INFO: Feature scaler mean: [18195.09787136 18308.03160529 18052.97630329]...
[2025-10-25 12:46:04,667] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 12:46:04,679] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:46:04,682] INFO: Return statistics: mean=0.0006, std=0.0112
[2025-10-25 12:46:04,682] INFO: Return range: [-0.1315, 0.0897]
[2025-10-25 12:46:04,682] INFO: Created 1726 sequences of length 60
[2025-10-25 12:46:04,682] INFO: Feature shape: (1726, 60, 13), Target shape: (1726,)
[2025-10-25 12:46:04,686] INFO: Sequence building completed for SENSEX
[2025-10-25 12:46:04,686] INFO: Training samples: 3609
[2025-10-25 12:46:04,688] INFO: Dataset initialized: 3609 samples, seq_len=60, features=13, device=mps
[2025-10-25 12:46:04,688] INFO: Training DataLoader: 3609 samples, 28 batches of size 128
[2025-10-25 12:46:04,705] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 12:46:04,705] INFO: Created basic model with 804097 parameters
[2025-10-25 12:46:04,712] INFO: Starting training for 400 epochs
[2025-10-25 12:46:11,513] INFO: Epoch 10: Train Loss 0.9826
[2025-10-25 12:46:18,221] INFO: Epoch 20: Train Loss 0.9411
[2025-10-25 12:46:24,940] INFO: Epoch 30: Train Loss 0.7956
[2025-10-25 12:46:31,819] INFO: Epoch 40: Train Loss 0.6184
[2025-10-25 12:46:38,658] INFO: Epoch 50: Train Loss 0.4400
[2025-10-25 12:46:45,517] INFO: Epoch 60: Train Loss 0.2844
[2025-10-25 12:46:52,346] INFO: Epoch 70: Train Loss 0.2065
[2025-10-25 12:46:59,181] INFO: Epoch 80: Train Loss 0.1484
[2025-10-25 12:47:06,005] INFO: Epoch 90: Train Loss 0.1232
[2025-10-25 12:47:12,825] INFO: Epoch 100: Train Loss 0.1018
[2025-10-25 12:47:19,866] INFO: Epoch 110: Train Loss 0.0832
[2025-10-25 12:47:26,735] INFO: Epoch 120: Train Loss 0.0787
[2025-10-25 12:47:33,479] INFO: Epoch 130: Train Loss 0.0685
[2025-10-25 12:47:40,272] INFO: Epoch 140: Train Loss 0.0616
[2025-10-25 12:47:46,984] INFO: Epoch 150: Train Loss 0.0563
[2025-10-25 12:47:53,749] INFO: Epoch 160: Train Loss 0.0561
[2025-10-25 12:48:00,582] INFO: Epoch 170: Train Loss 0.0490
[2025-10-25 12:48:07,406] INFO: Epoch 180: Train Loss 0.0419
[2025-10-25 12:48:14,161] INFO: Epoch 190: Train Loss 0.0431
[2025-10-25 12:48:20,898] INFO: Epoch 200: Train Loss 0.0396
[2025-10-25 12:48:27,610] INFO: Epoch 210: Train Loss 0.0401
[2025-10-25 12:48:34,327] INFO: Epoch 220: Train Loss 0.0372
[2025-10-25 12:48:41,063] INFO: Epoch 230: Train Loss 0.0352
[2025-10-25 12:48:47,800] INFO: Epoch 240: Train Loss 0.0332
[2025-10-25 12:48:54,537] INFO: Epoch 250: Train Loss 0.0329
[2025-10-25 12:49:01,310] INFO: Epoch 260: Train Loss 0.0303
[2025-10-25 12:49:08,025] INFO: Epoch 270: Train Loss 0.0299
[2025-10-25 12:49:14,750] INFO: Epoch 280: Train Loss 0.0290
[2025-10-25 12:49:21,510] INFO: Epoch 290: Train Loss 0.0287
[2025-10-25 12:49:28,209] INFO: Epoch 300: Train Loss 0.0271
[2025-10-25 12:49:34,935] INFO: Epoch 310: Train Loss 0.0264
[2025-10-25 12:49:41,642] INFO: Epoch 320: Train Loss 0.0259
[2025-10-25 12:49:48,521] INFO: Epoch 330: Train Loss 0.0261
[2025-10-25 12:49:55,384] INFO: Epoch 340: Train Loss 0.0252
[2025-10-25 12:50:02,218] INFO: Epoch 350: Train Loss 0.0246
[2025-10-25 12:50:09,076] INFO: Epoch 360: Train Loss 0.0244
[2025-10-25 12:50:15,902] INFO: Epoch 370: Train Loss 0.0246
[2025-10-25 12:50:22,774] INFO: Epoch 380: Train Loss 0.0253
[2025-10-25 12:50:29,611] INFO: Epoch 390: Train Loss 0.0236
[2025-10-25 12:50:36,486] INFO: Epoch 400: Train Loss 0.0246
[2025-10-25 12:50:36,505] INFO: âœ… Saved artifacts for SENSEX fold 3 to models/SENSEX/fold_3
[2025-10-25 12:50:36,506] INFO:    - Features: 13
[2025-10-25 12:50:36,506] INFO:    - Sequence length: 60
[2025-10-25 12:50:36,506] INFO:    - Model parameters: 804,097
[2025-10-25 12:50:36,506] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_3
[2025-10-25 12:50:36,506] INFO: Completed SENSEX fold 3: Train samples 3609, Final train loss 0.0246
[2025-10-25 12:50:36,506] INFO: Training SENSEX fold 4
[2025-10-25 12:50:36,506] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 12:50:36,524] INFO: Calculating technical indicators...
[2025-10-25 12:50:36,524] INFO: Calculating technical indicators...
[2025-10-25 12:50:36,527] INFO: Technical indicators calculated successfully
[2025-10-25 12:50:36,528] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 12:50:36,531] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:50:36,537] INFO: Return statistics: mean=0.0006, std=0.0138
[2025-10-25 12:50:36,537] INFO: Return range: [-0.1114, 0.1734]
[2025-10-25 12:50:36,537] INFO: Created 4000 sequences of length 60
[2025-10-25 12:50:36,537] INFO: Feature shape: (4000, 60, 13), Target shape: (4000,)
[2025-10-25 12:50:36,554] INFO: Scalers fitted on training data
[2025-10-25 12:50:36,555] INFO: Feature scaler mean: [20079.73273679 20196.32980303 19926.35556346]...
[2025-10-25 12:50:36,555] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 12:50:36,568] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:50:36,570] INFO: Return statistics: mean=0.0007, std=0.0091
[2025-10-25 12:50:36,570] INFO: Return range: [-0.0574, 0.0500]
[2025-10-25 12:50:36,570] INFO: Created 1339 sequences of length 60
[2025-10-25 12:50:36,570] INFO: Feature shape: (1339, 60, 13), Target shape: (1339,)
[2025-10-25 12:50:36,573] INFO: Sequence building completed for SENSEX
[2025-10-25 12:50:36,573] INFO: Training samples: 4000
[2025-10-25 12:50:36,575] INFO: Dataset initialized: 4000 samples, seq_len=60, features=13, device=mps
[2025-10-25 12:50:36,575] INFO: Training DataLoader: 4000 samples, 31 batches of size 128
[2025-10-25 12:50:36,594] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 12:50:36,594] INFO: Created basic model with 804097 parameters
[2025-10-25 12:50:36,601] INFO: Starting training for 400 epochs
[2025-10-25 12:50:44,302] INFO: Epoch 10: Train Loss 0.9778
[2025-10-25 12:50:52,007] INFO: Epoch 20: Train Loss 0.9307
[2025-10-25 12:50:59,667] INFO: Epoch 30: Train Loss 0.7804
[2025-10-25 12:51:07,313] INFO: Epoch 40: Train Loss 0.5921
[2025-10-25 12:51:14,954] INFO: Epoch 50: Train Loss 0.3966
[2025-10-25 12:51:22,581] INFO: Epoch 60: Train Loss 0.2693
[2025-10-25 12:51:30,232] INFO: Epoch 70: Train Loss 0.1738
[2025-10-25 12:51:37,884] INFO: Epoch 80: Train Loss 0.1418
[2025-10-25 12:51:45,644] INFO: Epoch 90: Train Loss 0.1114
[2025-10-25 12:51:53,260] INFO: Epoch 100: Train Loss 0.0906
[2025-10-25 12:52:00,972] INFO: Epoch 110: Train Loss 0.0835
[2025-10-25 12:52:08,326] INFO: Epoch 120: Train Loss 0.0718
[2025-10-25 12:52:15,646] INFO: Epoch 130: Train Loss 0.0648
[2025-10-25 12:52:23,004] INFO: Epoch 140: Train Loss 0.0627
[2025-10-25 12:52:30,341] INFO: Epoch 150: Train Loss 0.0536
[2025-10-25 12:52:37,664] INFO: Epoch 160: Train Loss 0.0474
[2025-10-25 12:52:44,985] INFO: Epoch 170: Train Loss 0.0469
[2025-10-25 12:52:52,306] INFO: Epoch 180: Train Loss 0.0477
[2025-10-25 12:52:59,605] INFO: Epoch 190: Train Loss 0.0424
[2025-10-25 12:53:06,899] INFO: Epoch 200: Train Loss 0.0406
[2025-10-25 12:53:14,207] INFO: Epoch 210: Train Loss 0.0359
[2025-10-25 12:53:21,487] INFO: Epoch 220: Train Loss 0.0350
[2025-10-25 12:53:29,044] INFO: Epoch 230: Train Loss 0.0323
[2025-10-25 12:53:36,696] INFO: Epoch 240: Train Loss 0.0321
[2025-10-25 12:53:44,389] INFO: Epoch 250: Train Loss 0.0304
[2025-10-25 12:53:51,973] INFO: Epoch 260: Train Loss 0.0297
[2025-10-25 12:53:59,671] INFO: Epoch 270: Train Loss 0.0289
[2025-10-25 12:54:07,202] INFO: Epoch 280: Train Loss 0.0273
[2025-10-25 12:54:14,745] INFO: Epoch 290: Train Loss 0.0260
[2025-10-25 12:54:22,285] INFO: Epoch 300: Train Loss 0.0272
[2025-10-25 12:54:29,903] INFO: Epoch 310: Train Loss 0.0244
[2025-10-25 12:54:37,483] INFO: Epoch 320: Train Loss 0.0258
[2025-10-25 12:54:45,271] INFO: Epoch 330: Train Loss 0.0249
[2025-10-25 12:54:52,908] INFO: Epoch 340: Train Loss 0.0239
[2025-10-25 12:55:00,541] INFO: Epoch 350: Train Loss 0.0237
[2025-10-25 12:55:08,090] INFO: Epoch 360: Train Loss 0.0227
[2025-10-25 12:55:15,555] INFO: Epoch 370: Train Loss 0.0237
[2025-10-25 12:55:23,036] INFO: Epoch 380: Train Loss 0.0239
[2025-10-25 12:55:30,476] INFO: Epoch 390: Train Loss 0.0242
[2025-10-25 12:55:38,207] INFO: Epoch 400: Train Loss 0.0221
[2025-10-25 12:55:38,232] INFO: âœ… Saved artifacts for SENSEX fold 4 to models/SENSEX/fold_4
[2025-10-25 12:55:38,232] INFO:    - Features: 13
[2025-10-25 12:55:38,232] INFO:    - Sequence length: 60
[2025-10-25 12:55:38,232] INFO:    - Model parameters: 804,097
[2025-10-25 12:55:38,232] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_4
[2025-10-25 12:55:38,232] INFO: Completed SENSEX fold 4: Train samples 4000, Final train loss 0.0221
[2025-10-25 12:55:38,232] INFO: Training SENSEX fold 5
[2025-10-25 12:55:38,232] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 12:55:38,253] INFO: Calculating technical indicators...
[2025-10-25 12:55:38,254] INFO: Calculating technical indicators...
[2025-10-25 12:55:38,257] INFO: Technical indicators calculated successfully
[2025-10-25 12:55:38,257] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 12:55:38,261] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:55:38,269] INFO: Return statistics: mean=0.0006, std=0.0142
[2025-10-25 12:55:38,269] INFO: Return range: [-0.1315, 0.1734]
[2025-10-25 12:55:38,269] INFO: Created 4393 sequences of length 60
[2025-10-25 12:55:38,269] INFO: Feature shape: (4393, 60, 13), Target shape: (4393,)
[2025-10-25 12:55:38,290] INFO: Scalers fitted on training data
[2025-10-25 12:55:38,290] INFO: Feature scaler mean: [22071.82399767 22201.28501312 21897.14903404]...
[2025-10-25 12:55:38,290] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 12:55:38,307] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 12:55:38,309] INFO: Return statistics: mean=0.0004, std=0.0087
[2025-10-25 12:55:38,309] INFO: Return range: [-0.0574, 0.0374]
[2025-10-25 12:55:38,309] INFO: Created 944 sequences of length 60
[2025-10-25 12:55:38,309] INFO: Feature shape: (944, 60, 13), Target shape: (944,)
[2025-10-25 12:55:38,312] INFO: Sequence building completed for SENSEX
[2025-10-25 12:55:38,312] INFO: Training samples: 4393
[2025-10-25 12:55:38,313] INFO: Dataset initialized: 4393 samples, seq_len=60, features=13, device=mps
[2025-10-25 12:55:38,313] INFO: Training DataLoader: 4393 samples, 34 batches of size 128
[2025-10-25 12:55:38,331] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 12:55:38,331] INFO: Created basic model with 804097 parameters
[2025-10-25 12:55:38,334] INFO: Starting training for 400 epochs
[2025-10-25 12:55:46,620] INFO: Epoch 10: Train Loss 0.9960
[2025-10-25 12:55:54,901] INFO: Epoch 20: Train Loss 0.9456
[2025-10-25 12:56:03,187] INFO: Epoch 30: Train Loss 0.8923
[2025-10-25 12:56:11,748] INFO: Epoch 40: Train Loss 0.6674
[2025-10-25 12:56:20,102] INFO: Epoch 50: Train Loss 0.4457
[2025-10-25 12:56:28,965] INFO: Epoch 60: Train Loss 0.3073
[2025-10-25 12:56:37,547] INFO: Epoch 70: Train Loss 0.1934
[2025-10-25 12:56:45,829] INFO: Epoch 80: Train Loss 0.1530
[2025-10-25 12:56:54,303] INFO: Epoch 90: Train Loss 0.1164
[2025-10-25 12:57:02,903] INFO: Epoch 100: Train Loss 0.0991
[2025-10-25 12:57:11,363] INFO: Epoch 110: Train Loss 0.0806
[2025-10-25 12:57:20,172] INFO: Epoch 120: Train Loss 0.0774
[2025-10-25 12:57:28,627] INFO: Epoch 130: Train Loss 0.0626
[2025-10-25 12:57:37,232] INFO: Epoch 140: Train Loss 0.0552
[2025-10-25 12:57:45,814] INFO: Epoch 150: Train Loss 0.0546
[2025-10-25 12:57:54,422] INFO: Epoch 160: Train Loss 0.0511
[2025-10-25 12:58:03,291] INFO: Epoch 170: Train Loss 0.0476
[2025-10-25 12:58:11,484] INFO: Epoch 180: Train Loss 0.0447
[2025-10-25 12:58:19,620] INFO: Epoch 190: Train Loss 0.0421
[2025-10-25 12:58:27,970] INFO: Epoch 200: Train Loss 0.0375
[2025-10-25 12:58:36,026] INFO: Epoch 210: Train Loss 0.0384
[2025-10-25 12:58:44,125] INFO: Epoch 220: Train Loss 0.0365
[2025-10-25 12:58:52,294] INFO: Epoch 230: Train Loss 0.0338
[2025-10-25 12:59:00,483] INFO: Epoch 240: Train Loss 0.0314
[2025-10-25 12:59:08,578] INFO: Epoch 250: Train Loss 0.0311
[2025-10-25 12:59:16,580] INFO: Epoch 260: Train Loss 0.0291
[2025-10-25 12:59:24,690] INFO: Epoch 270: Train Loss 0.0280
[2025-10-25 12:59:32,687] INFO: Epoch 280: Train Loss 0.0267
[2025-10-25 12:59:40,701] INFO: Epoch 290: Train Loss 0.0270
[2025-10-25 12:59:48,668] INFO: Epoch 300: Train Loss 0.0264
[2025-10-25 12:59:56,673] INFO: Epoch 310: Train Loss 0.0258
[2025-10-25 13:00:04,652] INFO: Epoch 320: Train Loss 0.0259
[2025-10-25 13:00:12,622] INFO: Epoch 330: Train Loss 0.0247
[2025-10-25 13:00:20,614] INFO: Epoch 340: Train Loss 0.0244
[2025-10-25 13:00:28,628] INFO: Epoch 350: Train Loss 0.0243
[2025-10-25 13:00:36,644] INFO: Epoch 360: Train Loss 0.0237
[2025-10-25 13:00:44,817] INFO: Epoch 370: Train Loss 0.0240
[2025-10-25 13:00:52,983] INFO: Epoch 380: Train Loss 0.0231
[2025-10-25 13:01:00,928] INFO: Epoch 390: Train Loss 0.0225
[2025-10-25 13:01:09,227] INFO: Epoch 400: Train Loss 0.0233
[2025-10-25 13:01:09,254] INFO: âœ… Saved artifacts for SENSEX fold 5 to models/SENSEX/fold_5
[2025-10-25 13:01:09,254] INFO:    - Features: 13
[2025-10-25 13:01:09,254] INFO:    - Sequence length: 60
[2025-10-25 13:01:09,254] INFO:    - Model parameters: 804,097
[2025-10-25 13:01:09,254] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_5
[2025-10-25 13:01:09,254] INFO: Completed SENSEX fold 5: Train samples 4393, Final train loss 0.0233
[2025-10-25 13:01:09,255] INFO: Training SENSEX fold 6
[2025-10-25 13:01:09,255] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 13:01:09,277] INFO: Calculating technical indicators...
[2025-10-25 13:01:09,278] INFO: Calculating technical indicators...
[2025-10-25 13:01:09,282] INFO: Technical indicators calculated successfully
[2025-10-25 13:01:09,282] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 13:01:09,286] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:01:09,296] INFO: Return statistics: mean=0.0006, std=0.0139
[2025-10-25 13:01:09,296] INFO: Return range: [-0.1315, 0.1734]
[2025-10-25 13:01:09,296] INFO: Created 4786 sequences of length 60
[2025-10-25 13:01:09,296] INFO: Feature shape: (4786, 60, 13), Target shape: (4786,)
[2025-10-25 13:01:09,318] INFO: Scalers fitted on training data
[2025-10-25 13:01:09,318] INFO: Feature scaler mean: [25025.26999679 25168.89189037 24834.2692111 ]...
[2025-10-25 13:01:09,318] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:01:09,335] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:01:09,337] INFO: Return statistics: mean=0.0005, std=0.0080
[2025-10-25 13:01:09,337] INFO: Return range: [-0.0574, 0.0374]
[2025-10-25 13:01:09,337] INFO: Created 555 sequences of length 60
[2025-10-25 13:01:09,337] INFO: Feature shape: (555, 60, 13), Target shape: (555,)
[2025-10-25 13:01:09,339] INFO: Sequence building completed for SENSEX
[2025-10-25 13:01:09,339] INFO: Training samples: 4786
[2025-10-25 13:01:09,341] INFO: Dataset initialized: 4786 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:01:09,341] INFO: Training DataLoader: 4786 samples, 37 batches of size 128
[2025-10-25 13:01:09,358] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:01:09,358] INFO: Created basic model with 804097 parameters
[2025-10-25 13:01:09,361] INFO: Starting training for 400 epochs
[2025-10-25 13:01:18,359] INFO: Epoch 10: Train Loss 0.9886
[2025-10-25 13:01:27,215] INFO: Epoch 20: Train Loss 0.9552
[2025-10-25 13:01:36,219] INFO: Epoch 30: Train Loss 0.8284
[2025-10-25 13:01:45,221] INFO: Epoch 40: Train Loss 0.6295
[2025-10-25 13:01:54,075] INFO: Epoch 50: Train Loss 0.4084
[2025-10-25 13:02:02,800] INFO: Epoch 60: Train Loss 0.2624
[2025-10-25 13:02:11,650] INFO: Epoch 70: Train Loss 0.1790
[2025-10-25 13:02:20,383] INFO: Epoch 80: Train Loss 0.1278
[2025-10-25 13:02:29,165] INFO: Epoch 90: Train Loss 0.1020
[2025-10-25 13:02:37,895] INFO: Epoch 100: Train Loss 0.0841
[2025-10-25 13:02:46,638] INFO: Epoch 110: Train Loss 0.0717
[2025-10-25 13:02:55,365] INFO: Epoch 120: Train Loss 0.0656
[2025-10-25 13:03:04,277] INFO: Epoch 130: Train Loss 0.0609
[2025-10-25 13:03:13,005] INFO: Epoch 140: Train Loss 0.0531
[2025-10-25 13:03:21,837] INFO: Epoch 150: Train Loss 0.0486
[2025-10-25 13:03:30,567] INFO: Epoch 160: Train Loss 0.0486
[2025-10-25 13:03:39,270] INFO: Epoch 170: Train Loss 0.0460
[2025-10-25 13:03:47,992] INFO: Epoch 180: Train Loss 0.0420
[2025-10-25 13:03:56,711] INFO: Epoch 190: Train Loss 0.0400
[2025-10-25 13:04:05,436] INFO: Epoch 200: Train Loss 0.0389
[2025-10-25 13:04:14,166] INFO: Epoch 210: Train Loss 0.0353
[2025-10-25 13:04:22,894] INFO: Epoch 220: Train Loss 0.0352
[2025-10-25 13:04:31,625] INFO: Epoch 230: Train Loss 0.0327
[2025-10-25 13:04:40,356] INFO: Epoch 240: Train Loss 0.0311
[2025-10-25 13:04:49,092] INFO: Epoch 250: Train Loss 0.0299
[2025-10-25 13:04:57,812] INFO: Epoch 260: Train Loss 0.0304
[2025-10-25 13:05:06,534] INFO: Epoch 270: Train Loss 0.0286
[2025-10-25 13:05:15,257] INFO: Epoch 280: Train Loss 0.0269
[2025-10-25 13:05:23,987] INFO: Epoch 290: Train Loss 0.0271
[2025-10-25 13:05:32,705] INFO: Epoch 300: Train Loss 0.0265
[2025-10-25 13:05:41,437] INFO: Epoch 310: Train Loss 0.0246
[2025-10-25 13:05:50,159] INFO: Epoch 320: Train Loss 0.0254
[2025-10-25 13:05:58,900] INFO: Epoch 330: Train Loss 0.0238
[2025-10-25 13:06:07,626] INFO: Epoch 340: Train Loss 0.0243
[2025-10-25 13:06:16,357] INFO: Epoch 350: Train Loss 0.0242
[2025-10-25 13:06:25,086] INFO: Epoch 360: Train Loss 0.0235
[2025-10-25 13:06:33,811] INFO: Epoch 370: Train Loss 0.0232
[2025-10-25 13:06:42,539] INFO: Epoch 380: Train Loss 0.0226
[2025-10-25 13:06:51,268] INFO: Epoch 390: Train Loss 0.0236
[2025-10-25 13:07:00,009] INFO: Epoch 400: Train Loss 0.0231
[2025-10-25 13:07:00,028] INFO: âœ… Saved artifacts for SENSEX fold 6 to models/SENSEX/fold_6
[2025-10-25 13:07:00,028] INFO:    - Features: 13
[2025-10-25 13:07:00,028] INFO:    - Sequence length: 60
[2025-10-25 13:07:00,028] INFO:    - Model parameters: 804,097
[2025-10-25 13:07:00,028] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_6
[2025-10-25 13:07:00,028] INFO: Completed SENSEX fold 6: Train samples 4786, Final train loss 0.0231
[2025-10-25 13:07:00,028] INFO: Training SENSEX fold 7
[2025-10-25 13:07:00,028] INFO: Loading data from data/processed/sensex_clean.csv
[2025-10-25 13:07:00,042] INFO: Calculating technical indicators...
[2025-10-25 13:07:00,042] INFO: Calculating technical indicators...
[2025-10-25 13:07:00,045] INFO: Technical indicators calculated successfully
[2025-10-25 13:07:00,045] INFO: Available features for SENSEX: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_gold_20d']
[2025-10-25 13:07:00,049] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:07:00,056] INFO: Return statistics: mean=0.0006, std=0.0135
[2025-10-25 13:07:00,056] INFO: Return range: [-0.1315, 0.1734]
[2025-10-25 13:07:00,056] INFO: Created 5178 sequences of length 60
[2025-10-25 13:07:00,056] INFO: Feature shape: (5178, 60, 13), Target shape: (5178,)
[2025-10-25 13:07:00,077] INFO: Scalers fitted on training data
[2025-10-25 13:07:00,077] INFO: Feature scaler mean: [28393.85959807 28547.53189498 28191.78851228]...
[2025-10-25 13:07:00,077] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:07:00,091] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:07:00,091] INFO: Return statistics: mean=0.0007, std=0.0079
[2025-10-25 13:07:00,091] INFO: Return range: [-0.0295, 0.0374]
[2025-10-25 13:07:00,091] INFO: Created 162 sequences of length 60
[2025-10-25 13:07:00,091] INFO: Feature shape: (162, 60, 13), Target shape: (162,)
[2025-10-25 13:07:00,091] INFO: Sequence building completed for SENSEX
[2025-10-25 13:07:00,091] INFO: Training samples: 5178
[2025-10-25 13:07:00,093] INFO: Dataset initialized: 5178 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:07:00,093] INFO: Training DataLoader: 5178 samples, 40 batches of size 128
[2025-10-25 13:07:00,110] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:07:00,110] INFO: Created basic model with 804097 parameters
[2025-10-25 13:07:00,113] INFO: Starting training for 400 epochs
[2025-10-25 13:07:09,480] INFO: Epoch 10: Train Loss 0.9856
[2025-10-25 13:07:18,829] INFO: Epoch 20: Train Loss 0.9624
[2025-10-25 13:07:28,169] INFO: Epoch 30: Train Loss 0.8554
[2025-10-25 13:07:37,536] INFO: Epoch 40: Train Loss 0.6429
[2025-10-25 13:07:46,886] INFO: Epoch 50: Train Loss 0.4340
[2025-10-25 13:07:56,244] INFO: Epoch 60: Train Loss 0.3033
[2025-10-25 13:08:05,595] INFO: Epoch 70: Train Loss 0.2093
[2025-10-25 13:08:14,952] INFO: Epoch 80: Train Loss 0.1567
[2025-10-25 13:08:24,303] INFO: Epoch 90: Train Loss 0.1240
[2025-10-25 13:08:33,648] INFO: Epoch 100: Train Loss 0.1048
[2025-10-25 13:08:43,007] INFO: Epoch 110: Train Loss 0.0827
[2025-10-25 13:08:52,365] INFO: Epoch 120: Train Loss 0.0739
[2025-10-25 13:09:01,795] INFO: Epoch 130: Train Loss 0.0687
[2025-10-25 13:09:11,134] INFO: Epoch 140: Train Loss 0.0588
[2025-10-25 13:09:20,486] INFO: Epoch 150: Train Loss 0.0577
[2025-10-25 13:09:29,837] INFO: Epoch 160: Train Loss 0.0532
[2025-10-25 13:09:39,184] INFO: Epoch 170: Train Loss 0.0492
[2025-10-25 13:09:48,546] INFO: Epoch 180: Train Loss 0.0472
[2025-10-25 13:09:57,897] INFO: Epoch 190: Train Loss 0.0454
[2025-10-25 13:10:07,253] INFO: Epoch 200: Train Loss 0.0413
[2025-10-25 13:10:16,607] INFO: Epoch 210: Train Loss 0.0392
[2025-10-25 13:10:25,945] INFO: Epoch 220: Train Loss 0.0378
[2025-10-25 13:10:35,284] INFO: Epoch 230: Train Loss 0.0366
[2025-10-25 13:10:44,621] INFO: Epoch 240: Train Loss 0.0350
[2025-10-25 13:10:54,009] INFO: Epoch 250: Train Loss 0.0346
[2025-10-25 13:11:03,516] INFO: Epoch 260: Train Loss 0.0319
[2025-10-25 13:11:12,817] INFO: Epoch 270: Train Loss 0.0319
[2025-10-25 13:11:22,402] INFO: Epoch 280: Train Loss 0.0295
[2025-10-25 13:11:31,816] INFO: Epoch 290: Train Loss 0.0287
[2025-10-25 13:11:41,270] INFO: Epoch 300: Train Loss 0.0277
[2025-10-25 13:11:50,576] INFO: Epoch 310: Train Loss 0.0277
[2025-10-25 13:11:59,908] INFO: Epoch 320: Train Loss 0.0270
[2025-10-25 13:12:09,357] INFO: Epoch 330: Train Loss 0.0267
[2025-10-25 13:12:18,756] INFO: Epoch 340: Train Loss 0.0255
[2025-10-25 13:12:28,141] INFO: Epoch 350: Train Loss 0.0254
[2025-10-25 13:12:37,474] INFO: Epoch 360: Train Loss 0.0251
[2025-10-25 13:12:46,823] INFO: Epoch 370: Train Loss 0.0252
[2025-10-25 13:12:56,159] INFO: Epoch 380: Train Loss 0.0251
[2025-10-25 13:13:05,582] INFO: Epoch 390: Train Loss 0.0254
[2025-10-25 13:13:15,123] INFO: Epoch 400: Train Loss 0.0252
[2025-10-25 13:13:15,158] INFO: âœ… Saved artifacts for SENSEX fold 7 to models/SENSEX/fold_7
[2025-10-25 13:13:15,159] INFO:    - Features: 13
[2025-10-25 13:13:15,159] INFO:    - Sequence length: 60
[2025-10-25 13:13:15,159] INFO:    - Model parameters: 804,097
[2025-10-25 13:13:15,159] INFO: âœ… Saved versioned artifacts to models/SENSEX/fold_7
[2025-10-25 13:13:15,159] INFO: Completed SENSEX fold 7: Train samples 5178, Final train loss 0.0252
[2025-10-25 13:13:15,159] INFO: SENSEX summary: Avg train loss 0.0251, Avg val loss nan
[2025-10-25 13:13:15,159] INFO: 
=== Training GOLD models ===
[2025-10-25 13:13:15,159] INFO: Training GOLD fold 0
[2025-10-25 13:13:15,159] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 13:13:15,176] INFO: Calculating technical indicators...
[2025-10-25 13:13:15,176] INFO: Calculating technical indicators...
[2025-10-25 13:13:15,180] INFO: Technical indicators calculated successfully
[2025-10-25 13:13:15,180] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 13:13:15,183] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:13:15,187] INFO: Return statistics: mean=0.0006, std=0.0128
[2025-10-25 13:13:15,187] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 13:13:15,187] INFO: Created 2318 sequences of length 60
[2025-10-25 13:13:15,187] INFO: Feature shape: (2318, 60, 13), Target shape: (2318,)
[2025-10-25 13:13:15,197] INFO: Scalers fitted on training data
[2025-10-25 13:13:15,197] INFO: Feature scaler mean: [1013.89488335 1022.45891816 1004.58627231]...
[2025-10-25 13:13:15,197] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:13:15,204] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:13:15,208] INFO: Return statistics: mean=0.0004, std=0.0093
[2025-10-25 13:13:15,208] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 13:13:15,208] INFO: Created 2922 sequences of length 60
[2025-10-25 13:13:15,208] INFO: Feature shape: (2922, 60, 13), Target shape: (2922,)
[2025-10-25 13:13:15,216] INFO: Sequence building completed for GOLD
[2025-10-25 13:13:15,216] INFO: Training samples: 2318
[2025-10-25 13:13:15,217] INFO: Dataset initialized: 2318 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:13:15,217] INFO: Training DataLoader: 2318 samples, 18 batches of size 128
[2025-10-25 13:13:15,234] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:13:15,234] INFO: Created basic model with 804097 parameters
[2025-10-25 13:13:15,237] INFO: Starting training for 400 epochs
[2025-10-25 13:13:19,530] INFO: Epoch 10: Train Loss 0.9898
[2025-10-25 13:13:23,854] INFO: Epoch 20: Train Loss 0.9354
[2025-10-25 13:13:28,120] INFO: Epoch 30: Train Loss 0.8178
[2025-10-25 13:13:32,441] INFO: Epoch 40: Train Loss 0.6537
[2025-10-25 13:13:36,741] INFO: Epoch 50: Train Loss 0.5004
[2025-10-25 13:13:40,996] INFO: Epoch 60: Train Loss 0.3919
[2025-10-25 13:13:45,203] INFO: Epoch 70: Train Loss 0.3182
[2025-10-25 13:13:49,415] INFO: Epoch 80: Train Loss 0.2390
[2025-10-25 13:13:53,642] INFO: Epoch 90: Train Loss 0.1877
[2025-10-25 13:13:57,857] INFO: Epoch 100: Train Loss 0.1482
[2025-10-25 13:14:02,064] INFO: Epoch 110: Train Loss 0.1280
[2025-10-25 13:14:06,273] INFO: Epoch 120: Train Loss 0.1170
[2025-10-25 13:14:10,492] INFO: Epoch 130: Train Loss 0.1010
[2025-10-25 13:14:14,738] INFO: Epoch 140: Train Loss 0.0831
[2025-10-25 13:14:18,997] INFO: Epoch 150: Train Loss 0.0764
[2025-10-25 13:14:23,296] INFO: Epoch 160: Train Loss 0.0703
[2025-10-25 13:14:27,543] INFO: Epoch 170: Train Loss 0.0659
[2025-10-25 13:14:31,819] INFO: Epoch 180: Train Loss 0.0611
[2025-10-25 13:14:36,038] INFO: Epoch 190: Train Loss 0.0550
[2025-10-25 13:14:40,306] INFO: Epoch 200: Train Loss 0.0569
[2025-10-25 13:14:44,600] INFO: Epoch 210: Train Loss 0.0489
[2025-10-25 13:14:48,881] INFO: Epoch 220: Train Loss 0.0494
[2025-10-25 13:14:53,120] INFO: Epoch 230: Train Loss 0.0474
[2025-10-25 13:14:57,361] INFO: Epoch 240: Train Loss 0.0449
[2025-10-25 13:15:01,612] INFO: Epoch 250: Train Loss 0.0423
[2025-10-25 13:15:05,919] INFO: Epoch 260: Train Loss 0.0413
[2025-10-25 13:15:10,164] INFO: Epoch 270: Train Loss 0.0404
[2025-10-25 13:15:14,382] INFO: Epoch 280: Train Loss 0.0364
[2025-10-25 13:15:18,600] INFO: Epoch 290: Train Loss 0.0369
[2025-10-25 13:15:22,818] INFO: Epoch 300: Train Loss 0.0341
[2025-10-25 13:15:27,047] INFO: Epoch 310: Train Loss 0.0339
[2025-10-25 13:15:31,277] INFO: Epoch 320: Train Loss 0.0321
[2025-10-25 13:15:35,558] INFO: Epoch 330: Train Loss 0.0335
[2025-10-25 13:15:39,823] INFO: Epoch 340: Train Loss 0.0319
[2025-10-25 13:15:44,133] INFO: Epoch 350: Train Loss 0.0304
[2025-10-25 13:15:48,425] INFO: Epoch 360: Train Loss 0.0325
[2025-10-25 13:15:52,748] INFO: Epoch 370: Train Loss 0.0327
[2025-10-25 13:15:56,975] INFO: Epoch 380: Train Loss 0.0318
[2025-10-25 13:16:01,224] INFO: Epoch 390: Train Loss 0.0312
[2025-10-25 13:16:05,482] INFO: Epoch 400: Train Loss 0.0313
[2025-10-25 13:16:05,499] INFO: âœ… Saved artifacts for GOLD fold 0 to models/GOLD/fold_0
[2025-10-25 13:16:05,499] INFO:    - Features: 13
[2025-10-25 13:16:05,499] INFO:    - Sequence length: 60
[2025-10-25 13:16:05,499] INFO:    - Model parameters: 804,097
[2025-10-25 13:16:05,499] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_0
[2025-10-25 13:16:05,499] INFO: Completed GOLD fold 0: Train samples 2318, Final train loss 0.0313
[2025-10-25 13:16:05,500] INFO: Training GOLD fold 1
[2025-10-25 13:16:05,500] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 13:16:05,513] INFO: Calculating technical indicators...
[2025-10-25 13:16:05,513] INFO: Calculating technical indicators...
[2025-10-25 13:16:05,516] INFO: Technical indicators calculated successfully
[2025-10-25 13:16:05,516] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 13:16:05,520] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:16:05,523] INFO: Return statistics: mean=0.0005, std=0.0123
[2025-10-25 13:16:05,523] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 13:16:05,523] INFO: Created 2725 sequences of length 60
[2025-10-25 13:16:05,523] INFO: Feature shape: (2725, 60, 13), Target shape: (2725,)
[2025-10-25 13:16:05,533] INFO: Scalers fitted on training data
[2025-10-25 13:16:05,534] INFO: Feature scaler mean: [1051.86499972 1060.46666378 1042.50163285]...
[2025-10-25 13:16:05,534] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:16:05,540] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:16:05,543] INFO: Return statistics: mean=0.0005, std=0.0094
[2025-10-25 13:16:05,543] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 13:16:05,543] INFO: Created 2517 sequences of length 60
[2025-10-25 13:16:05,544] INFO: Feature shape: (2517, 60, 13), Target shape: (2517,)
[2025-10-25 13:16:05,550] INFO: Sequence building completed for GOLD
[2025-10-25 13:16:05,550] INFO: Training samples: 2725
[2025-10-25 13:16:05,552] INFO: Dataset initialized: 2725 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:16:05,552] INFO: Training DataLoader: 2725 samples, 21 batches of size 128
[2025-10-25 13:16:05,568] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:16:05,569] INFO: Created basic model with 804097 parameters
[2025-10-25 13:16:05,572] INFO: Starting training for 400 epochs
[2025-10-25 13:16:10,488] INFO: Epoch 10: Train Loss 0.9843
[2025-10-25 13:16:15,366] INFO: Epoch 20: Train Loss 0.9181
[2025-10-25 13:16:20,287] INFO: Epoch 30: Train Loss 0.7922
[2025-10-25 13:16:25,177] INFO: Epoch 40: Train Loss 0.6274
[2025-10-25 13:16:30,059] INFO: Epoch 50: Train Loss 0.5190
[2025-10-25 13:16:34,943] INFO: Epoch 60: Train Loss 0.4144
[2025-10-25 13:16:39,826] INFO: Epoch 70: Train Loss 0.3363
[2025-10-25 13:16:44,720] INFO: Epoch 80: Train Loss 0.2498
[2025-10-25 13:16:49,602] INFO: Epoch 90: Train Loss 0.2063
[2025-10-25 13:16:54,489] INFO: Epoch 100: Train Loss 0.1599
[2025-10-25 13:16:59,368] INFO: Epoch 110: Train Loss 0.1359
[2025-10-25 13:17:04,263] INFO: Epoch 120: Train Loss 0.1187
[2025-10-25 13:17:09,147] INFO: Epoch 130: Train Loss 0.1020
[2025-10-25 13:17:14,039] INFO: Epoch 140: Train Loss 0.0934
[2025-10-25 13:17:18,928] INFO: Epoch 150: Train Loss 0.0761
[2025-10-25 13:17:23,811] INFO: Epoch 160: Train Loss 0.0732
[2025-10-25 13:17:28,704] INFO: Epoch 170: Train Loss 0.0683
[2025-10-25 13:17:33,588] INFO: Epoch 180: Train Loss 0.0605
[2025-10-25 13:17:38,479] INFO: Epoch 190: Train Loss 0.0585
[2025-10-25 13:17:43,362] INFO: Epoch 200: Train Loss 0.0564
[2025-10-25 13:17:48,259] INFO: Epoch 210: Train Loss 0.0492
[2025-10-25 13:17:53,149] INFO: Epoch 220: Train Loss 0.0505
[2025-10-25 13:17:58,039] INFO: Epoch 230: Train Loss 0.0452
[2025-10-25 13:18:02,926] INFO: Epoch 240: Train Loss 0.0448
[2025-10-25 13:18:07,811] INFO: Epoch 250: Train Loss 0.0439
[2025-10-25 13:18:12,704] INFO: Epoch 260: Train Loss 0.0403
[2025-10-25 13:18:17,590] INFO: Epoch 270: Train Loss 0.0396
[2025-10-25 13:18:22,485] INFO: Epoch 280: Train Loss 0.0374
[2025-10-25 13:18:27,371] INFO: Epoch 290: Train Loss 0.0367
[2025-10-25 13:18:32,253] INFO: Epoch 300: Train Loss 0.0365
[2025-10-25 13:18:37,139] INFO: Epoch 310: Train Loss 0.0336
[2025-10-25 13:18:42,025] INFO: Epoch 320: Train Loss 0.0335
[2025-10-25 13:18:46,914] INFO: Epoch 330: Train Loss 0.0341
[2025-10-25 13:18:51,798] INFO: Epoch 340: Train Loss 0.0330
[2025-10-25 13:18:56,695] INFO: Epoch 350: Train Loss 0.0329
[2025-10-25 13:19:01,578] INFO: Epoch 360: Train Loss 0.0329
[2025-10-25 13:19:06,457] INFO: Epoch 370: Train Loss 0.0328
[2025-10-25 13:19:11,330] INFO: Epoch 380: Train Loss 0.0318
[2025-10-25 13:19:16,211] INFO: Epoch 390: Train Loss 0.0318
[2025-10-25 13:19:21,091] INFO: Epoch 400: Train Loss 0.0325
[2025-10-25 13:19:21,112] INFO: âœ… Saved artifacts for GOLD fold 1 to models/GOLD/fold_1
[2025-10-25 13:19:21,112] INFO:    - Features: 13
[2025-10-25 13:19:21,112] INFO:    - Sequence length: 60
[2025-10-25 13:19:21,112] INFO:    - Model parameters: 804,097
[2025-10-25 13:19:21,112] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_1
[2025-10-25 13:19:21,112] INFO: Completed GOLD fold 1: Train samples 2725, Final train loss 0.0325
[2025-10-25 13:19:21,112] INFO: Training GOLD fold 2
[2025-10-25 13:19:21,112] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 13:19:21,126] INFO: Calculating technical indicators...
[2025-10-25 13:19:21,126] INFO: Calculating technical indicators...
[2025-10-25 13:19:21,129] INFO: Technical indicators calculated successfully
[2025-10-25 13:19:21,129] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 13:19:21,132] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:19:21,136] INFO: Return statistics: mean=0.0004, std=0.0120
[2025-10-25 13:19:21,136] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 13:19:21,136] INFO: Created 3136 sequences of length 60
[2025-10-25 13:19:21,136] INFO: Feature shape: (3136, 60, 13), Target shape: (3136,)
[2025-10-25 13:19:21,148] INFO: Scalers fitted on training data
[2025-10-25 13:19:21,148] INFO: Feature scaler mean: [1071.44355356 1080.04208941 1062.22798827]...
[2025-10-25 13:19:21,148] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:19:21,158] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:19:21,161] INFO: Return statistics: mean=0.0006, std=0.0094
[2025-10-25 13:19:21,161] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 13:19:21,161] INFO: Created 2107 sequences of length 60
[2025-10-25 13:19:21,161] INFO: Feature shape: (2107, 60, 13), Target shape: (2107,)
[2025-10-25 13:19:21,166] INFO: Sequence building completed for GOLD
[2025-10-25 13:19:21,166] INFO: Training samples: 3136
[2025-10-25 13:19:21,167] INFO: Dataset initialized: 3136 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:19:21,167] INFO: Training DataLoader: 3136 samples, 24 batches of size 128
[2025-10-25 13:19:21,184] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:19:21,184] INFO: Created basic model with 804097 parameters
[2025-10-25 13:19:21,187] INFO: Starting training for 400 epochs
[2025-10-25 13:19:26,814] INFO: Epoch 10: Train Loss 0.9794
[2025-10-25 13:19:32,437] INFO: Epoch 20: Train Loss 0.9310
[2025-10-25 13:19:38,066] INFO: Epoch 30: Train Loss 0.7780
[2025-10-25 13:19:43,694] INFO: Epoch 40: Train Loss 0.6341
[2025-10-25 13:19:49,333] INFO: Epoch 50: Train Loss 0.4835
[2025-10-25 13:19:54,965] INFO: Epoch 60: Train Loss 0.3582
[2025-10-25 13:20:00,597] INFO: Epoch 70: Train Loss 0.2798
[2025-10-25 13:20:06,226] INFO: Epoch 80: Train Loss 0.2074
[2025-10-25 13:20:11,869] INFO: Epoch 90: Train Loss 0.1800
[2025-10-25 13:20:17,503] INFO: Epoch 100: Train Loss 0.1294
[2025-10-25 13:20:23,130] INFO: Epoch 110: Train Loss 0.1213
[2025-10-25 13:20:28,762] INFO: Epoch 120: Train Loss 0.1083
[2025-10-25 13:20:34,394] INFO: Epoch 130: Train Loss 0.0973
[2025-10-25 13:20:40,024] INFO: Epoch 140: Train Loss 0.0776
[2025-10-25 13:20:45,661] INFO: Epoch 150: Train Loss 0.0728
[2025-10-25 13:20:51,291] INFO: Epoch 160: Train Loss 0.0627
[2025-10-25 13:20:56,934] INFO: Epoch 170: Train Loss 0.0632
[2025-10-25 13:21:02,562] INFO: Epoch 180: Train Loss 0.0547
[2025-10-25 13:21:08,194] INFO: Epoch 190: Train Loss 0.0516
[2025-10-25 13:21:13,822] INFO: Epoch 200: Train Loss 0.0507
[2025-10-25 13:21:19,462] INFO: Epoch 210: Train Loss 0.0449
[2025-10-25 13:21:25,075] INFO: Epoch 220: Train Loss 0.0437
[2025-10-25 13:21:30,699] INFO: Epoch 230: Train Loss 0.0443
[2025-10-25 13:21:36,330] INFO: Epoch 240: Train Loss 0.0417
[2025-10-25 13:21:41,963] INFO: Epoch 250: Train Loss 0.0365
[2025-10-25 13:21:47,596] INFO: Epoch 260: Train Loss 0.0390
[2025-10-25 13:21:53,242] INFO: Epoch 270: Train Loss 0.0370
[2025-10-25 13:21:58,875] INFO: Epoch 280: Train Loss 0.0336
[2025-10-25 13:22:04,515] INFO: Epoch 290: Train Loss 0.0344
[2025-10-25 13:22:10,147] INFO: Epoch 300: Train Loss 0.0343
[2025-10-25 13:22:15,782] INFO: Epoch 310: Train Loss 0.0326
[2025-10-25 13:22:21,411] INFO: Epoch 320: Train Loss 0.0331
[2025-10-25 13:22:27,043] INFO: Epoch 330: Train Loss 0.0323
[2025-10-25 13:22:32,670] INFO: Epoch 340: Train Loss 0.0313
[2025-10-25 13:22:38,317] INFO: Epoch 350: Train Loss 0.0302
[2025-10-25 13:22:43,952] INFO: Epoch 360: Train Loss 0.0291
[2025-10-25 13:22:49,586] INFO: Epoch 370: Train Loss 0.0285
[2025-10-25 13:22:55,240] INFO: Epoch 380: Train Loss 0.0289
[2025-10-25 13:23:00,912] INFO: Epoch 390: Train Loss 0.0301
[2025-10-25 13:23:06,587] INFO: Epoch 400: Train Loss 0.0287
[2025-10-25 13:23:06,610] INFO: âœ… Saved artifacts for GOLD fold 2 to models/GOLD/fold_2
[2025-10-25 13:23:06,610] INFO:    - Features: 13
[2025-10-25 13:23:06,610] INFO:    - Sequence length: 60
[2025-10-25 13:23:06,610] INFO:    - Model parameters: 804,097
[2025-10-25 13:23:06,610] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_2
[2025-10-25 13:23:06,610] INFO: Completed GOLD fold 2: Train samples 3136, Final train loss 0.0287
[2025-10-25 13:23:06,610] INFO: Training GOLD fold 3
[2025-10-25 13:23:06,610] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 13:23:06,629] INFO: Calculating technical indicators...
[2025-10-25 13:23:06,629] INFO: Calculating technical indicators...
[2025-10-25 13:23:06,632] INFO: Technical indicators calculated successfully
[2025-10-25 13:23:06,633] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 13:23:06,636] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:23:06,641] INFO: Return statistics: mean=0.0004, std=0.0115
[2025-10-25 13:23:06,641] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 13:23:06,641] INFO: Created 3541 sequences of length 60
[2025-10-25 13:23:06,641] INFO: Feature shape: (3541, 60, 13), Target shape: (3541,)
[2025-10-25 13:23:06,657] INFO: Scalers fitted on training data
[2025-10-25 13:23:06,657] INFO: Feature scaler mean: [1093.97833225 1102.34452822 1085.05226734]...
[2025-10-25 13:23:06,657] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:23:06,667] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:23:06,670] INFO: Return statistics: mean=0.0007, std=0.0100
[2025-10-25 13:23:06,670] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 13:23:06,670] INFO: Created 1699 sequences of length 60
[2025-10-25 13:23:06,670] INFO: Feature shape: (1699, 60, 13), Target shape: (1699,)
[2025-10-25 13:23:06,675] INFO: Sequence building completed for GOLD
[2025-10-25 13:23:06,675] INFO: Training samples: 3541
[2025-10-25 13:23:06,676] INFO: Dataset initialized: 3541 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:23:06,676] INFO: Training DataLoader: 3541 samples, 27 batches of size 128
[2025-10-25 13:23:06,694] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:23:06,694] INFO: Created basic model with 804097 parameters
[2025-10-25 13:23:06,697] INFO: Starting training for 400 epochs
[2025-10-25 13:23:13,018] INFO: Epoch 10: Train Loss 0.9922
[2025-10-25 13:23:19,356] INFO: Epoch 20: Train Loss 0.9328
[2025-10-25 13:23:25,685] INFO: Epoch 30: Train Loss 0.8025
[2025-10-25 13:23:32,007] INFO: Epoch 40: Train Loss 0.6195
[2025-10-25 13:23:38,342] INFO: Epoch 50: Train Loss 0.4681
[2025-10-25 13:23:44,669] INFO: Epoch 60: Train Loss 0.3498
[2025-10-25 13:23:50,997] INFO: Epoch 70: Train Loss 0.2636
[2025-10-25 13:23:57,334] INFO: Epoch 80: Train Loss 0.1911
[2025-10-25 13:24:03,654] INFO: Epoch 90: Train Loss 0.1645
[2025-10-25 13:24:09,983] INFO: Epoch 100: Train Loss 0.1317
[2025-10-25 13:24:16,324] INFO: Epoch 110: Train Loss 0.1070
[2025-10-25 13:24:22,651] INFO: Epoch 120: Train Loss 0.0950
[2025-10-25 13:24:28,977] INFO: Epoch 130: Train Loss 0.0820
[2025-10-25 13:24:35,312] INFO: Epoch 140: Train Loss 0.0708
[2025-10-25 13:24:41,633] INFO: Epoch 150: Train Loss 0.0652
[2025-10-25 13:24:47,968] INFO: Epoch 160: Train Loss 0.0603
[2025-10-25 13:24:54,292] INFO: Epoch 170: Train Loss 0.0577
[2025-10-25 13:25:00,616] INFO: Epoch 180: Train Loss 0.0575
[2025-10-25 13:25:06,952] INFO: Epoch 190: Train Loss 0.0520
[2025-10-25 13:25:13,284] INFO: Epoch 200: Train Loss 0.0486
[2025-10-25 13:25:19,612] INFO: Epoch 210: Train Loss 0.0458
[2025-10-25 13:25:25,940] INFO: Epoch 220: Train Loss 0.0427
[2025-10-25 13:25:32,272] INFO: Epoch 230: Train Loss 0.0403
[2025-10-25 13:25:38,602] INFO: Epoch 240: Train Loss 0.0401
[2025-10-25 13:25:44,941] INFO: Epoch 250: Train Loss 0.0363
[2025-10-25 13:25:51,263] INFO: Epoch 260: Train Loss 0.0347
[2025-10-25 13:25:57,587] INFO: Epoch 270: Train Loss 0.0352
[2025-10-25 13:26:03,919] INFO: Epoch 280: Train Loss 0.0330
[2025-10-25 13:26:10,247] INFO: Epoch 290: Train Loss 0.0325
[2025-10-25 13:26:16,582] INFO: Epoch 300: Train Loss 0.0311
[2025-10-25 13:26:22,905] INFO: Epoch 310: Train Loss 0.0305
[2025-10-25 13:26:29,229] INFO: Epoch 320: Train Loss 0.0307
[2025-10-25 13:26:35,560] INFO: Epoch 330: Train Loss 0.0293
[2025-10-25 13:26:41,871] INFO: Epoch 340: Train Loss 0.0297
[2025-10-25 13:26:48,262] INFO: Epoch 350: Train Loss 0.0281
[2025-10-25 13:26:54,648] INFO: Epoch 360: Train Loss 0.0264
[2025-10-25 13:27:01,010] INFO: Epoch 370: Train Loss 0.0298
[2025-10-25 13:27:07,364] INFO: Epoch 380: Train Loss 0.0278
[2025-10-25 13:27:13,680] INFO: Epoch 390: Train Loss 0.0277
[2025-10-25 13:27:19,998] INFO: Epoch 400: Train Loss 0.0273
[2025-10-25 13:27:20,023] INFO: âœ… Saved artifacts for GOLD fold 3 to models/GOLD/fold_3
[2025-10-25 13:27:20,023] INFO:    - Features: 13
[2025-10-25 13:27:20,023] INFO:    - Sequence length: 60
[2025-10-25 13:27:20,023] INFO:    - Model parameters: 804,097
[2025-10-25 13:27:20,023] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_3
[2025-10-25 13:27:20,023] INFO: Completed GOLD fold 3: Train samples 3541, Final train loss 0.0273
[2025-10-25 13:27:20,023] INFO: Training GOLD fold 4
[2025-10-25 13:27:20,023] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 13:27:20,041] INFO: Calculating technical indicators...
[2025-10-25 13:27:20,042] INFO: Calculating technical indicators...
[2025-10-25 13:27:20,045] INFO: Technical indicators calculated successfully
[2025-10-25 13:27:20,045] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 13:27:20,049] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:27:20,055] INFO: Return statistics: mean=0.0004, std=0.0111
[2025-10-25 13:27:20,055] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 13:27:20,055] INFO: Created 3951 sequences of length 60
[2025-10-25 13:27:20,055] INFO: Feature shape: (3951, 60, 13), Target shape: (3951,)
[2025-10-25 13:27:20,071] INFO: Scalers fitted on training data
[2025-10-25 13:27:20,071] INFO: Feature scaler mean: [1118.43204558 1126.68099732 1109.72593942]...
[2025-10-25 13:27:20,071] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:27:20,082] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:27:20,084] INFO: Return statistics: mean=0.0007, std=0.0104
[2025-10-25 13:27:20,084] INFO: Return range: [-0.0567, 0.1448]
[2025-10-25 13:27:20,084] INFO: Created 1292 sequences of length 60
[2025-10-25 13:27:20,084] INFO: Feature shape: (1292, 60, 13), Target shape: (1292,)
[2025-10-25 13:27:20,087] INFO: Sequence building completed for GOLD
[2025-10-25 13:27:20,087] INFO: Training samples: 3951
[2025-10-25 13:27:20,088] INFO: Dataset initialized: 3951 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:27:20,088] INFO: Training DataLoader: 3951 samples, 30 batches of size 128
[2025-10-25 13:27:20,105] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:27:20,105] INFO: Created basic model with 804097 parameters
[2025-10-25 13:27:20,108] INFO: Starting training for 400 epochs
[2025-10-25 13:27:27,205] INFO: Epoch 10: Train Loss 0.9721
[2025-10-25 13:27:34,343] INFO: Epoch 20: Train Loss 0.9569
[2025-10-25 13:27:41,419] INFO: Epoch 30: Train Loss 0.8332
[2025-10-25 13:27:48,496] INFO: Epoch 40: Train Loss 0.6461
[2025-10-25 13:27:55,561] INFO: Epoch 50: Train Loss 0.4951
[2025-10-25 13:28:02,629] INFO: Epoch 60: Train Loss 0.3811
[2025-10-25 13:28:09,729] INFO: Epoch 70: Train Loss 0.2700
[2025-10-25 13:28:16,790] INFO: Epoch 80: Train Loss 0.2047
[2025-10-25 13:28:23,864] INFO: Epoch 90: Train Loss 0.1554
[2025-10-25 13:28:30,943] INFO: Epoch 100: Train Loss 0.1206
[2025-10-25 13:28:38,019] INFO: Epoch 110: Train Loss 0.1079
[2025-10-25 13:28:45,097] INFO: Epoch 120: Train Loss 0.0923
[2025-10-25 13:28:52,164] INFO: Epoch 130: Train Loss 0.0813
[2025-10-25 13:28:59,239] INFO: Epoch 140: Train Loss 0.0727
[2025-10-25 13:29:06,307] INFO: Epoch 150: Train Loss 0.0682
[2025-10-25 13:29:13,388] INFO: Epoch 160: Train Loss 0.0637
[2025-10-25 13:29:20,463] INFO: Epoch 170: Train Loss 0.0586
[2025-10-25 13:29:27,535] INFO: Epoch 180: Train Loss 0.0512
[2025-10-25 13:29:34,614] INFO: Epoch 190: Train Loss 0.0486
[2025-10-25 13:29:41,688] INFO: Epoch 200: Train Loss 0.0479
[2025-10-25 13:29:48,758] INFO: Epoch 210: Train Loss 0.0443
[2025-10-25 13:29:55,834] INFO: Epoch 220: Train Loss 0.0407
[2025-10-25 13:30:02,909] INFO: Epoch 230: Train Loss 0.0395
[2025-10-25 13:30:09,989] INFO: Epoch 240: Train Loss 0.0395
[2025-10-25 13:30:17,056] INFO: Epoch 250: Train Loss 0.0371
[2025-10-25 13:30:24,137] INFO: Epoch 260: Train Loss 0.0369
[2025-10-25 13:30:31,198] INFO: Epoch 270: Train Loss 0.0367
[2025-10-25 13:30:38,358] INFO: Epoch 280: Train Loss 0.0344
[2025-10-25 13:30:45,446] INFO: Epoch 290: Train Loss 0.0332
[2025-10-25 13:30:52,550] INFO: Epoch 300: Train Loss 0.0321
[2025-10-25 13:30:59,714] INFO: Epoch 310: Train Loss 0.0306
[2025-10-25 13:31:06,891] INFO: Epoch 320: Train Loss 0.0303
[2025-10-25 13:31:13,999] INFO: Epoch 330: Train Loss 0.0318
[2025-10-25 13:31:21,096] INFO: Epoch 340: Train Loss 0.0317
[2025-10-25 13:31:28,169] INFO: Epoch 350: Train Loss 0.0287
[2025-10-25 13:31:35,246] INFO: Epoch 360: Train Loss 0.0284
[2025-10-25 13:31:42,308] INFO: Epoch 370: Train Loss 0.0280
[2025-10-25 13:31:49,363] INFO: Epoch 380: Train Loss 0.0279
[2025-10-25 13:31:56,440] INFO: Epoch 390: Train Loss 0.0269
[2025-10-25 13:32:03,507] INFO: Epoch 400: Train Loss 0.0291
[2025-10-25 13:32:03,526] INFO: âœ… Saved artifacts for GOLD fold 4 to models/GOLD/fold_4
[2025-10-25 13:32:03,526] INFO:    - Features: 13
[2025-10-25 13:32:03,526] INFO:    - Sequence length: 60
[2025-10-25 13:32:03,526] INFO:    - Model parameters: 804,097
[2025-10-25 13:32:03,526] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_4
[2025-10-25 13:32:03,526] INFO: Completed GOLD fold 4: Train samples 3951, Final train loss 0.0291
[2025-10-25 13:32:03,526] INFO: Training GOLD fold 5
[2025-10-25 13:32:03,526] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 13:32:03,540] INFO: Calculating technical indicators...
[2025-10-25 13:32:03,540] INFO: Calculating technical indicators...
[2025-10-25 13:32:03,543] INFO: Technical indicators calculated successfully
[2025-10-25 13:32:03,543] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 13:32:03,546] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:32:03,551] INFO: Return statistics: mean=0.0004, std=0.0111
[2025-10-25 13:32:03,551] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 13:32:03,551] INFO: Created 4360 sequences of length 60
[2025-10-25 13:32:03,551] INFO: Feature shape: (4360, 60, 13), Target shape: (4360,)
[2025-10-25 13:32:03,568] INFO: Scalers fitted on training data
[2025-10-25 13:32:03,568] INFO: Feature scaler mean: [1180.15587754 1188.90370647 1170.89573119]...
[2025-10-25 13:32:03,568] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:32:03,579] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:32:03,580] INFO: Return statistics: mean=0.0009, std=0.0107
[2025-10-25 13:32:03,580] INFO: Return range: [-0.0346, 0.1448]
[2025-10-25 13:32:03,580] INFO: Created 881 sequences of length 60
[2025-10-25 13:32:03,580] INFO: Feature shape: (881, 60, 13), Target shape: (881,)
[2025-10-25 13:32:03,583] INFO: Sequence building completed for GOLD
[2025-10-25 13:32:03,583] INFO: Training samples: 4360
[2025-10-25 13:32:03,584] INFO: Dataset initialized: 4360 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:32:03,584] INFO: Training DataLoader: 4360 samples, 34 batches of size 128
[2025-10-25 13:32:03,601] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:32:03,601] INFO: Created basic model with 804097 parameters
[2025-10-25 13:32:03,608] INFO: Starting training for 400 epochs
[2025-10-25 13:32:11,554] INFO: Epoch 10: Train Loss 0.9804
[2025-10-25 13:32:19,491] INFO: Epoch 20: Train Loss 0.9342
[2025-10-25 13:32:27,440] INFO: Epoch 30: Train Loss 0.8125
[2025-10-25 13:32:35,394] INFO: Epoch 40: Train Loss 0.6004
[2025-10-25 13:32:43,351] INFO: Epoch 50: Train Loss 0.4363
[2025-10-25 13:32:51,299] INFO: Epoch 60: Train Loss 0.3191
[2025-10-25 13:32:59,242] INFO: Epoch 70: Train Loss 0.2320
[2025-10-25 13:33:07,183] INFO: Epoch 80: Train Loss 0.1681
[2025-10-25 13:33:15,129] INFO: Epoch 90: Train Loss 0.1329
[2025-10-25 13:33:23,070] INFO: Epoch 100: Train Loss 0.1094
[2025-10-25 13:33:31,015] INFO: Epoch 110: Train Loss 0.0930
[2025-10-25 13:33:38,909] INFO: Epoch 120: Train Loss 0.0829
[2025-10-25 13:33:46,813] INFO: Epoch 130: Train Loss 0.0718
[2025-10-25 13:33:54,715] INFO: Epoch 140: Train Loss 0.0656
[2025-10-25 13:34:02,636] INFO: Epoch 150: Train Loss 0.0619
[2025-10-25 13:34:10,538] INFO: Epoch 160: Train Loss 0.0543
[2025-10-25 13:34:18,447] INFO: Epoch 170: Train Loss 0.0529
[2025-10-25 13:34:26,347] INFO: Epoch 180: Train Loss 0.0503
[2025-10-25 13:34:34,258] INFO: Epoch 190: Train Loss 0.0495
[2025-10-25 13:34:42,169] INFO: Epoch 200: Train Loss 0.0407
[2025-10-25 13:34:50,073] INFO: Epoch 210: Train Loss 0.0412
[2025-10-25 13:34:57,975] INFO: Epoch 220: Train Loss 0.0382
[2025-10-25 13:35:05,880] INFO: Epoch 230: Train Loss 0.0374
[2025-10-25 13:35:13,783] INFO: Epoch 240: Train Loss 0.0362
[2025-10-25 13:35:21,678] INFO: Epoch 250: Train Loss 0.0333
[2025-10-25 13:35:29,590] INFO: Epoch 260: Train Loss 0.0346
[2025-10-25 13:35:37,490] INFO: Epoch 270: Train Loss 0.0315
[2025-10-25 13:35:45,394] INFO: Epoch 280: Train Loss 0.0313
[2025-10-25 13:35:53,298] INFO: Epoch 290: Train Loss 0.0311
[2025-10-25 13:36:01,212] INFO: Epoch 300: Train Loss 0.0307
[2025-10-25 13:36:09,122] INFO: Epoch 310: Train Loss 0.0274
[2025-10-25 13:36:17,023] INFO: Epoch 320: Train Loss 0.0277
[2025-10-25 13:36:24,919] INFO: Epoch 330: Train Loss 0.0260
[2025-10-25 13:36:32,838] INFO: Epoch 340: Train Loss 0.0271
[2025-10-25 13:36:40,743] INFO: Epoch 350: Train Loss 0.0264
[2025-10-25 13:36:48,619] INFO: Epoch 360: Train Loss 0.0270
[2025-10-25 13:36:56,545] INFO: Epoch 370: Train Loss 0.0261
[2025-10-25 13:37:04,500] INFO: Epoch 380: Train Loss 0.0268
[2025-10-25 13:37:12,657] INFO: Epoch 390: Train Loss 0.0259
[2025-10-25 13:37:20,847] INFO: Epoch 400: Train Loss 0.0251
[2025-10-25 13:37:20,868] INFO: âœ… Saved artifacts for GOLD fold 5 to models/GOLD/fold_5
[2025-10-25 13:37:20,868] INFO:    - Features: 13
[2025-10-25 13:37:20,868] INFO:    - Sequence length: 60
[2025-10-25 13:37:20,868] INFO:    - Model parameters: 804,097
[2025-10-25 13:37:20,868] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_5
[2025-10-25 13:37:20,868] INFO: Completed GOLD fold 5: Train samples 4360, Final train loss 0.0251
[2025-10-25 13:37:20,868] INFO: Training GOLD fold 6
[2025-10-25 13:37:20,869] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 13:37:20,886] INFO: Calculating technical indicators...
[2025-10-25 13:37:20,887] INFO: Calculating technical indicators...
[2025-10-25 13:37:20,890] INFO: Technical indicators calculated successfully
[2025-10-25 13:37:20,891] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 13:37:20,895] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:37:20,902] INFO: Return statistics: mean=0.0004, std=0.0109
[2025-10-25 13:37:20,902] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 13:37:20,902] INFO: Created 4768 sequences of length 60
[2025-10-25 13:37:20,902] INFO: Feature shape: (4768, 60, 13), Target shape: (4768,)
[2025-10-25 13:37:20,921] INFO: Scalers fitted on training data
[2025-10-25 13:37:20,921] INFO: Feature scaler mean: [1233.6617701  1242.70960038 1224.15322389]...
[2025-10-25 13:37:20,921] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:37:20,936] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:37:20,939] INFO: Return statistics: mean=0.0015, std=0.0119
[2025-10-25 13:37:20,939] INFO: Return range: [-0.0346, 0.1448]
[2025-10-25 13:37:20,939] INFO: Created 475 sequences of length 60
[2025-10-25 13:37:20,939] INFO: Feature shape: (475, 60, 13), Target shape: (475,)
[2025-10-25 13:37:20,942] INFO: Sequence building completed for GOLD
[2025-10-25 13:37:20,942] INFO: Training samples: 4768
[2025-10-25 13:37:20,944] INFO: Dataset initialized: 4768 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:37:20,944] INFO: Training DataLoader: 4768 samples, 37 batches of size 128
[2025-10-25 13:37:20,961] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:37:20,961] INFO: Created basic model with 804097 parameters
[2025-10-25 13:37:20,967] INFO: Starting training for 400 epochs
[2025-10-25 13:37:29,878] INFO: Epoch 10: Train Loss 0.9853
[2025-10-25 13:37:38,884] INFO: Epoch 20: Train Loss 0.9553
[2025-10-25 13:37:48,050] INFO: Epoch 30: Train Loss 0.8374
[2025-10-25 13:37:56,953] INFO: Epoch 40: Train Loss 0.6266
[2025-10-25 13:38:05,852] INFO: Epoch 50: Train Loss 0.4314
[2025-10-25 13:38:14,747] INFO: Epoch 60: Train Loss 0.3002
[2025-10-25 13:38:23,781] INFO: Epoch 70: Train Loss 0.2077
[2025-10-25 13:38:32,537] INFO: Epoch 80: Train Loss 0.1456
[2025-10-25 13:38:41,364] INFO: Epoch 90: Train Loss 0.1252
[2025-10-25 13:38:50,134] INFO: Epoch 100: Train Loss 0.0997
[2025-10-25 13:38:58,952] INFO: Epoch 110: Train Loss 0.0884
[2025-10-25 13:39:07,706] INFO: Epoch 120: Train Loss 0.0764
[2025-10-25 13:39:16,435] INFO: Epoch 130: Train Loss 0.0717
[2025-10-25 13:39:25,115] INFO: Epoch 140: Train Loss 0.0643
[2025-10-25 13:39:33,794] INFO: Epoch 150: Train Loss 0.0622
[2025-10-25 13:39:42,416] INFO: Epoch 160: Train Loss 0.0553
[2025-10-25 13:39:51,083] INFO: Epoch 170: Train Loss 0.0509
[2025-10-25 13:39:59,562] INFO: Epoch 180: Train Loss 0.0534
[2025-10-25 13:40:08,292] INFO: Epoch 190: Train Loss 0.0459
[2025-10-25 13:40:16,993] INFO: Epoch 200: Train Loss 0.0440
[2025-10-25 13:40:25,683] INFO: Epoch 210: Train Loss 0.0406
[2025-10-25 13:40:34,349] INFO: Epoch 220: Train Loss 0.0379
[2025-10-25 13:40:43,033] INFO: Epoch 230: Train Loss 0.0375
[2025-10-25 13:40:51,717] INFO: Epoch 240: Train Loss 0.0361
[2025-10-25 13:41:00,406] INFO: Epoch 250: Train Loss 0.0348
[2025-10-25 13:41:09,081] INFO: Epoch 260: Train Loss 0.0334
[2025-10-25 13:41:17,752] INFO: Epoch 270: Train Loss 0.0326
[2025-10-25 13:41:26,434] INFO: Epoch 280: Train Loss 0.0311
[2025-10-25 13:41:35,119] INFO: Epoch 290: Train Loss 0.0289
[2025-10-25 13:41:43,800] INFO: Epoch 300: Train Loss 0.0285
[2025-10-25 13:41:52,487] INFO: Epoch 310: Train Loss 0.0295
[2025-10-25 13:42:01,180] INFO: Epoch 320: Train Loss 0.0280
[2025-10-25 13:42:09,858] INFO: Epoch 330: Train Loss 0.0272
[2025-10-25 13:42:18,584] INFO: Epoch 340: Train Loss 0.0275
[2025-10-25 13:42:28,017] INFO: Epoch 350: Train Loss 0.0272
[2025-10-25 13:42:36,806] INFO: Epoch 360: Train Loss 0.0256
[2025-10-25 13:42:45,614] INFO: Epoch 370: Train Loss 0.0254
[2025-10-25 13:42:54,442] INFO: Epoch 380: Train Loss 0.0259
[2025-10-25 13:43:03,186] INFO: Epoch 390: Train Loss 0.0265
[2025-10-25 13:43:11,917] INFO: Epoch 400: Train Loss 0.0248
[2025-10-25 13:43:11,949] INFO: âœ… Saved artifacts for GOLD fold 6 to models/GOLD/fold_6
[2025-10-25 13:43:11,949] INFO:    - Features: 13
[2025-10-25 13:43:11,949] INFO:    - Sequence length: 60
[2025-10-25 13:43:11,949] INFO:    - Model parameters: 804,097
[2025-10-25 13:43:11,949] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_6
[2025-10-25 13:43:11,949] INFO: Completed GOLD fold 6: Train samples 4768, Final train loss 0.0248
[2025-10-25 13:43:11,949] INFO: Training GOLD fold 7
[2025-10-25 13:43:11,949] INFO: Loading data from data/processed/gold_clean.csv
[2025-10-25 13:43:11,969] INFO: Calculating technical indicators...
[2025-10-25 13:43:11,969] INFO: Calculating technical indicators...
[2025-10-25 13:43:11,973] INFO: Technical indicators calculated successfully
[2025-10-25 13:43:11,973] INFO: Available features for GOLD: ['Close', 'Open', 'High', 'Low', 'Volume', 'ret_1d', 'vol_10d', 'zscore_20d', 'rsi_14', 'ema_10', 'ema_20', 'atr_14', 'corr_sensex_20d']
[2025-10-25 13:43:11,977] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:43:11,987] INFO: Return statistics: mean=0.0004, std=0.0107
[2025-10-25 13:43:11,987] INFO: Return range: [-0.0906, 0.1099]
[2025-10-25 13:43:11,987] INFO: Created 5179 sequences of length 60
[2025-10-25 13:43:11,987] INFO: Feature shape: (5179, 60, 13), Target shape: (5179,)
[2025-10-25 13:43:12,013] INFO: Scalers fitted on training data
[2025-10-25 13:43:12,013] INFO: Feature scaler mean: [1302.83408238 1312.33774858 1293.08487596]...
[2025-10-25 13:43:12,013] INFO: Target scaler mean: 0.00, std: 0.01
[2025-10-25 13:43:12,030] INFO: ðŸŽ¯ PREDICTING RETURNS (stationary target) instead of prices
[2025-10-25 13:43:12,030] INFO: Return statistics: mean=0.0046, std=0.0233
[2025-10-25 13:43:12,030] INFO: Return range: [-0.0279, 0.1448]
[2025-10-25 13:43:12,030] INFO: Created 64 sequences of length 60
[2025-10-25 13:43:12,030] INFO: Feature shape: (64, 60, 13), Target shape: (64,)
[2025-10-25 13:43:12,030] INFO: Sequence building completed for GOLD
[2025-10-25 13:43:12,030] INFO: Training samples: 5179
[2025-10-25 13:43:12,032] INFO: Dataset initialized: 5179 samples, seq_len=60, features=13, device=mps
[2025-10-25 13:43:12,032] INFO: Training DataLoader: 5179 samples, 40 batches of size 128
[2025-10-25 13:43:12,051] INFO: Initialized LSTM model: input_size=13, hidden_size=256, num_layers=2, dropout=0.2
[2025-10-25 13:43:12,052] INFO: Created basic model with 804097 parameters
[2025-10-25 13:43:12,054] INFO: Starting training for 400 epochs
[2025-10-25 13:43:21,552] INFO: Epoch 10: Train Loss 0.9877
[2025-10-25 13:43:30,881] INFO: Epoch 20: Train Loss 0.9413
[2025-10-25 13:43:40,196] INFO: Epoch 30: Train Loss 0.7968
[2025-10-25 13:43:49,511] INFO: Epoch 40: Train Loss 0.5940
[2025-10-25 13:43:58,824] INFO: Epoch 50: Train Loss 0.4123
[2025-10-25 13:44:08,137] INFO: Epoch 60: Train Loss 0.2831
[2025-10-25 13:44:17,454] INFO: Epoch 70: Train Loss 0.2146
[2025-10-25 13:44:26,769] INFO: Epoch 80: Train Loss 0.1589
[2025-10-25 13:44:36,089] INFO: Epoch 90: Train Loss 0.1322
[2025-10-25 13:44:45,405] INFO: Epoch 100: Train Loss 0.1033
[2025-10-25 13:44:54,754] INFO: Epoch 110: Train Loss 0.0911
[2025-10-25 13:45:04,108] INFO: Epoch 120: Train Loss 0.0853
[2025-10-25 13:45:13,481] INFO: Epoch 130: Train Loss 0.0714
[2025-10-25 13:45:22,848] INFO: Epoch 140: Train Loss 0.0645
[2025-10-25 13:45:32,216] INFO: Epoch 150: Train Loss 0.0653
[2025-10-25 13:45:41,724] INFO: Epoch 160: Train Loss 0.0574
[2025-10-25 13:45:51,214] INFO: Epoch 170: Train Loss 0.0530
[2025-10-25 13:46:00,621] INFO: Epoch 180: Train Loss 0.0507
[2025-10-25 13:47:33,567] INFO: Epoch 190: Train Loss 0.0456
[2025-10-25 14:02:44,561] INFO: Epoch 200: Train Loss 0.0461
[2025-10-25 14:02:53,925] INFO: Epoch 210: Train Loss 0.0431
[2025-10-25 14:03:03,311] INFO: Epoch 220: Train Loss 0.0381
[2025-10-25 14:03:12,651] INFO: Epoch 230: Train Loss 0.0382
[2025-10-25 14:03:21,993] INFO: Epoch 240: Train Loss 0.0367
[2025-10-25 14:18:30,755] INFO: Epoch 250: Train Loss 0.0354
[2025-10-25 14:18:40,074] INFO: Epoch 260: Train Loss 0.0349
[2025-10-25 14:18:49,449] INFO: Epoch 270: Train Loss 0.0342
[2025-10-25 14:18:58,822] INFO: Epoch 280: Train Loss 0.0316
[2025-10-25 14:19:08,125] INFO: Epoch 290: Train Loss 0.0299
[2025-10-25 14:19:17,493] INFO: Epoch 300: Train Loss 0.0304
[2025-10-25 14:19:26,900] INFO: Epoch 310: Train Loss 0.0298
[2025-10-25 14:19:36,275] INFO: Epoch 320: Train Loss 0.0289
[2025-10-25 14:19:45,688] INFO: Epoch 330: Train Loss 0.0281
[2025-10-25 14:19:55,114] INFO: Epoch 340: Train Loss 0.0276
[2025-10-25 14:20:04,537] INFO: Epoch 350: Train Loss 0.0278
[2025-10-25 14:20:13,978] INFO: Epoch 360: Train Loss 0.0275
[2025-10-25 14:20:23,370] INFO: Epoch 370: Train Loss 0.0278
[2025-10-25 14:20:32,788] INFO: Epoch 380: Train Loss 0.0263
[2025-10-25 14:20:42,203] INFO: Epoch 390: Train Loss 0.0259
[2025-10-25 14:20:57,780] INFO: Epoch 400: Train Loss 0.0252
[2025-10-25 14:20:57,821] INFO: âœ… Saved artifacts for GOLD fold 7 to models/GOLD/fold_7
[2025-10-25 14:20:57,822] INFO:    - Features: 13
[2025-10-25 14:20:57,822] INFO:    - Sequence length: 60
[2025-10-25 14:20:57,822] INFO:    - Model parameters: 804,097
[2025-10-25 14:20:57,822] INFO: âœ… Saved versioned artifacts to models/GOLD/fold_7
[2025-10-25 14:20:57,822] INFO: Completed GOLD fold 7: Train samples 5179, Final train loss 0.0252
[2025-10-25 14:20:57,822] INFO: GOLD summary: Avg train loss 0.0280, Avg val loss nan
[2025-10-25 14:20:57,825] INFO: Training completed successfully. Summary saved to reports/training_summary.json
[2025-10-25 14:20:57,826] INFO: âœ… Training pipeline completed successfully

    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘               SENSEX & GOLD LSTM PRICE PREDICTOR                 â•‘
    â•‘                                                                  â•‘
    â•‘  ðŸ“ˆ Advanced LSTM models for financial time series prediction   â•‘
    â•‘  ðŸ”® Next-day price forecasting with temporal cross-validation   â•‘
    â•‘  ðŸŽ Optimized for Apple Silicon (MPS) and CUDA acceleration     â•‘
    â•‘  ðŸ“Š Real data verification and comprehensive evaluation          â•‘
    â•‘                                                                  â•‘
    â•‘  Assets: BSE SENSEX, Gold (INR)                                 â•‘
    â•‘  Horizon: T+1 (next business day)                               â•‘
    â•‘  Features: Technical indicators + price history                  â•‘
    â•‘                                                                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    

=== REAL DATA VERIFICATION STARTING ===

Verifying SENSEX data...
Found 1 file(s) for SENSEX
âœ… VERIFIED: SENSEX rows=5,478 span=2003-10-01â†’2025-10-21 gaps<=2 max_flat=1.0

Verifying GOLD data...
Found 1 file(s) for GOLD
âœ… VERIFIED: GOLD rows=5,383 span=2004-06-11â†’2025-09-30 gaps<=5 max_flat=3.0
ðŸ“ Hashes saved to logs/data_hashes.json

REAL DATA VERIFIED âœ…
